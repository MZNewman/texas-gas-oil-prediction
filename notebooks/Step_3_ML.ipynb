{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4648485d-a4e1-4f6d-ad39-7dee39a7e844",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Pre-Processing](#Pre)\n",
    "    - [Imports](#Imports)\n",
    "    - [Dataset Loading](#Loading)\n",
    "    - [Data Examination](#Exam)\n",
    "    - [Column Pruning](#Column)\n",
    "    - [Temporal Filtering](#Temp)\n",
    "    - [Texas Boundary Validation](#Texas)\n",
    "    - [Calendar Features](#Calendar)\n",
    "    - [Backfill Features](#Back)\n",
    "    - [Rolling Statistics](#Rolling)\n",
    "    - [Categorical Encoding](#Cat)\n",
    "    - [Machine Learning Preparation](#Prep)\n",
    "- [Machine Learning](#Learn)\n",
    "    - [Retry for Speedup](#Retry)\n",
    "- [Making Predictions](#Pred)\n",
    "- [Forecasting and Final Calculations](#Conclusions)\n",
    "    - [State Totals and Uncertainty](#State)\n",
    "- [Results](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5d83e-ab78-430c-9422-b7737cf9575a",
   "metadata": {},
   "source": [
    "## Pre-Processing <a id=\"Pre\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238a020-ef49-4229-a5ad-6db846f92d32",
   "metadata": {},
   "source": [
    "### Imports <a id=\"Imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f488ae1-5746-4128-b909-4ace3d410697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Geospatial processing\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Machine learning\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# GPU acceleration (install with: pip install cudf-cu11 cuml-cu11)\n",
    "GPU_AVAILABLE = True\n",
    "\n",
    "# Visualization and progress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b10c58b-de8b-470c-b718-cae05f15702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff2c5a-a982-4b14-aabc-8b368647424c",
   "metadata": {},
   "source": [
    "### Dataset Loading <a id=\"Loading\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f5a2a-bc46-475d-baee-6b3e8325e659",
   "metadata": {},
   "source": [
    "One version of load_parquet_datasets for most of the notebook that handles using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27df846-8eab-47d3-b4b2-84850e947fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_datasets(file_paths):\n",
    "    \"\"\"\n",
    "    Load multiple parquet files with error handling and initial inspection.\n",
    "    \n",
    "    Args:\n",
    "        file_paths (dict): Dictionary with dataset names as keys and file paths as values\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing loaded DataFrames\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    \n",
    "    for name, path in file_paths.items():\n",
    "        try:\n",
    "            df = pd.read_parquet(path)\n",
    "            print(f\"  Successfully loaded {name} with pandas\")\n",
    "            print(f\"  Shape: {df.shape}\")\n",
    "            datasets[name] = df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load {name}: {str(e)}\")\n",
    "            \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0f6de-f546-4a33-982f-72d94a2035e9",
   "metadata": {},
   "source": [
    "Another version of load_parquet_datasets which handles using dask for data that's difficult to hold in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5615c404-2f79-481b-a553-64fa4ee2f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_datasets(file_paths, use_dask=False, batch_size=1_000_000):\n",
    "    \"\"\"\n",
    "    Load multiple parquet files with memory-friendly options.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import pyarrow.parquet as pq\n",
    "    datasets = {}\n",
    "    for name, path in file_paths.items():\n",
    "        try:\n",
    "            if use_dask:\n",
    "                import dask.dataframe as dd\n",
    "                df = dd.read_parquet(path)\n",
    "                print(f\"  Loaded {name} as Dask DataFrame\")\n",
    "            else:\n",
    "                # Load just the first batch for inspection\n",
    "                table = pq.ParquetFile(path)\n",
    "                batch = next(table.iter_batches(batch_size=batch_size))\n",
    "                df = batch.to_pandas()\n",
    "                print(f\"  Loaded first {len(df)} rows of {name} for inspection\")\n",
    "            print(f\"  Shape: {df.shape}\")\n",
    "            datasets[name] = df\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load {name}: {str(e)}\")\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69efe30c-4a81-4172-ac0b-772a1c34ab58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joined_data': '../data/feature_data_13.parquet'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file_paths = {\n",
    "    'joined_data': '../data/feature_data_13.parquet'\n",
    "}\n",
    "\n",
    "new_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6dcc34-6d41-4ee6-95f3-571aa9cc7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully loaded joined_data with pandas\n",
      "  Shape: (16603790, 29)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16603790 entries, 0 to 16603789\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   county                    object        \n",
      " 6   sub_region                object        \n",
      " 7   wellbore_type             object        \n",
      " 8   Quality_Quant             float64       \n",
      " 9   Production_Age            int32         \n",
      " 10  Last_Report               datetime64[ms]\n",
      " 11  Well_Production_Type      object        \n",
      " 12  reservoir type            object        \n",
      " 13  arps model                object        \n",
      " 14  Production_Status         object        \n",
      " 15  lat_surface               float64       \n",
      " 16  lon_surface               float64       \n",
      " 17  lat_bottomhole            float64       \n",
      " 18  lon_bottomhole            float64       \n",
      " 19  basin                     object        \n",
      " 20  formation_standardized    object        \n",
      " 21  formation_group           object        \n",
      " 22  horizontal_length         float64       \n",
      " 23  measured_depth            float64       \n",
      " 24  depth_tvd                 float64       \n",
      " 25  operator_cluster          float64       \n",
      " 26  well_generation           int64         \n",
      " 27  well_density_1km          int64         \n",
      " 28  nearest_well_distance_km  float64       \n",
      "dtypes: datetime64[ms](2), datetime64[ns](1), float64(12), int32(1), int64(2), object(11)\n",
      "memory usage: 3.5+ GB\n"
     ]
    }
   ],
   "source": [
    "joined_data = load_parquet_datasets(new_file_paths)['joined_data']\n",
    "\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55ccff-2f55-49c3-ac73-2d0444dfb26e",
   "metadata": {},
   "source": [
    "### Data Examination <a id=\"Exam\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55b60c2-cb6e-454b-9492-c58859340f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_data_overview(datasets):\n",
    "    \"\"\"\n",
    "    Provide comprehensive overview of all datasets including data types,\n",
    "    missing values, and basic statistics.\n",
    "    \n",
    "    Args:\n",
    "        datasets (dict): Dictionary of DataFrames to analyze\n",
    "    \"\"\"\n",
    "    for name, df in datasets.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DATASET: {name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Shape\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        \n",
    "        # Column information\n",
    "        print(f\"\\nColumn Overview:\")\n",
    "        print(f\"{'Column':<25} {'Type':<15} {'Non-Null':<10} {'Unique':<10} {'Missing %':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            dtype = str(df[col].dtype)\n",
    "            non_null = df[col].count()\n",
    "            unique_count = df[col].nunique()\n",
    "            missing_pct = (df[col].isnull().sum() / len(df)) * 100\n",
    "            \n",
    "            print(f\"{col:<25} {dtype:<15} {non_null:<10} {unique_count:<10} {missing_pct:<10.1f}%\")\n",
    "        \n",
    "        # Date/time columns detection\n",
    "        potential_date_cols = [col for col in df.columns if \n",
    "                              any(keyword in col.lower() for keyword in \n",
    "                                  ['date', 'time', 'year', 'month', 'spud', 'completion'])]\n",
    "        if potential_date_cols:\n",
    "            print(f\"\\nPotential date/time columns: {potential_date_cols}\")\n",
    "            \n",
    "        # Coordinate columns detection\n",
    "        coord_cols = [col for col in df.columns if \n",
    "                     any(keyword in col.lower() for keyword in \n",
    "                         ['lat', 'lon', 'longitude', 'latitude', 'surface', 'bottom'])]\n",
    "        if coord_cols:\n",
    "            print(f\"\\nCoordinate columns: {coord_cols}\")\n",
    "        \n",
    "        # Production-related columns (for well_production dataset)\n",
    "        if 'production' in name.lower():\n",
    "            prod_cols = [col for col in df.columns if \n",
    "                        any(keyword in col.lower() for keyword in \n",
    "                            ['oil', 'gas', 'water', 'bbl', 'mcf', 'prod', 'volume'])]\n",
    "            if prod_cols:\n",
    "                print(f\"\\nProduction columns: {prod_cols}\")\n",
    "        \n",
    "        # Formation-related columns (for well_formations dataset)\n",
    "        if 'formation' in name.lower():\n",
    "            form_cols = [col for col in df.columns if \n",
    "                        any(keyword in col.lower() for keyword in \n",
    "                            ['formation', 'zone', 'reservoir', 'rock', 'geology', 'basin'])]\n",
    "            if form_cols:\n",
    "                print(f\"\\nFormation columns: {form_cols}\")\n",
    "        \n",
    "        # Well properties columns\n",
    "        if 'properties' in name.lower() or 'props' in name.lower():\n",
    "            prop_cols = [col for col in df.columns if \n",
    "                        any(keyword in col.lower() for keyword in \n",
    "                            ['depth', 'length', 'horizontal', 'vertical', 'lateral', 'completion', 'wellbore', 'field', 'county', 'region'])]\n",
    "            if prop_cols:\n",
    "                print(f\"\\nWell property columns: {prop_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c1668b-8e2f-427f-a580-b1975d33cc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: JOINED_DATA\n",
      "============================================================\n",
      "Shape: (16603790, 29)\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "date_prod                 datetime64[ms]  16603790   472        0.0       %\n",
      "api_no_10                 object          16603790   399913     0.0       %\n",
      "gas_monthly               float64         16603790   130811     0.0       %\n",
      "oil_monthly               float64         16603790   38712      0.0       %\n",
      "start_date                datetime64[ns]  16603790   386        0.0       %\n",
      "county                    object          16603790   225        0.0       %\n",
      "sub_region                object          16603790   5          0.0       %\n",
      "wellbore_type             object          16603790   3          0.0       %\n",
      "Quality_Quant             float64         16603790   9          0.0       %\n",
      "Production_Age            int32           16603790   472        0.0       %\n",
      "Last_Report               datetime64[ms]  16603790   48         0.0       %\n",
      "Well_Production_Type      object          16603790   4          0.0       %\n",
      "reservoir type            object          16603790   3          0.0       %\n",
      "arps model                object          16603790   4          0.0       %\n",
      "Production_Status         object          16603790   3          0.0       %\n",
      "lat_surface               float64         16603790   379510     0.0       %\n",
      "lon_surface               float64         16603790   385972     0.0       %\n",
      "lat_bottomhole            float64         16603790   383244     0.0       %\n",
      "lon_bottomhole            float64         16603790   387732     0.0       %\n",
      "basin                     object          16603790   13         0.0       %\n",
      "formation_standardized    object          16603790   30         0.0       %\n",
      "formation_group           object          16603790   17         0.0       %\n",
      "horizontal_length         float64         16603790   99890      0.0       %\n",
      "measured_depth            float64         16603790   25897      0.0       %\n",
      "depth_tvd                 float64         16603790   105596     0.0       %\n",
      "operator_cluster          float64         16603790   4          0.0       %\n",
      "well_generation           int64           16603790   17         0.0       %\n",
      "well_density_1km          int64           16603790   730        0.0       %\n",
      "nearest_well_distance_km  float64         16603790   273671     0.0       %\n",
      "\n",
      "Potential date/time columns: ['date_prod', 'gas_monthly', 'oil_monthly', 'start_date']\n",
      "\n",
      "Coordinate columns: ['lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole']\n"
     ]
    }
   ],
   "source": [
    "comprehensive_data_overview({'joined_data': joined_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ec1dd-5bab-481f-b100-42dd0a341697",
   "metadata": {},
   "source": [
    "### Column Pruning <a id=\"Column\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ff430a-77d0-4ed1-abb4-02282dfca173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping columns: (16603790, 26)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns we won't use (high cardinality categoricals or unspecific locations)\n",
    "columns_to_drop = ['county', 'sub_region', 'formation_standardized']\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in joined_data.columns]\n",
    "joined_data = joined_data.drop(columns=existing_columns_to_drop)\n",
    "\n",
    "print(f\"After dropping columns: {joined_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1ffcd-fc3b-4b0c-92ee-c6099145e455",
   "metadata": {},
   "source": [
    "### Temporal Filtering <a id=\"Temp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1731f3e-e438-499b-852c-e14d31ee2977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After temporal filtering: (16602611, 26)\n",
      "Date range: 2021-01-01 00:00:00 to 2024-11-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Filter to spike period (January 2021 through November 2024)\n",
    "start_date = pd.to_datetime('2021-01-01')\n",
    "end_date = pd.to_datetime('2024-11-30')\n",
    "\n",
    "joined_data = joined_data[(joined_data['date_prod'] >= start_date) & (joined_data['date_prod'] <= end_date)]\n",
    "print(f\"After temporal filtering: {joined_data.shape}\")\n",
    "\n",
    "# Display date range\n",
    "print(f\"Date range: {joined_data['date_prod'].min()} to {joined_data['date_prod'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ca001-231e-4ab1-87d5-e2d6715f44c8",
   "metadata": {},
   "source": [
    "### Texas Boundary Validation <a id=\"Texas\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53a17b15-337f-45a4-a3f2-d853a479a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_texas_wells(df):\n",
    "    \"\"\"\n",
    "    Remove wells whose surface lies outside Texas.\n",
    "    \"\"\"\n",
    "    print(\"Validating Texas coordinates...\")\n",
    "    \n",
    "    # Load Texas boundary\n",
    "    texas_boundary_url = \"https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA/TX.geo.json\"\n",
    "    texas_gdf = gpd.read_file(texas_boundary_url)\n",
    "    texas_gdf = texas_gdf.to_crs(epsg=4326)\n",
    "    texas_polygon = texas_gdf.unary_union\n",
    "    \n",
    "    def _inside(lat, lon):\n",
    "        if pd.isna(lat) or pd.isna(lon):\n",
    "            return False\n",
    "        return Point(lon, lat).within(texas_polygon)\n",
    "    \n",
    "    # Check surface coordinates\n",
    "    surface_mask = df.dropna(subset=['lat_surface', 'lon_surface']).apply(\n",
    "        lambda r: _inside(r['lat_surface'], r['lon_surface']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Keep wells where the surface is in Texas\n",
    "    valid_surface_apis = surface_mask[surface_mask].index\n",
    "    \n",
    "    print(f\"Wells with valid surface coordinates: {len(valid_surface_apis):,}\")\n",
    "    \n",
    "    return df.loc[valid_surface_apis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc6bc817-8d41-41b5-8e77-aa823bca6ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_well_level_aggregation(df, api_col='api_no_10'):\n",
    "    \"\"\"\n",
    "    Aggregate time series data to well-level (one row per well) for feature engineering.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Time series dataframe\n",
    "    api_col : str\n",
    "        Well API column name\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame : Well-level aggregated dataframe\n",
    "    \"\"\"\n",
    "    well_level = df.groupby(api_col).agg({\n",
    "        'gas_monthly': ['mean', 'median', 'max'],\n",
    "        'oil_monthly': ['mean', 'median', 'max'],\n",
    "        'horizontal_length': 'first',\n",
    "        'measured_depth': 'first',\n",
    "        'lat_surface': 'first',\n",
    "        'lon_surface': 'first',\n",
    "        'lat_bottomhole': 'first',\n",
    "        'lon_bottomhole': 'first',\n",
    "        'wellbore_type': 'first',\n",
    "        'reservoir type': 'first',\n",
    "        'arps model': 'first',\n",
    "        'start_date': 'first',\n",
    "        'basin': 'first',\n",
    "        'formation_group': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    well_level.columns = [\n",
    "        'api_no_10',\n",
    "        'gas_monthly_mean',\n",
    "        'gas_monthly_median',\n",
    "        'gas_monthly_max',\n",
    "        'oil_monthly_mean',\n",
    "        'oil_monthly_median',\n",
    "        'oil_monthly_max',\n",
    "        'horizontal_length',\n",
    "        'measured_depth',\n",
    "        'lat_surface',\n",
    "        'lon_surface',\n",
    "        'lat_bottomhole',\n",
    "        'lon_bottomhole',\n",
    "        'wellbore_type',\n",
    "        'reservoir type',\n",
    "        'arps model',\n",
    "        'start_date',\n",
    "        'basin',\n",
    "        'formation_group'\n",
    "                         ]\n",
    "    \n",
    "    return well_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71d0575b-5061-4037-a094-8b1bf19d417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399913 entries, 0 to 399912\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   api_no_10           399913 non-null  object        \n",
      " 1   gas_monthly_mean    399913 non-null  float64       \n",
      " 2   gas_monthly_median  399913 non-null  float64       \n",
      " 3   gas_monthly_max     399913 non-null  float64       \n",
      " 4   oil_monthly_mean    399913 non-null  float64       \n",
      " 5   oil_monthly_median  399913 non-null  float64       \n",
      " 6   oil_monthly_max     399913 non-null  float64       \n",
      " 7   horizontal_length   399913 non-null  float64       \n",
      " 8   measured_depth      399913 non-null  float64       \n",
      " 9   lat_surface         399913 non-null  float64       \n",
      " 10  lon_surface         399913 non-null  float64       \n",
      " 11  lat_bottomhole      399913 non-null  float64       \n",
      " 12  lon_bottomhole      399913 non-null  float64       \n",
      " 13  wellbore_type       399913 non-null  object        \n",
      " 14  reservoir type      399913 non-null  object        \n",
      " 15  arps model          399913 non-null  object        \n",
      " 16  start_date          399913 non-null  datetime64[ns]\n",
      " 17  basin               399913 non-null  object        \n",
      " 18  formation_group     399913 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(6)\n",
      "memory usage: 58.0+ MB\n"
     ]
    }
   ],
   "source": [
    "well_df = get_well_level_aggregation(joined_data, api_col='api_no_10')\n",
    "well_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b36cd48-a0ec-442b-9d35-13397d98a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Texas coordinates...\n",
      "Wells with valid surface coordinates: 399,039\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 399039 entries, 0 to 399912\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   api_no_10           399039 non-null  object        \n",
      " 1   gas_monthly_mean    399039 non-null  float64       \n",
      " 2   gas_monthly_median  399039 non-null  float64       \n",
      " 3   gas_monthly_max     399039 non-null  float64       \n",
      " 4   oil_monthly_mean    399039 non-null  float64       \n",
      " 5   oil_monthly_median  399039 non-null  float64       \n",
      " 6   oil_monthly_max     399039 non-null  float64       \n",
      " 7   horizontal_length   399039 non-null  float64       \n",
      " 8   measured_depth      399039 non-null  float64       \n",
      " 9   lat_surface         399039 non-null  float64       \n",
      " 10  lon_surface         399039 non-null  float64       \n",
      " 11  lat_bottomhole      399039 non-null  float64       \n",
      " 12  lon_bottomhole      399039 non-null  float64       \n",
      " 13  wellbore_type       399039 non-null  object        \n",
      " 14  reservoir type      399039 non-null  object        \n",
      " 15  arps model          399039 non-null  object        \n",
      " 16  start_date          399039 non-null  datetime64[ns]\n",
      " 17  basin               399039 non-null  object        \n",
      " 18  formation_group     399039 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(6)\n",
      "memory usage: 60.9+ MB\n"
     ]
    }
   ],
   "source": [
    "result_df = keep_texas_wells(well_df)\n",
    "result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be86773-cf1a-4113-aa09-948a5e1d20a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Texas validation: (16564703, 26)\n"
     ]
    }
   ],
   "source": [
    "api_list = result_df['api_no_10'].unique()\n",
    "joined_data = joined_data[joined_data['api_no_10'].isin(api_list)]\n",
    "print(f\"After Texas validation: {joined_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaa2b89a-eed4-4c34-94a5-7b2d00018d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.to_parquet('../data/preprocess_1.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb0c70-8d3e-4c2f-8733-aece128dd73f",
   "metadata": {},
   "source": [
    "### Calendar Features <a id=\"Calendar\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05bbdc90-b241-4e80-b8d4-530f75f499a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joined_data': '../data/preprocess_1.parquet'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file_paths = {\n",
    "    'joined_data': '../data/preprocess_1.parquet'\n",
    "}\n",
    "\n",
    "new_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ccd712b-dd4b-460d-84fd-1d8a0a1ec772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully loaded joined_data with pandas\n",
      "  Shape: (16564703, 26)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 26 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             object        \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Last_Report               datetime64[ms]\n",
      " 9   Well_Production_Type      object        \n",
      " 10  reservoir type            object        \n",
      " 11  arps model                object        \n",
      " 12  Production_Status         object        \n",
      " 13  lat_surface               float64       \n",
      " 14  lon_surface               float64       \n",
      " 15  lat_bottomhole            float64       \n",
      " 16  lon_bottomhole            float64       \n",
      " 17  basin                     object        \n",
      " 18  formation_group           object        \n",
      " 19  horizontal_length         float64       \n",
      " 20  measured_depth            float64       \n",
      " 21  depth_tvd                 float64       \n",
      " 22  operator_cluster          float64       \n",
      " 23  well_generation           int64         \n",
      " 24  well_density_1km          int64         \n",
      " 25  nearest_well_distance_km  float64       \n",
      "dtypes: datetime64[ms](2), datetime64[ns](1), float64(12), int32(1), int64(2), object(8)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "joined_data = load_parquet_datasets(new_file_paths)['joined_data']\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd0c438-1d90-4c91-bb7f-cc18ccc5c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 30 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             object        \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Last_Report               datetime64[ms]\n",
      " 9   Well_Production_Type      object        \n",
      " 10  reservoir type            object        \n",
      " 11  arps model                object        \n",
      " 12  Production_Status         object        \n",
      " 13  lat_surface               float64       \n",
      " 14  lon_surface               float64       \n",
      " 15  lat_bottomhole            float64       \n",
      " 16  lon_bottomhole            float64       \n",
      " 17  basin                     object        \n",
      " 18  formation_group           object        \n",
      " 19  horizontal_length         float64       \n",
      " 20  measured_depth            float64       \n",
      " 21  depth_tvd                 float64       \n",
      " 22  operator_cluster          float64       \n",
      " 23  well_generation           int64         \n",
      " 24  well_density_1km          int64         \n",
      " 25  nearest_well_distance_km  float64       \n",
      " 26  prod_year                 int32         \n",
      " 27  prod_month                int32         \n",
      " 28  month_sin                 float64       \n",
      " 29  month_cos                 float64       \n",
      "dtypes: datetime64[ms](2), datetime64[ns](1), float64(14), int32(3), int64(2), object(8)\n",
      "memory usage: 3.6+ GB\n"
     ]
    }
   ],
   "source": [
    "# Basic calendar features\n",
    "joined_data['prod_year'] = joined_data['date_prod'].dt.year\n",
    "joined_data['prod_month'] = joined_data['date_prod'].dt.month\n",
    "\n",
    "# Seasonal features (sine/cosine pairs)\n",
    "joined_data['month_sin'] = np.sin(2 * np.pi * joined_data['prod_month'] / 12)\n",
    "joined_data['month_cos'] = np.cos(2 * np.pi * joined_data['prod_month'] / 12)\n",
    "\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d528da0-bd71-4439-a399-ed060895ad94",
   "metadata": {},
   "source": [
    "### Backfill Features <a id=\"Back\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502babae-ecb0-4e9a-9339-b2b997647527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backfill_features_fast(df):\n",
    "    \"\"\"\n",
    "    Efficiently create backfill features for each well using vectorized operations.\n",
    "    \"\"\"\n",
    "    print(\"Creating backfill features (vectorized)...\")\n",
    "    df = df.sort_values(['api_no_10', 'date_prod']).copy()\n",
    "    \n",
    "    # Group by well\n",
    "    grouped = df.groupby('api_no_10')\n",
    "    \n",
    "    # Shifted features\n",
    "    df['last_year'] = grouped['date_prod'].shift(1).dt.year.fillna(-1).astype(int)\n",
    "    df['last_month'] = grouped['date_prod'].shift(1).dt.month.fillna(-1).astype(int)\n",
    "    df['last_gas'] = grouped['gas_monthly'].shift(1).fillna(-1)\n",
    "    df['last_oil'] = grouped['oil_monthly'].shift(1).fillna(-1)\n",
    "    \n",
    "    # Months since last report\n",
    "    prev_date = grouped['date_prod'].shift(1)\n",
    "    df['months_since_last'] = ((df['date_prod'] - prev_date).dt.days / 30.44).round().fillna(-1).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b7266-b939-4e30-a17d-399491507316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating backfill features (vectorized)...\n"
     ]
    }
   ],
   "source": [
    "joined_data = create_backfill_features_fast(joined_data)\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6f4bf-43ff-4c11-842d-ac5fa90c34bf",
   "metadata": {},
   "source": [
    "This function freezes my computer, and a previous one wasn't fast enough to process all this time series data. Here is another one that might work by using batching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb7715e7-8192-42dc-a774-a9a350839085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(df, batch_size):\n",
    "    \"\"\"\n",
    "    Yields batches of the dataframe, grouped by unique api_no_10 values.\n",
    "    \"\"\"\n",
    "    unique_apis = df['api_no_10'].unique()\n",
    "    for start in range(0, len(unique_apis), batch_size):\n",
    "        batch_apis = unique_apis[start:start + batch_size]\n",
    "        yield df[df['api_no_10'].isin(batch_apis)].copy()\n",
    "\n",
    "def create_backfill_features_batched(df, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Create backfill features in batches to reduce memory usage.\n",
    "    \"\"\"\n",
    "    print(f\"Processing in batches of {batch_size} wells...\")\n",
    "    processed_batches = []\n",
    "    batch_number = 1\n",
    "    for batch_df in batch_iter(df, batch_size):\n",
    "        print(f\"Processing batch {batch_number} ({batch_df['api_no_10'].nunique()} wells, {len(batch_df)} rows)\")\n",
    "        batch_df = batch_df.sort_values(['api_no_10', 'date_prod'])\n",
    "        grouped = batch_df.groupby('api_no_10')\n",
    "        batch_df['last_year'] = grouped['date_prod'].shift(1).dt.year.fillna(-1).astype(int)\n",
    "        batch_df['last_month'] = grouped['date_prod'].shift(1).dt.month.fillna(-1).astype(int)\n",
    "        batch_df['last_gas'] = grouped['gas_monthly'].shift(1).fillna(-1)\n",
    "        batch_df['last_oil'] = grouped['oil_monthly'].shift(1).fillna(-1)\n",
    "        prev_date = grouped['date_prod'].shift(1)\n",
    "        batch_df['months_since_last'] = ((batch_df['date_prod'] - prev_date).dt.days / 30.44).round().fillna(-1).astype(int)\n",
    "        processed_batches.append(batch_df)\n",
    "        batch_number += 1\n",
    "    # Concatenate all processed batches\n",
    "    result_df = pd.concat(processed_batches).sort_index()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b1b1d1-6ad7-47db-ba6d-6d87b2c4c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing in batches of 10000 wells...\n",
      "Processing batch 1 (10000 wells, 436982 rows)\n",
      "Processing batch 2 (10000 wells, 436599 rows)\n",
      "Processing batch 3 (10000 wells, 436660 rows)\n",
      "Processing batch 4 (10000 wells, 436382 rows)\n",
      "Processing batch 5 (10000 wells, 436013 rows)\n",
      "Processing batch 6 (10000 wells, 436164 rows)\n",
      "Processing batch 7 (10000 wells, 434300 rows)\n",
      "Processing batch 8 (10000 wells, 435459 rows)\n",
      "Processing batch 9 (10000 wells, 434428 rows)\n",
      "Processing batch 10 (10000 wells, 434634 rows)\n",
      "Processing batch 11 (10000 wells, 433542 rows)\n",
      "Processing batch 12 (10000 wells, 433859 rows)\n",
      "Processing batch 13 (10000 wells, 433264 rows)\n",
      "Processing batch 14 (10000 wells, 433858 rows)\n",
      "Processing batch 15 (10000 wells, 434111 rows)\n",
      "Processing batch 16 (10000 wells, 433314 rows)\n",
      "Processing batch 17 (10000 wells, 433006 rows)\n",
      "Processing batch 18 (10000 wells, 431961 rows)\n",
      "Processing batch 19 (10000 wells, 432668 rows)\n",
      "Processing batch 20 (10000 wells, 431541 rows)\n",
      "Processing batch 21 (10000 wells, 430828 rows)\n",
      "Processing batch 22 (10000 wells, 430952 rows)\n",
      "Processing batch 23 (10000 wells, 430376 rows)\n",
      "Processing batch 24 (10000 wells, 429173 rows)\n",
      "Processing batch 25 (10000 wells, 429459 rows)\n",
      "Processing batch 26 (10000 wells, 426591 rows)\n",
      "Processing batch 27 (10000 wells, 426371 rows)\n",
      "Processing batch 28 (10000 wells, 425641 rows)\n",
      "Processing batch 29 (10000 wells, 424501 rows)\n",
      "Processing batch 30 (10000 wells, 424883 rows)\n",
      "Processing batch 31 (10000 wells, 421593 rows)\n",
      "Processing batch 32 (10000 wells, 418426 rows)\n",
      "Processing batch 33 (10000 wells, 416339 rows)\n",
      "Processing batch 34 (10000 wells, 414553 rows)\n",
      "Processing batch 35 (10000 wells, 410650 rows)\n",
      "Processing batch 36 (10000 wells, 403119 rows)\n",
      "Processing batch 37 (10000 wells, 393313 rows)\n",
      "Processing batch 38 (10000 wells, 371342 rows)\n",
      "Processing batch 39 (10000 wells, 289410 rows)\n",
      "Processing batch 40 (9039 wells, 58438 rows)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             object        \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Last_Report               datetime64[ms]\n",
      " 9   Well_Production_Type      object        \n",
      " 10  reservoir type            object        \n",
      " 11  arps model                object        \n",
      " 12  Production_Status         object        \n",
      " 13  lat_surface               float64       \n",
      " 14  lon_surface               float64       \n",
      " 15  lat_bottomhole            float64       \n",
      " 16  lon_bottomhole            float64       \n",
      " 17  basin                     object        \n",
      " 18  formation_group           object        \n",
      " 19  horizontal_length         float64       \n",
      " 20  measured_depth            float64       \n",
      " 21  depth_tvd                 float64       \n",
      " 22  operator_cluster          float64       \n",
      " 23  well_generation           int64         \n",
      " 24  well_density_1km          int64         \n",
      " 25  nearest_well_distance_km  float64       \n",
      " 26  prod_year                 int32         \n",
      " 27  prod_month                int32         \n",
      " 28  month_sin                 float64       \n",
      " 29  month_cos                 float64       \n",
      " 30  last_year                 int32         \n",
      " 31  last_month                int32         \n",
      " 32  last_gas                  float64       \n",
      " 33  last_oil                  float64       \n",
      " 34  months_since_last         int32         \n",
      "dtypes: datetime64[ms](2), datetime64[ns](1), float64(16), int32(6), int64(2), object(8)\n",
      "memory usage: 4.1+ GB\n"
     ]
    }
   ],
   "source": [
    "joined_data = create_backfill_features_batched(joined_data)\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f5362-7ba6-4da7-8919-a34ec8a82973",
   "metadata": {},
   "source": [
    "Now that we have superior backfilling columns, we can drop columns that give us unnecessary temporal information but most likely won't be as useful, such as \"Last_Report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65288c71-ad88-4ede-a968-52e9bd1c430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 34 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             object        \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Well_Production_Type      object        \n",
      " 9   reservoir type            object        \n",
      " 10  arps model                object        \n",
      " 11  Production_Status         object        \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     object        \n",
      " 17  formation_group           object        \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          float64       \n",
      " 22  well_generation           int64         \n",
      " 23  well_density_1km          int64         \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 int32         \n",
      " 26  prod_month                int32         \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      " 29  last_year                 int32         \n",
      " 30  last_month                int32         \n",
      " 31  last_gas                  float64       \n",
      " 32  last_oil                  float64       \n",
      " 33  months_since_last         int32         \n",
      "dtypes: datetime64[ms](1), datetime64[ns](1), float64(16), int32(6), int64(2), object(8)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "joined_data.drop('Last_Report', axis=1, inplace=True)\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29d0806-5f5e-4148-902a-94c21547f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.to_parquet('../data/preprocess_2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6a34a-6feb-4d20-9442-c62f497f262e",
   "metadata": {},
   "source": [
    "### Rolling Statistics <a id=\"Rolling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e26d45-938d-4e03-a0b3-1e2aa6ded6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(df, batch_size):\n",
    "    \"\"\"\n",
    "    Yields batches of the dataframe, grouped by unique api_no_10 values.\n",
    "    \"\"\"\n",
    "    unique_apis = df['api_no_10'].unique()\n",
    "    for start in range(0, len(unique_apis), batch_size):\n",
    "        batch_apis = unique_apis[start:start + batch_size]\n",
    "        yield df[df['api_no_10'].isin(batch_apis)].copy()\n",
    "\n",
    "def create_rolling_features_batched(df, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Efficiently create rolling statistics features in batches.\n",
    "    \"\"\"\n",
    "    print(f\"Processing rolling features in batches of {batch_size} wells...\")\n",
    "    processed_batches = []\n",
    "    batch_number = 1\n",
    "    for batch_df in batch_iter(df, batch_size):\n",
    "        print(f\"Processing batch {batch_number} ({batch_df['api_no_10'].nunique()} wells, {len(batch_df)} rows)\")\n",
    "        batch_df = batch_df.sort_values(['api_no_10', 'date_prod'])\n",
    "        grouped = batch_df.groupby('api_no_10', group_keys=False)\n",
    "        batch_df['gas_avg_3'] = grouped['gas_monthly'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        batch_df['oil_avg_3'] = grouped['oil_monthly'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        batch_df['gas_avg_6'] = grouped['gas_monthly'].rolling(window=6, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        batch_df['oil_avg_6'] = grouped['oil_monthly'].rolling(window=6, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        processed_batches.append(batch_df)\n",
    "        batch_number += 1\n",
    "    # Concatenate all processed batches and restore original order\n",
    "    result_df = pd.concat(processed_batches).sort_index()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e1311e-cc0d-4a09-aaa5-17acf79703bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rolling features in batches of 10000 wells...\n",
      "Processing batch 1 (10000 wells, 436982 rows)\n",
      "Processing batch 2 (10000 wells, 436599 rows)\n",
      "Processing batch 3 (10000 wells, 436660 rows)\n",
      "Processing batch 4 (10000 wells, 436382 rows)\n",
      "Processing batch 5 (10000 wells, 436013 rows)\n",
      "Processing batch 6 (10000 wells, 436164 rows)\n",
      "Processing batch 7 (10000 wells, 434300 rows)\n",
      "Processing batch 8 (10000 wells, 435459 rows)\n",
      "Processing batch 9 (10000 wells, 434428 rows)\n",
      "Processing batch 10 (10000 wells, 434634 rows)\n",
      "Processing batch 11 (10000 wells, 433542 rows)\n",
      "Processing batch 12 (10000 wells, 433859 rows)\n",
      "Processing batch 13 (10000 wells, 433264 rows)\n",
      "Processing batch 14 (10000 wells, 433858 rows)\n",
      "Processing batch 15 (10000 wells, 434111 rows)\n",
      "Processing batch 16 (10000 wells, 433314 rows)\n",
      "Processing batch 17 (10000 wells, 433006 rows)\n",
      "Processing batch 18 (10000 wells, 431961 rows)\n",
      "Processing batch 19 (10000 wells, 432668 rows)\n",
      "Processing batch 20 (10000 wells, 431541 rows)\n",
      "Processing batch 21 (10000 wells, 430828 rows)\n",
      "Processing batch 22 (10000 wells, 430952 rows)\n",
      "Processing batch 23 (10000 wells, 430376 rows)\n",
      "Processing batch 24 (10000 wells, 429173 rows)\n",
      "Processing batch 25 (10000 wells, 429459 rows)\n",
      "Processing batch 26 (10000 wells, 426591 rows)\n",
      "Processing batch 27 (10000 wells, 426371 rows)\n",
      "Processing batch 28 (10000 wells, 425641 rows)\n",
      "Processing batch 29 (10000 wells, 424501 rows)\n",
      "Processing batch 30 (10000 wells, 424883 rows)\n",
      "Processing batch 31 (10000 wells, 421593 rows)\n",
      "Processing batch 32 (10000 wells, 418426 rows)\n",
      "Processing batch 33 (10000 wells, 416339 rows)\n",
      "Processing batch 34 (10000 wells, 414553 rows)\n",
      "Processing batch 35 (10000 wells, 410650 rows)\n",
      "Processing batch 36 (10000 wells, 403119 rows)\n",
      "Processing batch 37 (10000 wells, 393313 rows)\n",
      "Processing batch 38 (10000 wells, 371342 rows)\n",
      "Processing batch 39 (10000 wells, 289410 rows)\n",
      "Processing batch 40 (9039 wells, 58438 rows)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             object        \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Well_Production_Type      object        \n",
      " 9   reservoir type            object        \n",
      " 10  arps model                object        \n",
      " 11  Production_Status         object        \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     object        \n",
      " 17  formation_group           object        \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          float64       \n",
      " 22  well_generation           int64         \n",
      " 23  well_density_1km          int64         \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 int32         \n",
      " 26  prod_month                int32         \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      " 29  last_year                 int32         \n",
      " 30  last_month                int32         \n",
      " 31  last_gas                  float64       \n",
      " 32  last_oil                  float64       \n",
      " 33  months_since_last         int32         \n",
      " 34  gas_avg_3                 float64       \n",
      " 35  oil_avg_3                 float64       \n",
      " 36  gas_avg_6                 float64       \n",
      " 37  oil_avg_6                 float64       \n",
      "dtypes: datetime64[ms](1), datetime64[ns](1), float64(20), int32(6), int64(2), object(8)\n",
      "memory usage: 4.4+ GB\n"
     ]
    }
   ],
   "source": [
    "joined_data = create_rolling_features_batched(joined_data)\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74cd17b8-1239-4f00-8eb7-5e9fd486bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.to_parquet('../data/preprocess_3.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355d0b3-0f96-4da2-b850-c2b3ec61217b",
   "metadata": {},
   "source": [
    "### Categorical Encoding <a id=\"Cat\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32051f4d-f0cb-424b-9ec2-934169a0aa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 7 categorical columns\n",
      "Final dataset shape: (16564703, 38)\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['wellbore_type', 'Well_Production_Type', 'reservoir type', \n",
    "                   'arps model', 'Production_Status', 'basin', 'formation_group']\n",
    "\n",
    "# Only process columns that exist in the dataframe\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in joined_data.columns]\n",
    "\n",
    "# Create label encoders\n",
    "label_encoders = {}\n",
    "for col in existing_categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    joined_data[col] = joined_data[col].astype(str)  # Convert to string first\n",
    "    joined_data[col] = le.fit_transform(joined_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"Encoded {len(existing_categorical_cols)} categorical columns\")\n",
    "\n",
    "# Fill any remaining NaN values\n",
    "numeric_cols = joined_data.select_dtypes(include=[np.number]).columns\n",
    "joined_data[numeric_cols] = joined_data[numeric_cols].fillna(-1)\n",
    "\n",
    "print(f\"Final dataset shape: {joined_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd12bec9-9598-4f6e-bb0e-484b08b8721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.to_parquet('../data/preprocess_4.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189875d2-59e0-4d29-adb5-6b59e44f3d3c",
   "metadata": {},
   "source": [
    "### Machine Learning Preparation <a id=\"Prep\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86095ed8-45e5-401f-9eec-cd1603f20d13",
   "metadata": {},
   "source": [
    "Forgot to turn operator cluster into a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd291390-b5a6-4950-9cdb-1997d88d207c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operator_cluster\n",
       "3.0    9049392\n",
       "0.0    6932712\n",
       "2.0     529380\n",
       "1.0      53219\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data['operator_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ecfc53c-2e25-49d7-bd09-bbcef4a61020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wellbore_type': LabelEncoder(),\n",
       " 'Well_Production_Type': LabelEncoder(),\n",
       " 'reservoir type': LabelEncoder(),\n",
       " 'arps model': LabelEncoder(),\n",
       " 'Production_Status': LabelEncoder(),\n",
       " 'basin': LabelEncoder(),\n",
       " 'formation_group': LabelEncoder(),\n",
       " 'operator_cluster': LabelEncoder()}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "joined_data['operator_cluster'] = joined_data['operator_cluster'].astype(str)  # Convert to string first\n",
    "joined_data['operator_cluster'] = le.fit_transform(joined_data['operator_cluster'])\n",
    "label_encoders['operator_cluster'] = le\n",
    "label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee524ae0-11f6-4884-97b3-0658c0802e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             int32         \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Well_Production_Type      int32         \n",
      " 9   reservoir type            int32         \n",
      " 10  arps model                int32         \n",
      " 11  Production_Status         int32         \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     int32         \n",
      " 17  formation_group           int32         \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          int32         \n",
      " 22  well_generation           int64         \n",
      " 23  well_density_1km          int64         \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 int32         \n",
      " 26  prod_month                int32         \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      " 29  last_year                 int32         \n",
      " 30  last_month                int32         \n",
      " 31  last_gas                  float64       \n",
      " 32  last_oil                  float64       \n",
      " 33  months_since_last         int32         \n",
      " 34  gas_avg_3                 float64       \n",
      " 35  oil_avg_3                 float64       \n",
      " 36  gas_avg_6                 float64       \n",
      " 37  oil_avg_6                 float64       \n",
      "dtypes: datetime64[ms](1), datetime64[ns](1), float64(19), int32(14), int64(2), object(1)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9e54599-5831-4a3e-a28e-fbd7867845b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operator_cluster\n",
       "3    9049392\n",
       "0    6932712\n",
       "2     529380\n",
       "1      53219\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data['operator_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e87124f2-795f-4703-be19-350f3d633993",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.to_parquet('../data/preprocess_5.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e9b0bea-d3f2-4521-aca2-32d923bf3047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns (33):\n",
      "['wellbore_type', 'Quality_Quant', 'Production_Age', 'Well_Production_Type', 'reservoir type', 'arps model', 'Production_Status', 'lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole', 'basin', 'formation_group', 'horizontal_length', 'measured_depth', 'depth_tvd', 'operator_cluster', 'well_generation', 'well_density_1km', 'nearest_well_distance_km', 'prod_year', 'prod_month', 'month_sin', 'month_cos', 'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last', 'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6']\n",
      "Feature matrix shape: (16564703, 33)\n",
      "Target vectors shape: (16564703,)\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns (exclude API, dates, and targets)\n",
    "exclude_cols = ['api_no_10', 'date_prod', 'start_date', 'gas_monthly', 'oil_monthly']\n",
    "feature_cols = [col for col in joined_data.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Feature columns ({len(feature_cols)}):\")\n",
    "print(feature_cols)\n",
    "\n",
    "# Create feature matrix and target vectors\n",
    "X = joined_data[feature_cols].copy()\n",
    "y_gas = joined_data['gas_monthly'].copy()\n",
    "y_oil = joined_data['oil_monthly'].copy()\n",
    "\n",
    "# Store API mapping for later use\n",
    "api_mapping = joined_data[['api_no_10', 'date_prod']].copy()\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vectors shape: {y_gas.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07f2ef75-63d0-4d92-bbd9-38f0763ba45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (15558160, 33)\n",
      "Test set shape: (1006543, 33)\n",
      "Training date range: 2021-01-01 00:00:00 to 2024-06-01 00:00:00\n",
      "Test date range: 2024-07-01 00:00:00 to 2024-11-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Hold out last 5 months (July-November 2024) as test set\n",
    "# model shouldn't look at future data to simulate deployment into production\n",
    "# so test set should be the latest months\n",
    "test_start_date = pd.to_datetime('2024-07-01')\n",
    "train_mask = joined_data['date_prod'] < test_start_date\n",
    "test_mask = joined_data['date_prod'] >= test_start_date\n",
    "\n",
    "# Create splits\n",
    "X_train = X[train_mask]\n",
    "y_gas_train = y_gas[train_mask]\n",
    "y_oil_train = y_oil[train_mask]\n",
    "\n",
    "X_test = X[test_mask]\n",
    "y_gas_test = y_gas[test_mask]\n",
    "y_oil_test = y_oil[test_mask]\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training date range: {joined_data[train_mask]['date_prod'].min()} to {joined_data[train_mask]['date_prod'].max()}\")\n",
    "print(f\"Test date range: {joined_data[test_mask]['date_prod'].min()} to {joined_data[test_mask]['date_prod'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d07e72-0560-4c03-9b2e-f747c0997d79",
   "metadata": {},
   "source": [
    "## Machine Learning <a id=\"Learn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d204753-dda6-477b-a99b-92106d8940ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'n_estimators': [600, 800, 1000]\n",
    "}\n",
    "\n",
    "# Base XGBoost parameters\n",
    "xgb_base_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' if GPU_AVAILABLE else 'cpu',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Time series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=None, gap=1) #should split by one month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78bc08c3-009f-474c-886c-626b44112b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, target_name):\n",
    "    print(f\"Training XGBoost for {target_name}...\")\n",
    "    \n",
    "    # Create base model\n",
    "    xgb_model = xgb.XGBRegressor(**xgb_base_params)\n",
    "    \n",
    "    # Random search\n",
    "    xgb_search = RandomizedSearchCV(\n",
    "        xgb_model,\n",
    "        xgb_param_grid,\n",
    "        n_iter=25,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        random_state=42,\n",
    "        n_jobs=1,  # Use 1 job to avoid GPU memory issues\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    \n",
    "    return xgb_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47d2c8c1-ee16-4c24-85d9-09d02e81e401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost for gas...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m xgb_gas_model = \u001b[43mtrain_xgb_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gas_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mtrain_xgb_model\u001b[39m\u001b[34m(X_train, y_train, target_name)\u001b[39m\n\u001b[32m      8\u001b[39m xgb_search = RandomizedSearchCV(\n\u001b[32m      9\u001b[39m     xgb_model,\n\u001b[32m     10\u001b[39m     xgb_param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mxgb_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xgb_search\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:881\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    878\u001b[39m result[\u001b[33m\"\u001b[39m\u001b[33mfit_error\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    880\u001b[39m fit_time = time.time() - start_time\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m test_scores = \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    884\u001b[39m score_time = time.time() - start_time - fit_time\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:942\u001b[39m, in \u001b[36m_score\u001b[39m\u001b[34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[39m\n\u001b[32m    940\u001b[39m         scores = scorer(estimator, X_test, **score_params)\n\u001b[32m    941\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m         scores = \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[32m    945\u001b[39m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[32m    946\u001b[39m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:308\u001b[39m, in \u001b[36m_BaseScorer.__call__\u001b[39m\u001b[34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    306\u001b[39m     _kwargs[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:400\u001b[39m, in \u001b[36m_Scorer._score\u001b[39m\u001b[34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m pos_label = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_pos_label()\n\u001b[32m    399\u001b[39m response_method = _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m._response_method)\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m y_pred = \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_get_response_method_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m scoring_kwargs = {**\u001b[38;5;28mself\u001b[39m._kwargs, **kwargs}\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sign * \u001b[38;5;28mself\u001b[39m._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:90\u001b[39m, in \u001b[36m_cached_call\u001b[39m\u001b[34m(cache, estimator, response_method, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m result, _ = \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     95\u001b[39m     cache[response_method] = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\sklearn\\utils\\_response.py:242\u001b[39m, in \u001b[36m_get_response_values\u001b[39m\u001b[34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[39m\n\u001b[32m    235\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    236\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m should either be a classifier to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mused with response_method=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or the response_method \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mshould be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Got a regressor with response_method=\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m         )\n\u001b[32m    241\u001b[39m     prediction_method = estimator.predict\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     y_pred, pos_label = \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_response_method_used:\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, pos_label, prediction_method.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\sklearn.py:1327\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1327\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmargin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1336\u001b[39m             cp = import_cupy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\core.py:2700\u001b[39m, in \u001b[36mBooster.inplace_predict\u001b[39m\u001b[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[39m\n\u001b[32m   2697\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (ArrowTransformed, PandasTransformed)):\n\u001b[32m   2699\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2700\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterPredictFromColumnar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2701\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2703\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mp_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2705\u001b[39m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2706\u001b[39m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2707\u001b[39m \u001b[43m            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2708\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2709\u001b[39m     )\n\u001b[32m   2710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, scipy.sparse.csr_matrix):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "xgb_gas_model = train_xgb_model(X_train, y_gas_train, \"gas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5949acf4-90a4-42d0-9c1d-2cee32e88101",
   "metadata": {},
   "source": [
    "Unfortunately, this model is going to take too long (it will take literally days to run with my current setup)\n",
    "- there are too many features, I put a lot of effort into creating them but they won't work well with my particular setup\n",
    "- we're fitting too many samples to the trees for hyperparameter tuning, we can use a representative subset for that\n",
    "- we aren't implementing early stopping of unpromising models, which will waste time\n",
    "- we are doing more random search iterations than we can afford, let's lower it down for this limited setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2ffa7-df3c-4f12-b29b-a03a25f205c1",
   "metadata": {},
   "source": [
    "### Retry for Speedup <a id=\"Retry\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee4583c7-197d-40dc-9e96-ab70b507391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = [\n",
    "    'wellbore_type',\n",
    "    'lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole',\n",
    "    'basin', 'operator_cluster', 'well_density_1km',\n",
    "    'gas_avg_3', 'oil_avg_3'\n",
    "]\n",
    "\n",
    "# For gas model, remove 'oil_avg_6' as well\n",
    "features_gas = [col for col in X.columns if col not in features_to_remove + ['oil_avg_6']]\n",
    "\n",
    "# For oil model, remove 'gas_avg_6' as well\n",
    "features_oil = [col for col in X.columns if col not in features_to_remove + ['gas_avg_6']]\n",
    "\n",
    "# Create reduced feature sets\n",
    "X_gas = X[features_gas]\n",
    "X_oil = X[features_oil]\n",
    "\n",
    "# Downsample (e.g., 500,000 rows; adjust as needed)\n",
    "sample_frac = 500_000 / len(X_gas)\n",
    "X_gas_sample = X_gas.sample(frac=sample_frac, random_state=42)\n",
    "y_gas_sample = y_gas.loc[X_gas_sample.index]\n",
    "\n",
    "X_oil_sample = X_oil.sample(frac=sample_frac, random_state=42)\n",
    "y_oil_sample = y_oil.loc[X_oil_sample.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e50083c7-9cef-47aa-ac3a-f8ebc0fadf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for early stopping\n",
    "tscv = TimeSeriesSplit(n_splits=5, gap=1)\n",
    "\n",
    "# Reduced hyperparameter search space\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'n_estimators': [600, 800]\n",
    "}\n",
    "\n",
    "xgb_base_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' if GPU_AVAILABLE else 'cpu',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_rounds': 10,\n",
    "    'eval_metric': 'mae',\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "# Only 5–10 iterations for speed\n",
    "n_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b8f8d85-8c32-41ec-99a0-a448e48d6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X_train, y_train, target_name):\n",
    "    print(f\"Training XGBoost for {target_name}...\")\n",
    "    xgb_model = xgb.XGBRegressor(**xgb_base_params)\n",
    "    xgb_search = RandomizedSearchCV(\n",
    "        xgb_model,\n",
    "        xgb_param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        random_state=42,\n",
    "        n_jobs=1,\n",
    "        verbose=0\n",
    "    )\n",
    "    # Use callbacks for early stopping\n",
    "    xgb_search.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train)],  # Required for early stopping, but CV will override this per fold\n",
    "        verbose=False\n",
    "    )\n",
    "    return xgb_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a99a6f01-f85b-422e-a975-c4d9ecdb2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost for gas...\n"
     ]
    }
   ],
   "source": [
    "xgb_gas_model = train_xgb_model(X_gas_sample, y_gas_sample, \"gas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "310f0b78-92fe-4de0-a414-b71792da3317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best gas model MAE: 524.7908\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best gas model MAE: {-xgb_gas_model.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91f376c4-1919-40ee-96ac-366d9113e03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=TimeSeriesSplit(gap=1, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=&#x27;cuda&#x27;,\n",
       "                                          early_stopping_rounds=10,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=&#x27;mae&#x27;, feature_types=None,\n",
       "                                          feature_weights=None, gam...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          multi_strategy=None,\n",
       "                                          n_estimators=None, n_jobs=-1,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.8, 1.0],\n",
       "                                        &#x27;learning_rate&#x27;: [0.03, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [4, 6, 8],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 3],\n",
       "                                        &#x27;n_estimators&#x27;: [600, 800],\n",
       "                                        &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">XGBRegressor(...ree=None, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_distributions',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_distributions&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;colsample_bytree&#x27;: [0.8, 1.0], &#x27;learning_rate&#x27;: [0.03, 0.05, ...], &#x27;max_depth&#x27;: [4, 6, ...], &#x27;min_child_weight&#x27;: [1, 3], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;neg_mean_absolute_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">TimeSeriesSpl...est_size=None)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=&#x27;cuda&#x27;, early_stopping_rounds=10,\n",
       "             enable_categorical=False, eval_metric=&#x27;mae&#x27;, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;mae&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.03</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=1, max_train_size=None, n_splits=5, test_size=None),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device='cuda',\n",
       "                                          early_stopping_rounds=10,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric='mae', feature_types=None,\n",
       "                                          feature_weights=None, gam...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          multi_strategy=None,\n",
       "                                          n_estimators=None, n_jobs=-1,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={'colsample_bytree': [0.8, 1.0],\n",
       "                                        'learning_rate': [0.03, 0.05, 0.1],\n",
       "                                        'max_depth': [4, 6, 8],\n",
       "                                        'min_child_weight': [1, 3],\n",
       "                                        'n_estimators': [600, 800],\n",
       "                                        'subsample': [0.8, 1.0]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_gas_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b44bb023-c913-4110-92ce-22360a8e0b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost for oil...\n"
     ]
    }
   ],
   "source": [
    "xgb_oil_model = train_xgb_model(X_oil_sample, y_oil_sample, \"oil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40533a6c-26e9-4f8b-a92f-23b25149610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best oil model MAE: 100.2080\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best oil model MAE: {-xgb_oil_model.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35b3a1d2-66ff-4dcd-8169-1693a69b6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device='cuda', early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric='mae', feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...),\n",
       " XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device='cuda', early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric='mae', feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gas_model = xgb_gas_model.best_estimator_\n",
    "best_oil_model = xgb_oil_model.best_estimator_\n",
    "best_gas_model, best_oil_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03c2c501-9401-4ea2-bc8c-31d39fb6f11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/label_encoders.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save models\n",
    "joblib.dump(best_gas_model, '../models/best_gas_model.pkl')\n",
    "joblib.dump(best_oil_model, '../models/best_oil_model.pkl')\n",
    "joblib.dump(label_encoders, '../models/label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd7f09-8312-449f-a62a-43ce6f586684",
   "metadata": {},
   "source": [
    "Now that we have our best model parameters, we should train on the full training set and estimate performance using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cec57a2e-179a-42b0-b9c2-33d76f23c8a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have at least 1 validation dataset for early stopping.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbest_gas_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gas_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\training.py:184\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    183\u001b[39m     bst.update(dtrain, iteration=i, fobj=obj)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    187\u001b[39m bst = cb_container.after_training(bst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\callback.py:267\u001b[39m, in \u001b[36mCallbackContainer.after_iteration\u001b[39m\u001b[34m(self, model, epoch, dtrain, evals)\u001b[39m\n\u001b[32m    265\u001b[39m     metric_score = _parse_eval_str(score)\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m ret = \u001b[38;5;28many\u001b[39m(c.after_iteration(model, epoch, \u001b[38;5;28mself\u001b[39m.history) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\callback.py:267\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    265\u001b[39m     metric_score = _parse_eval_str(score)\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m ret = \u001b[38;5;28many\u001b[39m(\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\xgboost\\callback.py:463\u001b[39m, in \u001b[36mEarlyStopping.after_iteration\u001b[39m\u001b[34m(self, model, epoch, evals_log)\u001b[39m\n\u001b[32m    461\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mMust have at least 1 validation dataset for early stopping.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(evals_log.keys()) < \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# Get data name\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data:\n",
      "\u001b[31mValueError\u001b[39m: Must have at least 1 validation dataset for early stopping."
     ]
    }
   ],
   "source": [
    "best_gas_model.fit(X_train, y_gas_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16771943-f590-48ae-aa9b-1bd445b94af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'n_estimators': 800,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 6,\n",
       " 'learning_rate': 0.03,\n",
       " 'colsample_bytree': 1.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_gas_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22dc7c09-186a-4687-9e0e-a3b09aa0a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gas_params = {\n",
    "    'subsample': 0.8,\n",
    "    'n_estimators': 800,\n",
    "    'min_child_weight': 1,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.03,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' if GPU_AVAILABLE else 'cpu',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'eval_metric': 'mae',\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "final_gas_model = xgb.XGBRegressor(**new_gas_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a18958b-3951-4670-ae97-aab698498e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;mae&#x27;, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;mae&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.03</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device='cuda', early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='mae', feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_gas_model.fit(X_train, y_gas_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87d48b10-67d4-4aa8-8f39-3c14ae266f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'n_estimators': 800,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 6,\n",
       " 'learning_rate': 0.03,\n",
       " 'colsample_bytree': 1.0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_oil_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6badc95b-7631-44e1-9a13-2789ab4c6508",
   "metadata": {},
   "source": [
    "Same params for oil we can just run the gas params for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c75b8c89-6074-4574-b097-8ac5aa380a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_oil_model = xgb.XGBRegressor(**new_gas_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "913f82ac-7e7a-43f1-a6fd-9508e5de1fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;mae&#x27;, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;mae&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.03</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device='cuda', early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='mae', feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_oil_model.fit(X_train, y_oil_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "beb47232-0265-486a-92e5-bf4ef32d0631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/final_oil_model.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final_gas_model, '../models/final_gas_model.pkl')\n",
    "joblib.dump(final_oil_model, '../models/final_oil_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81e410e9-6d9f-40ad-9a41-b8ebd32b472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_pred = final_gas_model.predict(X_test)\n",
    "oil_pred = final_oil_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c03c4211-958a-4fb2-a760-b86f61209e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514.4783804691635, 93.31968212236362)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_mae = mean_absolute_error(y_gas_test, gas_pred)\n",
    "oil_mae = mean_absolute_error(y_oil_test, oil_pred)\n",
    "gas_mae, oil_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd94499-04d0-4df8-8f9b-f0edb5b5c215",
   "metadata": {},
   "source": [
    "A little better than the hyperparameter tuning models, which shows that our sampling strategy worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a57d0968-c9c9-4594-a1bf-144c4b0683d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.220877791622806e+16, 1.2086298113880788e+16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_mape = mean_absolute_percentage_error(y_gas_test, gas_pred)\n",
    "oil_mape = mean_absolute_percentage_error(y_oil_test, oil_pred)\n",
    "gas_mape, oil_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057986d8-4825-43e8-8ccb-1523dfaa92b6",
   "metadata": {},
   "source": [
    "These mape values aren't good but are also obviously nonsensical given the MAE. It might be because of zero values or near zero values in the dataset. With the proper libraries, I might implement smape in the future, as it seems to correct for some mape problems, but also has its own and ultimately isn't necessarily important right now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71e77e-0dcf-4d23-9f41-4a0c7eb5c41d",
   "metadata": {},
   "source": [
    "## Making Predictions <a id=\"Pred\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99c54519-fea3-4b7b-a59f-3cf960756783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating forecast grid: 100%|████████████████████████████████████████████████| 399039/399039 [00:40<00:00, 9865.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19951950 entries, 0 to 19951949\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   api_no_10  object        \n",
      " 1   date_prod  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 304.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create complete date range for each well\n",
    "all_apis = joined_data['api_no_10'].unique()\n",
    "date_range = pd.date_range(start='2021-01-01', end='2025-02-28', freq='MS')\n",
    "\n",
    "# Create complete grid\n",
    "forecast_data = []\n",
    "for api in tqdm(all_apis, desc=\"Creating forecast grid\"):\n",
    "    for date in date_range:\n",
    "        forecast_data.append({'api_no_10': api, 'date_prod': date})\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_data)\n",
    "\n",
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ef1f6-86d0-4bc9-b0e5-97b72e00db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with existing data\n",
    "forecast_df = forecast_df.merge(joined_data, on=['api_no_10', 'date_prod'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5535f-4b27-4227-ba33-550c58729118",
   "metadata": {},
   "source": [
    "That simple approach is likely to overload my memory based on recent memory, so let's try this instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c27927c1-3c60-45bb-bbce-463809667071",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10000  # Adjust based on your available RAM\n",
    "\n",
    "merged_chunks = []\n",
    "for i in range(0, len(all_apis), chunk_size):\n",
    "    api_chunk = all_apis[i:i+chunk_size]\n",
    "    forecast_chunk = forecast_df[forecast_df['api_no_10'].isin(api_chunk)]\n",
    "    df_chunk = joined_data[joined_data['api_no_10'].isin(api_chunk)]\n",
    "    merged_chunk = forecast_chunk.merge(df_chunk, on=['api_no_10', 'date_prod'], how='left')\n",
    "    merged_chunks.append(merged_chunk)\n",
    "    del forecast_chunk, df_chunk, merged_chunk  # Free memory\n",
    "\n",
    "# Concatenate all chunks\n",
    "forecast_df = pd.concat(merged_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42510b3b-dca8-47d2-91cd-32782934cf3e",
   "metadata": {},
   "source": [
    "This took a very long time so isn't really recommended on systems like mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "587937b4-473e-4b5a-ab46-97004a1af3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_parquet('../data/forecast_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d89ece2a-e3ca-4995-a828-b1615c1ae6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully loaded joined_data with pandas\n",
      "  Shape: (19951950, 38)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19951950 entries, 0 to 19951949\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   api_no_10                 object        \n",
      " 1   date_prod                 datetime64[ns]\n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             float64       \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            float64       \n",
      " 8   Well_Production_Type      float64       \n",
      " 9   reservoir type            float64       \n",
      " 10  arps model                float64       \n",
      " 11  Production_Status         float64       \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     float64       \n",
      " 17  formation_group           float64       \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          float64       \n",
      " 22  well_generation           float64       \n",
      " 23  well_density_1km          float64       \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 float64       \n",
      " 26  prod_month                float64       \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      " 29  last_year                 float64       \n",
      " 30  last_month                float64       \n",
      " 31  last_gas                  float64       \n",
      " 32  last_oil                  float64       \n",
      " 33  months_since_last         float64       \n",
      " 34  gas_avg_3                 float64       \n",
      " 35  oil_avg_3                 float64       \n",
      " 36  gas_avg_6                 float64       \n",
      " 37  oil_avg_6                 float64       \n",
      "dtypes: datetime64[ns](2), float64(35), object(1)\n",
      "memory usage: 5.6+ GB\n"
     ]
    }
   ],
   "source": [
    "forecast_df = load_parquet_datasets({'joined_data': '../data/forecast_1.parquet'})['joined_data']\n",
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f053763a-10cb-437b-9634-1c9865c10084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing static features from the last known values\n",
    "static_cols = ['lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole',\n",
    "               'basin', 'formation_group', 'horizontal_length', 'measured_depth',\n",
    "               'depth_tvd', 'operator_cluster', 'well_generation', 'well_density_1km',\n",
    "               'nearest_well_distance_km', 'wellbore_type', 'Well_Production_Type',\n",
    "               'reservoir type', 'arps model', 'Production_Status']\n",
    "\n",
    "existing_static_cols = [col for col in static_cols if col in forecast_df.columns]\n",
    "\n",
    "def batch_fill_static_features(df, static_cols, batch_size=10000):\n",
    "    unique_apis = df['api_no_10'].unique()\n",
    "    batches = []\n",
    "    for start in range(0, len(unique_apis), batch_size):\n",
    "        batch_apis = unique_apis[start:start + batch_size]\n",
    "        batch_df = df[df['api_no_10'].isin(batch_apis)].copy()\n",
    "        for col in static_cols:\n",
    "            if col in batch_df.columns:\n",
    "                batch_df[col] = batch_df.groupby('api_no_10')[col].ffill().bfill()\n",
    "        batches.append(batch_df)\n",
    "        del batch_df  # Free memory\n",
    "    result_df = pd.concat(batches, ignore_index=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73da0c73-77a4-4617-83ad-ad683d4d6f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: FORECAST_DF\n",
      "============================================================\n",
      "Shape: (19951950, 38)\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 object          19951950   399039     0.0       %\n",
      "date_prod                 datetime64[ns]  19951950   50         0.0       %\n",
      "gas_monthly               float64         16564703   129580     17.0      %\n",
      "oil_monthly               float64         16564703   38707      17.0      %\n",
      "start_date                datetime64[ns]  16564703   385        17.0      %\n",
      "wellbore_type             float64         19951950   3          0.0       %\n",
      "Quality_Quant             float64         16564703   9          17.0      %\n",
      "Production_Age            float64         16564703   383        17.0      %\n",
      "Well_Production_Type      float64         19951950   4          0.0       %\n",
      "reservoir type            float64         19951950   3          0.0       %\n",
      "arps model                float64         19951950   4          0.0       %\n",
      "Production_Status         float64         19951950   3          0.0       %\n",
      "lat_surface               float64         19951950   378656     0.0       %\n",
      "lon_surface               float64         19951950   385128     0.0       %\n",
      "lat_bottomhole            float64         19951950   382387     0.0       %\n",
      "lon_bottomhole            float64         19951950   386886     0.0       %\n",
      "basin                     float64         19951950   13         0.0       %\n",
      "formation_group           float64         19951950   17         0.0       %\n",
      "horizontal_length         float64         19951950   99702      0.0       %\n",
      "measured_depth            float64         19951950   25850      0.0       %\n",
      "depth_tvd                 float64         19951950   105422     0.0       %\n",
      "operator_cluster          float64         19951950   4          0.0       %\n",
      "well_generation           float64         19951950   17         0.0       %\n",
      "well_density_1km          float64         19951950   730        0.0       %\n",
      "nearest_well_distance_km  float64         19951950   273057     0.0       %\n",
      "prod_year                 float64         16564703   4          17.0      %\n",
      "prod_month                float64         16564703   12         17.0      %\n",
      "month_sin                 float64         16564703   11         17.0      %\n",
      "month_cos                 float64         16564703   11         17.0      %\n",
      "last_year                 float64         16564703   5          17.0      %\n",
      "last_month                float64         16564703   13         17.0      %\n",
      "last_gas                  float64         16564703   128036     17.0      %\n",
      "last_oil                  float64         16564703   38278      17.0      %\n",
      "months_since_last         float64         16564703   43         17.0      %\n",
      "gas_avg_3                 float64         16564703   262000     17.0      %\n",
      "oil_avg_3                 float64         16564703   95299      17.0      %\n",
      "gas_avg_6                 float64         16564703   430300     17.0      %\n",
      "oil_avg_6                 float64         16564703   172912     17.0      %\n",
      "\n",
      "Potential date/time columns: ['date_prod', 'gas_monthly', 'oil_monthly', 'start_date', 'prod_year', 'prod_month', 'month_sin', 'month_cos', 'last_year', 'last_month', 'months_since_last']\n",
      "\n",
      "Coordinate columns: ['lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole']\n"
     ]
    }
   ],
   "source": [
    "forecast_df = batch_fill_static_features(forecast_df, existing_static_cols, batch_size=10000)\n",
    "comprehensive_data_overview({'forecast_df': forecast_df})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff8629-4aa0-4f57-8edb-e904a2f0dbce",
   "metadata": {},
   "source": [
    "start_date and quality_quant are also static, prod age is easy to fill as are prod_year, prod_month, month_sin and month_cos, the rest are a little more complicated and gas and oil are what we are predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4481ad-5344-4092-8d9d-7b62f49f55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_parquet('../data/forecast_2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf5ec5a-5f91-49ed-9031-c370cb697d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19951950 entries, 0 to 19951949\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   api_no_10                 object        \n",
      " 1   date_prod                 datetime64[ns]\n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             float64       \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            float64       \n",
      " 8   Well_Production_Type      float64       \n",
      " 9   reservoir type            float64       \n",
      " 10  arps model                float64       \n",
      " 11  Production_Status         float64       \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     float64       \n",
      " 17  formation_group           float64       \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          float64       \n",
      " 22  well_generation           float64       \n",
      " 23  well_density_1km          float64       \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 float64       \n",
      " 26  prod_month                float64       \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      " 29  last_year                 float64       \n",
      " 30  last_month                float64       \n",
      " 31  last_gas                  float64       \n",
      " 32  last_oil                  float64       \n",
      " 33  months_since_last         float64       \n",
      " 34  gas_avg_3                 float64       \n",
      " 35  oil_avg_3                 float64       \n",
      " 36  gas_avg_6                 float64       \n",
      " 37  oil_avg_6                 float64       \n",
      "dtypes: datetime64[ns](2), float64(35), object(1)\n",
      "memory usage: 5.6+ GB\n"
     ]
    }
   ],
   "source": [
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc7624b-3d67-4cdc-930b-3bbe4c3ef20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         19951950\n",
       "mean     2023-01-15 16:48:00.000002560\n",
       "min                2021-01-01 00:00:00\n",
       "25%                2022-01-01 00:00:00\n",
       "50%                2023-01-16 12:00:00\n",
       "75%                2024-02-01 00:00:00\n",
       "max                2025-02-01 00:00:00\n",
       "Name: date_prod, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df['date_prod'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "666b97f6-4184-4b9b-a53d-3635a65d78e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: FORECAST_DF\n",
      "============================================================\n",
      "Shape: (19951950, 38)\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 object          19951950   399039     0.0       %\n",
      "date_prod                 datetime64[ns]  19951950   50         0.0       %\n",
      "gas_monthly               float64         16564703   129580     17.0      %\n",
      "oil_monthly               float64         16564703   38707      17.0      %\n",
      "start_date                datetime64[ns]  19951950   385        0.0       %\n",
      "wellbore_type             float64         19951950   3          0.0       %\n",
      "Quality_Quant             float64         19951950   9          0.0       %\n",
      "Production_Age            float64         16564703   383        17.0      %\n",
      "Well_Production_Type      float64         19951950   4          0.0       %\n",
      "reservoir type            float64         19951950   3          0.0       %\n",
      "arps model                float64         19951950   4          0.0       %\n",
      "Production_Status         float64         19951950   3          0.0       %\n",
      "lat_surface               float64         19951950   378656     0.0       %\n",
      "lon_surface               float64         19951950   385128     0.0       %\n",
      "lat_bottomhole            float64         19951950   382387     0.0       %\n",
      "lon_bottomhole            float64         19951950   386886     0.0       %\n",
      "basin                     float64         19951950   13         0.0       %\n",
      "formation_group           float64         19951950   17         0.0       %\n",
      "horizontal_length         float64         19951950   99702      0.0       %\n",
      "measured_depth            float64         19951950   25850      0.0       %\n",
      "depth_tvd                 float64         19951950   105422     0.0       %\n",
      "operator_cluster          float64         19951950   4          0.0       %\n",
      "well_generation           float64         19951950   17         0.0       %\n",
      "well_density_1km          float64         19951950   730        0.0       %\n",
      "nearest_well_distance_km  float64         19951950   273057     0.0       %\n",
      "prod_year                 float64         16564703   4          17.0      %\n",
      "prod_month                float64         16564703   12         17.0      %\n",
      "month_sin                 float64         16564703   11         17.0      %\n",
      "month_cos                 float64         16564703   11         17.0      %\n",
      "last_year                 float64         16564703   5          17.0      %\n",
      "last_month                float64         16564703   13         17.0      %\n",
      "last_gas                  float64         16564703   128036     17.0      %\n",
      "last_oil                  float64         16564703   38278      17.0      %\n",
      "months_since_last         float64         16564703   43         17.0      %\n",
      "gas_avg_3                 float64         16564703   262000     17.0      %\n",
      "oil_avg_3                 float64         16564703   95299      17.0      %\n",
      "gas_avg_6                 float64         16564703   430300     17.0      %\n",
      "oil_avg_6                 float64         16564703   172912     17.0      %\n",
      "\n",
      "Potential date/time columns: ['date_prod', 'gas_monthly', 'oil_monthly', 'start_date', 'prod_year', 'prod_month', 'month_sin', 'month_cos', 'last_year', 'last_month', 'months_since_last']\n",
      "\n",
      "Coordinate columns: ['lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole']\n"
     ]
    }
   ],
   "source": [
    "forecast_df['start_date'] = forecast_df.groupby('api_no_10')['start_date'].ffill().bfill()\n",
    "forecast_df['Quality_Quant'] = forecast_df.groupby('api_no_10')['Quality_Quant'].ffill().bfill()\n",
    "comprehensive_data_overview({'forecast_df': forecast_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24feacd3-2789-4031-b75b-8c9868a7f4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: FORECAST_DF\n",
      "============================================================\n",
      "Shape: (19951950, 38)\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 object          19951950   399039     0.0       %\n",
      "date_prod                 datetime64[ns]  19951950   50         0.0       %\n",
      "gas_monthly               float64         16564703   129580     17.0      %\n",
      "oil_monthly               float64         16564703   38707      17.0      %\n",
      "start_date                datetime64[ns]  19951950   385        0.0       %\n",
      "wellbore_type             float64         19951950   3          0.0       %\n",
      "Quality_Quant             float64         19951950   9          0.0       %\n",
      "Production_Age            int32           19951950   386        0.0       %\n",
      "Well_Production_Type      float64         19951950   4          0.0       %\n",
      "reservoir type            float64         19951950   3          0.0       %\n",
      "arps model                float64         19951950   4          0.0       %\n",
      "Production_Status         float64         19951950   3          0.0       %\n",
      "lat_surface               float64         19951950   378656     0.0       %\n",
      "lon_surface               float64         19951950   385128     0.0       %\n",
      "lat_bottomhole            float64         19951950   382387     0.0       %\n",
      "lon_bottomhole            float64         19951950   386886     0.0       %\n",
      "basin                     float64         19951950   13         0.0       %\n",
      "formation_group           float64         19951950   17         0.0       %\n",
      "horizontal_length         float64         19951950   99702      0.0       %\n",
      "measured_depth            float64         19951950   25850      0.0       %\n",
      "depth_tvd                 float64         19951950   105422     0.0       %\n",
      "operator_cluster          float64         19951950   4          0.0       %\n",
      "well_generation           float64         19951950   17         0.0       %\n",
      "well_density_1km          float64         19951950   730        0.0       %\n",
      "nearest_well_distance_km  float64         19951950   273057     0.0       %\n",
      "prod_year                 int32           19951950   5          0.0       %\n",
      "prod_month                int32           19951950   12         0.0       %\n",
      "month_sin                 float64         19951950   11         0.0       %\n",
      "month_cos                 float64         19951950   11         0.0       %\n",
      "last_year                 float64         16564703   5          17.0      %\n",
      "last_month                float64         16564703   13         17.0      %\n",
      "last_gas                  float64         16564703   128036     17.0      %\n",
      "last_oil                  float64         16564703   38278      17.0      %\n",
      "months_since_last         float64         16564703   43         17.0      %\n",
      "gas_avg_3                 float64         16564703   262000     17.0      %\n",
      "oil_avg_3                 float64         16564703   95299      17.0      %\n",
      "gas_avg_6                 float64         16564703   430300     17.0      %\n",
      "oil_avg_6                 float64         16564703   172912     17.0      %\n",
      "\n",
      "Potential date/time columns: ['date_prod', 'gas_monthly', 'oil_monthly', 'start_date', 'prod_year', 'prod_month', 'month_sin', 'month_cos', 'last_year', 'last_month', 'months_since_last']\n",
      "\n",
      "Coordinate columns: ['lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole']\n"
     ]
    }
   ],
   "source": [
    "date_diff = forecast_df['date_prod'] - forecast_df['start_date']\n",
    "forecast_df['Production_Age'] = (date_diff.dt.days / 30.44).round().astype(int) + 1  # +1 so start month = 1\n",
    "    \n",
    "# Handle negative values (data quality issues)\n",
    "forecast_df['Production_Age'] = np.maximum(forecast_df['Production_Age'], 1)\n",
    "\n",
    "forecast_df['prod_year'] = forecast_df['date_prod'].dt.year\n",
    "forecast_df['prod_month'] = forecast_df['date_prod'].dt.month\n",
    "forecast_df['month_sin'] = np.sin(2 * np.pi * forecast_df['prod_month'] / 12)\n",
    "forecast_df['month_cos'] = np.cos(2 * np.pi * forecast_df['prod_month'] / 12)\n",
    "\n",
    "comprehensive_data_overview({'forecast_df': forecast_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "095d9d48-6993-4e59-8e37-5079d172864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_parquet('../data/forecast_3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87f45606-bf9f-47aa-b885-c495bba323e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(df, batch_size):\n",
    "    unique_apis = df['api_no_10'].unique()\n",
    "    for start in range(0, len(unique_apis), batch_size):\n",
    "        batch_apis = unique_apis[start:start + batch_size]\n",
    "        yield df[df['api_no_10'].isin(batch_apis)].copy()\n",
    "\n",
    "def create_backfill_features_batched_skipna(df, batch_size=10000):\n",
    "    print(f\"Processing in batches of {batch_size} wells...\")\n",
    "    processed_batches = []\n",
    "    batch_number = 1\n",
    "    for batch_df in batch_iter(df, batch_size):\n",
    "        print(f\"Processing batch {batch_number} ({batch_df['api_no_10'].nunique()} wells, {len(batch_df)} rows)\")\n",
    "        batch_df = batch_df.sort_values(['api_no_10', 'date_prod'])\n",
    "        for api, group in batch_df.groupby('api_no_10'):\n",
    "            group = group.copy()\n",
    "            # Identify valid (non-missing) production rows\n",
    "            valid_idx = group['gas_monthly'].notna() & group['oil_monthly'].notna()\n",
    "            # Prepare columns for last known values\n",
    "            last_year = np.full(len(group), -1)\n",
    "            last_month = np.full(len(group), -1)\n",
    "            last_gas = np.full(len(group), -1.0)\n",
    "            last_oil = np.full(len(group), -1.0)\n",
    "            months_since_last = np.full(len(group), -1)\n",
    "            last_valid_idx = -1\n",
    "            for i in range(len(group)):\n",
    "                if i > 0 and last_valid_idx != -1:\n",
    "                    last_year[i] = group.iloc[last_valid_idx]['date_prod'].year\n",
    "                    last_month[i] = group.iloc[last_valid_idx]['date_prod'].month\n",
    "                    last_gas[i] = group.iloc[last_valid_idx]['gas_monthly']\n",
    "                    last_oil[i] = group.iloc[last_valid_idx]['oil_monthly']\n",
    "                    months_since_last[i] = int(round((group.iloc[i]['date_prod'] - group.iloc[last_valid_idx]['date_prod']).days / 30.44))\n",
    "                if valid_idx.iloc[i]:\n",
    "                    last_valid_idx = i\n",
    "            group['last_year'] = last_year\n",
    "            group['last_month'] = last_month\n",
    "            group['last_gas'] = last_gas\n",
    "            group['last_oil'] = last_oil\n",
    "            group['months_since_last'] = months_since_last\n",
    "            processed_batches.append(group)\n",
    "        batch_number += 1\n",
    "    result_df = pd.concat(processed_batches).sort_index()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6125ce1f-d31c-4df5-9e83-4ef2aa14e375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing in batches of 10000 wells...\n",
      "Processing batch 1 (10000 wells, 500000 rows)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m forecast_df = \u001b[43mcreate_backfill_features_batched_skipna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m comprehensive_data_overview({\u001b[33m'\u001b[39m\u001b[33mforecast_df\u001b[39m\u001b[33m'\u001b[39m: forecast_df})\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mcreate_backfill_features_batched_skipna\u001b[39m\u001b[34m(df, batch_size)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(group)):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m last_valid_idx != -\u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         last_year[i] = \u001b[43mgroup\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_valid_idx\u001b[49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdate_prod\u001b[39m\u001b[33m'\u001b[39m].year\n\u001b[32m     28\u001b[39m         last_month[i] = group.iloc[last_valid_idx][\u001b[33m'\u001b[39m\u001b[33mdate_prod\u001b[39m\u001b[33m'\u001b[39m].month\n\u001b[32m     29\u001b[39m         last_gas[i] = group.iloc[last_valid_idx][\u001b[33m'\u001b[39m\u001b[33mgas_monthly\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1150\u001b[39m axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m   1152\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m-> \u001b[39m\u001b[32m1153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\indexing.py:1716\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m   1714\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_integer(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\frame.py:3789\u001b[39m, in \u001b[36mDataFrame._ixs\u001b[39m\u001b[34m(self, i, axis)\u001b[39m\n\u001b[32m   3787\u001b[39m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[32m   3788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3789\u001b[39m     new_mgr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3791\u001b[39m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[32m   3792\u001b[39m     copy = \u001b[38;5;28misinstance\u001b[39m(new_mgr.array, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr.array.base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:974\u001b[39m, in \u001b[36mBlockManager.fast_xs\u001b[39m\u001b[34m(self, loc)\u001b[39m\n\u001b[32m    972\u001b[39m     result = np.empty(n, dtype=\u001b[38;5;28mobject\u001b[39m)\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     result = np.empty(n, dtype=dtype)\n\u001b[32m    975\u001b[39m     result = ensure_wrapped_if_datetimelike(result)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "forecast_df = create_backfill_features_batched_skipna(forecast_df, batch_size=10000)\n",
    "comprehensive_data_overview({'forecast_df': forecast_df})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979d04f-664f-4c79-b484-387f9b274a7a",
   "metadata": {},
   "source": [
    "This is too slow, we will need to take an approach of merging and backfilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbdfc634-861e-429f-9dda-c37aeb307ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully loaded joined_data with pandas\n",
      "  Shape: (16564703, 38)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   date_prod                 datetime64[ms]\n",
      " 1   api_no_10                 object        \n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             int32         \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Well_Production_Type      int32         \n",
      " 9   reservoir type            int32         \n",
      " 10  arps model                int32         \n",
      " 11  Production_Status         int32         \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     int32         \n",
      " 17  formation_group           int32         \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          int32         \n",
      " 22  well_generation           int64         \n",
      " 23  well_density_1km          int64         \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 int32         \n",
      " 26  prod_month                int32         \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      " 29  last_year                 int32         \n",
      " 30  last_month                int32         \n",
      " 31  last_gas                  float64       \n",
      " 32  last_oil                  float64       \n",
      " 33  months_since_last         int32         \n",
      " 34  gas_avg_3                 float64       \n",
      " 35  oil_avg_3                 float64       \n",
      " 36  gas_avg_6                 float64       \n",
      " 37  oil_avg_6                 float64       \n",
      "dtypes: datetime64[ms](1), datetime64[ns](1), float64(19), int32(14), int64(2), object(1)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "joined_data = load_parquet_datasets({'joined_data': '../data/preprocess_5.parquet'})['joined_data']\n",
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db564eca-2487-46af-ba1c-17f71e4a0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_and_rolling_cols = [\n",
    "    'api_no_10', 'date_prod',\n",
    "    'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last',\n",
    "    'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6'\n",
    "]\n",
    "bfill_helper = joined_data[last_and_rolling_cols].copy()\n",
    "bfill_helper.to_parquet('../data/forecast_helper_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c19f45-d113-44c6-b2a0-9aa2e928b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded first 1000000 rows of joined_data for inspection\n",
      "  Shape: (1000000, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000000 entries, 0 to 1002295\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count    Dtype         \n",
      "---  ------             --------------    -----         \n",
      " 0   api_no_10          1000000 non-null  object        \n",
      " 1   date_prod          1000000 non-null  datetime64[ms]\n",
      " 2   last_year          1000000 non-null  int32         \n",
      " 3   last_month         1000000 non-null  int32         \n",
      " 4   last_gas           1000000 non-null  float64       \n",
      " 5   last_oil           1000000 non-null  float64       \n",
      " 6   months_since_last  1000000 non-null  int32         \n",
      " 7   gas_avg_3          1000000 non-null  float64       \n",
      " 8   oil_avg_3          1000000 non-null  float64       \n",
      " 9   gas_avg_6          1000000 non-null  float64       \n",
      " 10  oil_avg_6          1000000 non-null  float64       \n",
      "dtypes: datetime64[ms](1), float64(6), int32(3), object(1)\n",
      "memory usage: 80.1+ MB\n"
     ]
    }
   ],
   "source": [
    "bfill_helper = load_parquet_datasets({'joined_data': '../data/forecast_helper_1.parquet'})['joined_data']\n",
    "bfill_helper.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c36628-2a87-4ada-ad8e-30c95a72ff66",
   "metadata": {},
   "source": [
    "I have now implemented the dask library in the \"load_parquet_datasets\" function to prevent my computer from continually freezing when I load forecast_df, hopefully it helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48c483f-a850-4e21-97b3-522457a8cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded joined_data as Dask DataFrame\n",
      "  Shape: (<dask_expr.expr.Scalar: expr=ReadParquetFSSpec(124b6ae).size() // 38, dtype=int32>, 38)\n",
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 38 entries, api_no_10 to oil_avg_6\n",
      "dtypes: datetime64[ns](2), float64(32), int32(3), string(1)"
     ]
    }
   ],
   "source": [
    "forecast_df = load_parquet_datasets({'joined_data': '../data/forecast_3.parquet'}, use_dask=True)['joined_data']\n",
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc9a050-093f-4b58-b263-a54e540546e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def batch_merge_and_backfill_dask(forecast_df, df_last, cols_to_fill, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Batch merge and backfill for Dask DataFrame (forecast_df) and pandas DataFrame (df_last).\n",
    "    \"\"\"\n",
    "    # Get unique APIs as a pandas array (efficient, as Dask only computes the column)\n",
    "    unique_apis = forecast_df['api_no_10'].drop_duplicates().compute().values\n",
    "    merged_batches = []\n",
    "    for start in range(0, len(unique_apis), batch_size):\n",
    "        batch_apis = unique_apis[start:start + batch_size]\n",
    "        # Subset forecast_df for this batch and compute to pandas\n",
    "        forecast_batch = forecast_df[forecast_df['api_no_10'].isin(batch_apis)].compute()\n",
    "        last_batch = df_last[df_last['api_no_10'].isin(batch_apis)].copy()\n",
    "        # Sort by api_no_10 and date_prod\n",
    "        forecast_batch = forecast_batch.sort_values(['api_no_10', 'date_prod'])\n",
    "        last_batch = last_batch.sort_values(['api_no_10', 'date_prod'])\n",
    "        # Merge\n",
    "        merged = forecast_batch.merge(\n",
    "            last_batch,\n",
    "            on=['api_no_10', 'date_prod'],\n",
    "            how='left',\n",
    "            suffixes=('', '_fromlast')\n",
    "        )\n",
    "        # For each feature, fill NAs by backfilling within each well\n",
    "        for col in cols_to_fill:\n",
    "            merged[col] = merged[col].combine_first(merged[f\"{col}_fromlast\"])\n",
    "            # Backfill (future to past) within each well\n",
    "            merged[col] = merged.groupby('api_no_10')[col].bfill()\n",
    "            # Forward fill to ensure all nulls are filled (optional, for edge cases)\n",
    "            merged[col] = merged.groupby('api_no_10')[col].ffill()\n",
    "            merged = merged.drop(columns=[f\"{col}_fromlast\"])\n",
    "        merged_batches.append(merged)\n",
    "    # Concatenate all batches (as pandas DataFrame)\n",
    "    result_df = pd.concat(merged_batches, ignore_index=True)\n",
    "    # Optionally, convert back to Dask DataFrame for further processing\n",
    "    # result_ddf = dd.from_pandas(result_df, npartitions=forecast_df.npartitions)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f389e3d3-3f73-41c8-9a19-1d61b4eb34f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_merge_and_backfill' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[32m      2\u001b[39m cols_to_fill = [\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlast_year\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlast_month\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlast_gas\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlast_oil\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmonths_since_last\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgas_avg_3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33moil_avg_3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgas_avg_6\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33moil_avg_6\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m forecast_df = \u001b[43mbatch_merge_and_backfill\u001b[49m(forecast_df, bfill_helper, cols_to_fill)\n",
      "\u001b[31mNameError\u001b[39m: name 'batch_merge_and_backfill' is not defined"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "cols_to_fill = [\n",
    "    'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last',\n",
    "    'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6'\n",
    "]\n",
    "forecast_df = batch_merge_and_backfill_dask(forecast_df, bfill_helper, cols_to_fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f792b-c45d-485e-8f28-beb1557fba70",
   "metadata": {},
   "source": [
    "Even this function is overloading my memory, it froze my computer which wasn't saved here. Let's try another even more memory conscious version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f6372d-f564-414c-aeb6-b05d74ff924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import gc\n",
    "\n",
    "def batch_merge_and_backfill_dask(\n",
    "    forecast_df, df_last, cols_to_fill, batch_size=10000, \n",
    "    write_batches_to_disk=False, batch_output_prefix=\"batch_result\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Memory-efficient batch merge and backfill for Dask DataFrame (forecast_df) \n",
    "    and pandas DataFrame (df_last).\n",
    "    Provides progress logging for batches and APIs.\n",
    "    \"\"\"\n",
    "    unique_apis = forecast_df['api_no_10'].drop_duplicates().compute().values\n",
    "    total_apis = len(unique_apis)\n",
    "    num_batches = (total_apis + batch_size - 1) // batch_size  # ceil div\n",
    "\n",
    "    print(f\"✅ Total unique APIs: {total_apis}\")\n",
    "    print(f\"✅ Batch size: {batch_size}\")\n",
    "    print(f\"✅ Total batches: {num_batches}\")\n",
    "\n",
    "    batch_filepaths = []\n",
    "    merged_batches = []\n",
    "\n",
    "    for batch_num, start in enumerate(range(0, total_apis, batch_size), start=1):\n",
    "        end = min(start + batch_size, total_apis)\n",
    "        batch_apis = unique_apis[start:end]\n",
    "\n",
    "        print(f\"🔹 Processing batch {batch_num}/{num_batches} ({len(batch_apis)} APIs)...\")\n",
    "\n",
    "        # Subset and load only this batch into pandas\n",
    "        forecast_batch = forecast_df[forecast_df['api_no_10'].isin(batch_apis)].compute()\n",
    "        last_batch = df_last[df_last['api_no_10'].isin(batch_apis)].copy()\n",
    "\n",
    "        forecast_batch = forecast_batch.sort_values(['api_no_10', 'date_prod'])\n",
    "        last_batch = last_batch.sort_values(['api_no_10', 'date_prod'])\n",
    "\n",
    "        # Merge\n",
    "        merged = forecast_batch.merge(\n",
    "            last_batch,\n",
    "            on=['api_no_10', 'date_prod'],\n",
    "            how='left',\n",
    "            suffixes=('', '_fromlast')\n",
    "        )\n",
    "\n",
    "        # Backfill and forward fill for each feature\n",
    "        for col in cols_to_fill:\n",
    "            merged[col] = merged[col].combine_first(merged[f\"{col}_fromlast\"])\n",
    "            merged[col] = merged.groupby('api_no_10')[col].bfill()\n",
    "            merged[col] = merged.groupby('api_no_10')[col].ffill()\n",
    "            merged = merged.drop(columns=[f\"{col}_fromlast\"])\n",
    "\n",
    "        if write_batches_to_disk:\n",
    "            filepath = f\"{batch_output_prefix}_{batch_num}.parquet\"\n",
    "            merged.to_parquet(filepath, index=False)\n",
    "            batch_filepaths.append(filepath)\n",
    "            print(f\"✅ Batch {batch_num} written to {filepath}\")\n",
    "            del merged\n",
    "        else:\n",
    "            merged_batches.append(merged)\n",
    "            print(f\"✅ Batch {batch_num} completed and kept in memory.\")\n",
    "\n",
    "        del forecast_batch, last_batch\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ All {num_batches} batches processed.\")\n",
    "\n",
    "    if write_batches_to_disk:\n",
    "        print(f\"🔄 Combining {len(batch_filepaths)} batch files into Dask DataFrame...\")\n",
    "        result_ddf = dd.read_parquet(batch_filepaths)\n",
    "        return result_ddf\n",
    "    else:\n",
    "        print(f\"🔄 Concatenating {len(merged_batches)} batches into final DataFrame...\")\n",
    "        result_df = pd.concat(merged_batches, ignore_index=True)\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd71d9f-3b52-4eab-b944-83c87f5745f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fill = [\n",
    "    'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last',\n",
    "    'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6'\n",
    "]\n",
    "forecast_df = batch_merge_and_backfill_dask(forecast_df, bfill_helper, cols_to_fill, batch_size=5000)\n",
    "# trying batch size of 5000 since 10000 still froze my machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ffa891-350f-4c49-b09b-efd71920ab13",
   "metadata": {},
   "source": [
    "Batch size of 5000 still did not work, it did not even get past 1 batch before freezing. I'll try much smaller just to see if I can get it to work at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6211c-2814-42ca-8c9e-5bba01b97438",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fill = [\n",
    "    'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last',\n",
    "    'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6'\n",
    "]\n",
    "forecast_df = batch_merge_and_backfill_dask(forecast_df, bfill_helper, cols_to_fill, batch_size=100)\n",
    "# trying batch size of 100 to check if it works at all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527e714-aa8e-4e82-8bb6-5c467b9c5fd4",
   "metadata": {},
   "source": [
    "It got through one batch (out of about 4000, quite slowly) and then already froze on the 2nd, so something is definitely wrong with the implementation in terms of memory handling at least\n",
    "\n",
    "I'm going to save to disk while using dask and compute/use only the needed columns in the forecast_batch to save a lot of time in computation and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50112e9-ddf1-4e4c-a75e-251c3ff61a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import gc\n",
    "\n",
    "def batch_merge_and_backfill_dask(\n",
    "    forecast_df, df_last, cols_to_fill, batch_size=10000, \n",
    "    write_batches_to_disk=False, batch_output_prefix=\"batch_result\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Memory-efficient batch merge and backfill for Dask DataFrame (forecast_df) \n",
    "    and pandas DataFrame (df_last).\n",
    "    Provides progress logging for batches and APIs.\n",
    "    \"\"\"\n",
    "    columns_needed = ['api_no_10', 'date_prod'] + cols_to_fill\n",
    "    unique_apis = forecast_df['api_no_10'].drop_duplicates().compute().values\n",
    "    total_apis = len(unique_apis)\n",
    "    num_batches = (total_apis + batch_size - 1) // batch_size  # ceil div\n",
    "\n",
    "    print(f\"✅ Total unique APIs: {total_apis}\")\n",
    "    print(f\"✅ Batch size: {batch_size}\")\n",
    "    print(f\"✅ Total batches: {num_batches}\")\n",
    "\n",
    "    batch_filepaths = []\n",
    "    merged_batches = []\n",
    "\n",
    "    for batch_num, start in enumerate(range(0, total_apis, batch_size), start=1):\n",
    "        end = min(start + batch_size, total_apis)\n",
    "        batch_apis = unique_apis[start:end]\n",
    "\n",
    "        print(f\"🔹 Processing batch {batch_num}/{num_batches} ({len(batch_apis)} APIs)...\")\n",
    "\n",
    "        # Subset and load only this batch into pandas\n",
    "        forecast_batch = forecast_df[forecast_df['api_no_10'].isin(batch_apis)][columns_needed].compute()\n",
    "        last_batch = df_last[df_last['api_no_10'].isin(batch_apis)].copy()\n",
    "\n",
    "        forecast_batch = forecast_batch.sort_values(['api_no_10', 'date_prod'])\n",
    "        last_batch = last_batch.sort_values(['api_no_10', 'date_prod'])\n",
    "\n",
    "        # Merge\n",
    "        merged = forecast_batch.merge(\n",
    "            last_batch,\n",
    "            on=['api_no_10', 'date_prod'],\n",
    "            how='left',\n",
    "            suffixes=('', '_fromlast')\n",
    "        )\n",
    "\n",
    "        # Backfill and forward fill for each feature\n",
    "        for col in cols_to_fill:\n",
    "            merged[col] = merged[col].combine_first(merged[f\"{col}_fromlast\"])\n",
    "            merged[col] = merged.groupby('api_no_10')[col].bfill()\n",
    "            merged[col] = merged.groupby('api_no_10')[col].ffill()\n",
    "            merged = merged.drop(columns=[f\"{col}_fromlast\"])\n",
    "\n",
    "        if write_batches_to_disk:\n",
    "            filepath = f\"../batch_data/{batch_output_prefix}_{batch_num}.parquet\"\n",
    "            merged.to_parquet(filepath, index=False)\n",
    "            batch_filepaths.append(filepath)\n",
    "            print(f\"✅ Batch {batch_num} written to {filepath}\")\n",
    "            del merged\n",
    "        else:\n",
    "            merged_batches.append(merged)\n",
    "            print(f\"✅ Batch {batch_num} completed and kept in memory.\")\n",
    "\n",
    "        del forecast_batch, last_batch\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ All {num_batches} batches processed.\")\n",
    "\n",
    "    if write_batches_to_disk:\n",
    "        print(f\"🔄 Combining {len(batch_filepaths)} batch files into Dask DataFrame...\")\n",
    "        result_ddf = dd.read_parquet(batch_filepaths)\n",
    "        return result_ddf\n",
    "    else:\n",
    "        print(f\"🔄 Concatenating {len(merged_batches)} batches into final DataFrame...\")\n",
    "        result_df = pd.concat(merged_batches, ignore_index=True)\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a4fc2a-3335-4924-b13b-0f4426ca7a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total unique APIs: 399039\n",
      "✅ Batch size: 1000\n",
      "✅ Total batches: 400\n",
      "🔹 Processing batch 1/400 (1000 APIs)...\n",
      "✅ Batch 1 completed and kept in memory.\n",
      "🔹 Processing batch 2/400 (1000 APIs)...\n",
      "✅ Batch 2 completed and kept in memory.\n",
      "🔹 Processing batch 3/400 (1000 APIs)...\n",
      "✅ Batch 3 completed and kept in memory.\n",
      "🔹 Processing batch 4/400 (1000 APIs)...\n",
      "✅ Batch 4 completed and kept in memory.\n",
      "🔹 Processing batch 5/400 (1000 APIs)...\n",
      "✅ Batch 5 completed and kept in memory.\n",
      "🔹 Processing batch 6/400 (1000 APIs)...\n",
      "✅ Batch 6 completed and kept in memory.\n",
      "🔹 Processing batch 7/400 (1000 APIs)...\n",
      "✅ Batch 7 completed and kept in memory.\n",
      "🔹 Processing batch 8/400 (1000 APIs)...\n",
      "✅ Batch 8 completed and kept in memory.\n",
      "🔹 Processing batch 9/400 (1000 APIs)...\n",
      "✅ Batch 9 completed and kept in memory.\n",
      "🔹 Processing batch 10/400 (1000 APIs)...\n",
      "✅ Batch 10 completed and kept in memory.\n",
      "🔹 Processing batch 11/400 (1000 APIs)...\n",
      "✅ Batch 11 completed and kept in memory.\n",
      "🔹 Processing batch 12/400 (1000 APIs)...\n",
      "✅ Batch 12 completed and kept in memory.\n",
      "🔹 Processing batch 13/400 (1000 APIs)...\n",
      "✅ Batch 13 completed and kept in memory.\n",
      "🔹 Processing batch 14/400 (1000 APIs)...\n",
      "✅ Batch 14 completed and kept in memory.\n",
      "🔹 Processing batch 15/400 (1000 APIs)...\n",
      "✅ Batch 15 completed and kept in memory.\n",
      "🔹 Processing batch 16/400 (1000 APIs)...\n",
      "✅ Batch 16 completed and kept in memory.\n",
      "🔹 Processing batch 17/400 (1000 APIs)...\n",
      "✅ Batch 17 completed and kept in memory.\n",
      "🔹 Processing batch 18/400 (1000 APIs)...\n",
      "✅ Batch 18 completed and kept in memory.\n",
      "🔹 Processing batch 19/400 (1000 APIs)...\n",
      "✅ Batch 19 completed and kept in memory.\n",
      "🔹 Processing batch 20/400 (1000 APIs)...\n",
      "✅ Batch 20 completed and kept in memory.\n",
      "🔹 Processing batch 21/400 (1000 APIs)...\n",
      "✅ Batch 21 completed and kept in memory.\n",
      "🔹 Processing batch 22/400 (1000 APIs)...\n",
      "✅ Batch 22 completed and kept in memory.\n",
      "🔹 Processing batch 23/400 (1000 APIs)...\n",
      "✅ Batch 23 completed and kept in memory.\n",
      "🔹 Processing batch 24/400 (1000 APIs)...\n",
      "✅ Batch 24 completed and kept in memory.\n",
      "🔹 Processing batch 25/400 (1000 APIs)...\n",
      "✅ Batch 25 completed and kept in memory.\n",
      "🔹 Processing batch 26/400 (1000 APIs)...\n",
      "✅ Batch 26 completed and kept in memory.\n",
      "🔹 Processing batch 27/400 (1000 APIs)...\n",
      "✅ Batch 27 completed and kept in memory.\n",
      "🔹 Processing batch 28/400 (1000 APIs)...\n",
      "✅ Batch 28 completed and kept in memory.\n",
      "🔹 Processing batch 29/400 (1000 APIs)...\n",
      "✅ Batch 29 completed and kept in memory.\n",
      "🔹 Processing batch 30/400 (1000 APIs)...\n",
      "✅ Batch 30 completed and kept in memory.\n",
      "🔹 Processing batch 31/400 (1000 APIs)...\n",
      "✅ Batch 31 completed and kept in memory.\n",
      "🔹 Processing batch 32/400 (1000 APIs)...\n",
      "✅ Batch 32 completed and kept in memory.\n",
      "🔹 Processing batch 33/400 (1000 APIs)...\n",
      "✅ Batch 33 completed and kept in memory.\n",
      "🔹 Processing batch 34/400 (1000 APIs)...\n",
      "✅ Batch 34 completed and kept in memory.\n",
      "🔹 Processing batch 35/400 (1000 APIs)...\n",
      "✅ Batch 35 completed and kept in memory.\n",
      "🔹 Processing batch 36/400 (1000 APIs)...\n",
      "✅ Batch 36 completed and kept in memory.\n",
      "🔹 Processing batch 37/400 (1000 APIs)...\n",
      "✅ Batch 37 completed and kept in memory.\n",
      "🔹 Processing batch 38/400 (1000 APIs)...\n",
      "✅ Batch 38 completed and kept in memory.\n",
      "🔹 Processing batch 39/400 (1000 APIs)...\n",
      "✅ Batch 39 completed and kept in memory.\n",
      "🔹 Processing batch 40/400 (1000 APIs)...\n",
      "✅ Batch 40 completed and kept in memory.\n",
      "🔹 Processing batch 41/400 (1000 APIs)...\n",
      "✅ Batch 41 completed and kept in memory.\n",
      "🔹 Processing batch 42/400 (1000 APIs)...\n",
      "✅ Batch 42 completed and kept in memory.\n",
      "🔹 Processing batch 43/400 (1000 APIs)...\n",
      "✅ Batch 43 completed and kept in memory.\n",
      "🔹 Processing batch 44/400 (1000 APIs)...\n",
      "✅ Batch 44 completed and kept in memory.\n",
      "🔹 Processing batch 45/400 (1000 APIs)...\n",
      "✅ Batch 45 completed and kept in memory.\n",
      "🔹 Processing batch 46/400 (1000 APIs)...\n",
      "✅ Batch 46 completed and kept in memory.\n",
      "🔹 Processing batch 47/400 (1000 APIs)...\n",
      "✅ Batch 47 completed and kept in memory.\n",
      "🔹 Processing batch 48/400 (1000 APIs)...\n",
      "✅ Batch 48 completed and kept in memory.\n",
      "🔹 Processing batch 49/400 (1000 APIs)...\n",
      "✅ Batch 49 completed and kept in memory.\n",
      "🔹 Processing batch 50/400 (1000 APIs)...\n",
      "✅ Batch 50 completed and kept in memory.\n",
      "🔹 Processing batch 51/400 (1000 APIs)...\n",
      "✅ Batch 51 completed and kept in memory.\n",
      "🔹 Processing batch 52/400 (1000 APIs)...\n",
      "✅ Batch 52 completed and kept in memory.\n",
      "🔹 Processing batch 53/400 (1000 APIs)...\n",
      "✅ Batch 53 completed and kept in memory.\n",
      "🔹 Processing batch 54/400 (1000 APIs)...\n",
      "✅ Batch 54 completed and kept in memory.\n",
      "🔹 Processing batch 55/400 (1000 APIs)...\n",
      "✅ Batch 55 completed and kept in memory.\n",
      "🔹 Processing batch 56/400 (1000 APIs)...\n",
      "✅ Batch 56 completed and kept in memory.\n",
      "🔹 Processing batch 57/400 (1000 APIs)...\n",
      "✅ Batch 57 completed and kept in memory.\n",
      "🔹 Processing batch 58/400 (1000 APIs)...\n",
      "✅ Batch 58 completed and kept in memory.\n",
      "🔹 Processing batch 59/400 (1000 APIs)...\n",
      "✅ Batch 59 completed and kept in memory.\n",
      "🔹 Processing batch 60/400 (1000 APIs)...\n",
      "✅ Batch 60 completed and kept in memory.\n",
      "🔹 Processing batch 61/400 (1000 APIs)...\n",
      "✅ Batch 61 completed and kept in memory.\n",
      "🔹 Processing batch 62/400 (1000 APIs)...\n",
      "✅ Batch 62 completed and kept in memory.\n",
      "🔹 Processing batch 63/400 (1000 APIs)...\n",
      "✅ Batch 63 completed and kept in memory.\n",
      "🔹 Processing batch 64/400 (1000 APIs)...\n",
      "✅ Batch 64 completed and kept in memory.\n",
      "🔹 Processing batch 65/400 (1000 APIs)...\n",
      "✅ Batch 65 completed and kept in memory.\n",
      "🔹 Processing batch 66/400 (1000 APIs)...\n",
      "✅ Batch 66 completed and kept in memory.\n",
      "🔹 Processing batch 67/400 (1000 APIs)...\n",
      "✅ Batch 67 completed and kept in memory.\n",
      "🔹 Processing batch 68/400 (1000 APIs)...\n",
      "✅ Batch 68 completed and kept in memory.\n",
      "🔹 Processing batch 69/400 (1000 APIs)...\n",
      "✅ Batch 69 completed and kept in memory.\n",
      "🔹 Processing batch 70/400 (1000 APIs)...\n",
      "✅ Batch 70 completed and kept in memory.\n",
      "🔹 Processing batch 71/400 (1000 APIs)...\n",
      "✅ Batch 71 completed and kept in memory.\n",
      "🔹 Processing batch 72/400 (1000 APIs)...\n",
      "✅ Batch 72 completed and kept in memory.\n",
      "🔹 Processing batch 73/400 (1000 APIs)...\n",
      "✅ Batch 73 completed and kept in memory.\n",
      "🔹 Processing batch 74/400 (1000 APIs)...\n",
      "✅ Batch 74 completed and kept in memory.\n",
      "🔹 Processing batch 75/400 (1000 APIs)...\n",
      "✅ Batch 75 completed and kept in memory.\n",
      "🔹 Processing batch 76/400 (1000 APIs)...\n",
      "✅ Batch 76 completed and kept in memory.\n",
      "🔹 Processing batch 77/400 (1000 APIs)...\n",
      "✅ Batch 77 completed and kept in memory.\n",
      "🔹 Processing batch 78/400 (1000 APIs)...\n",
      "✅ Batch 78 completed and kept in memory.\n",
      "🔹 Processing batch 79/400 (1000 APIs)...\n",
      "✅ Batch 79 completed and kept in memory.\n",
      "🔹 Processing batch 80/400 (1000 APIs)...\n",
      "✅ Batch 80 completed and kept in memory.\n",
      "🔹 Processing batch 81/400 (1000 APIs)...\n",
      "✅ Batch 81 completed and kept in memory.\n",
      "🔹 Processing batch 82/400 (1000 APIs)...\n",
      "✅ Batch 82 completed and kept in memory.\n",
      "🔹 Processing batch 83/400 (1000 APIs)...\n",
      "✅ Batch 83 completed and kept in memory.\n",
      "🔹 Processing batch 84/400 (1000 APIs)...\n",
      "✅ Batch 84 completed and kept in memory.\n",
      "🔹 Processing batch 85/400 (1000 APIs)...\n",
      "✅ Batch 85 completed and kept in memory.\n",
      "🔹 Processing batch 86/400 (1000 APIs)...\n",
      "✅ Batch 86 completed and kept in memory.\n",
      "🔹 Processing batch 87/400 (1000 APIs)...\n",
      "✅ Batch 87 completed and kept in memory.\n",
      "🔹 Processing batch 88/400 (1000 APIs)...\n",
      "✅ Batch 88 completed and kept in memory.\n",
      "🔹 Processing batch 89/400 (1000 APIs)...\n",
      "✅ Batch 89 completed and kept in memory.\n",
      "🔹 Processing batch 90/400 (1000 APIs)...\n",
      "✅ Batch 90 completed and kept in memory.\n",
      "🔹 Processing batch 91/400 (1000 APIs)...\n",
      "✅ Batch 91 completed and kept in memory.\n",
      "🔹 Processing batch 92/400 (1000 APIs)...\n",
      "✅ Batch 92 completed and kept in memory.\n",
      "🔹 Processing batch 93/400 (1000 APIs)...\n",
      "✅ Batch 93 completed and kept in memory.\n",
      "🔹 Processing batch 94/400 (1000 APIs)...\n",
      "✅ Batch 94 completed and kept in memory.\n",
      "🔹 Processing batch 95/400 (1000 APIs)...\n",
      "✅ Batch 95 completed and kept in memory.\n",
      "🔹 Processing batch 96/400 (1000 APIs)...\n",
      "✅ Batch 96 completed and kept in memory.\n",
      "🔹 Processing batch 97/400 (1000 APIs)...\n",
      "✅ Batch 97 completed and kept in memory.\n",
      "🔹 Processing batch 98/400 (1000 APIs)...\n",
      "✅ Batch 98 completed and kept in memory.\n",
      "🔹 Processing batch 99/400 (1000 APIs)...\n",
      "✅ Batch 99 completed and kept in memory.\n",
      "🔹 Processing batch 100/400 (1000 APIs)...\n",
      "✅ Batch 100 completed and kept in memory.\n",
      "🔹 Processing batch 101/400 (1000 APIs)...\n",
      "✅ Batch 101 completed and kept in memory.\n",
      "🔹 Processing batch 102/400 (1000 APIs)...\n",
      "✅ Batch 102 completed and kept in memory.\n",
      "🔹 Processing batch 103/400 (1000 APIs)...\n",
      "✅ Batch 103 completed and kept in memory.\n",
      "🔹 Processing batch 104/400 (1000 APIs)...\n",
      "✅ Batch 104 completed and kept in memory.\n",
      "🔹 Processing batch 105/400 (1000 APIs)...\n",
      "✅ Batch 105 completed and kept in memory.\n",
      "🔹 Processing batch 106/400 (1000 APIs)...\n",
      "✅ Batch 106 completed and kept in memory.\n",
      "🔹 Processing batch 107/400 (1000 APIs)...\n",
      "✅ Batch 107 completed and kept in memory.\n",
      "🔹 Processing batch 108/400 (1000 APIs)...\n",
      "✅ Batch 108 completed and kept in memory.\n",
      "🔹 Processing batch 109/400 (1000 APIs)...\n",
      "✅ Batch 109 completed and kept in memory.\n",
      "🔹 Processing batch 110/400 (1000 APIs)...\n",
      "✅ Batch 110 completed and kept in memory.\n",
      "🔹 Processing batch 111/400 (1000 APIs)...\n",
      "✅ Batch 111 completed and kept in memory.\n",
      "🔹 Processing batch 112/400 (1000 APIs)...\n",
      "✅ Batch 112 completed and kept in memory.\n",
      "🔹 Processing batch 113/400 (1000 APIs)...\n",
      "✅ Batch 113 completed and kept in memory.\n",
      "🔹 Processing batch 114/400 (1000 APIs)...\n",
      "✅ Batch 114 completed and kept in memory.\n",
      "🔹 Processing batch 115/400 (1000 APIs)...\n",
      "✅ Batch 115 completed and kept in memory.\n",
      "🔹 Processing batch 116/400 (1000 APIs)...\n",
      "✅ Batch 116 completed and kept in memory.\n",
      "🔹 Processing batch 117/400 (1000 APIs)...\n",
      "✅ Batch 117 completed and kept in memory.\n",
      "🔹 Processing batch 118/400 (1000 APIs)...\n",
      "✅ Batch 118 completed and kept in memory.\n",
      "🔹 Processing batch 119/400 (1000 APIs)...\n",
      "✅ Batch 119 completed and kept in memory.\n",
      "🔹 Processing batch 120/400 (1000 APIs)...\n",
      "✅ Batch 120 completed and kept in memory.\n",
      "🔹 Processing batch 121/400 (1000 APIs)...\n",
      "✅ Batch 121 completed and kept in memory.\n",
      "🔹 Processing batch 122/400 (1000 APIs)...\n",
      "✅ Batch 122 completed and kept in memory.\n",
      "🔹 Processing batch 123/400 (1000 APIs)...\n",
      "✅ Batch 123 completed and kept in memory.\n",
      "🔹 Processing batch 124/400 (1000 APIs)...\n",
      "✅ Batch 124 completed and kept in memory.\n",
      "🔹 Processing batch 125/400 (1000 APIs)...\n",
      "✅ Batch 125 completed and kept in memory.\n",
      "🔹 Processing batch 126/400 (1000 APIs)...\n",
      "✅ Batch 126 completed and kept in memory.\n",
      "🔹 Processing batch 127/400 (1000 APIs)...\n",
      "✅ Batch 127 completed and kept in memory.\n",
      "🔹 Processing batch 128/400 (1000 APIs)...\n",
      "✅ Batch 128 completed and kept in memory.\n",
      "🔹 Processing batch 129/400 (1000 APIs)...\n",
      "✅ Batch 129 completed and kept in memory.\n",
      "🔹 Processing batch 130/400 (1000 APIs)...\n",
      "✅ Batch 130 completed and kept in memory.\n",
      "🔹 Processing batch 131/400 (1000 APIs)...\n",
      "✅ Batch 131 completed and kept in memory.\n",
      "🔹 Processing batch 132/400 (1000 APIs)...\n",
      "✅ Batch 132 completed and kept in memory.\n",
      "🔹 Processing batch 133/400 (1000 APIs)...\n",
      "✅ Batch 133 completed and kept in memory.\n",
      "🔹 Processing batch 134/400 (1000 APIs)...\n",
      "✅ Batch 134 completed and kept in memory.\n",
      "🔹 Processing batch 135/400 (1000 APIs)...\n",
      "✅ Batch 135 completed and kept in memory.\n",
      "🔹 Processing batch 136/400 (1000 APIs)...\n",
      "✅ Batch 136 completed and kept in memory.\n",
      "🔹 Processing batch 137/400 (1000 APIs)...\n",
      "✅ Batch 137 completed and kept in memory.\n",
      "🔹 Processing batch 138/400 (1000 APIs)...\n",
      "✅ Batch 138 completed and kept in memory.\n",
      "🔹 Processing batch 139/400 (1000 APIs)...\n",
      "✅ Batch 139 completed and kept in memory.\n",
      "🔹 Processing batch 140/400 (1000 APIs)...\n",
      "✅ Batch 140 completed and kept in memory.\n",
      "🔹 Processing batch 141/400 (1000 APIs)...\n",
      "✅ Batch 141 completed and kept in memory.\n",
      "🔹 Processing batch 142/400 (1000 APIs)...\n",
      "✅ Batch 142 completed and kept in memory.\n",
      "🔹 Processing batch 143/400 (1000 APIs)...\n",
      "✅ Batch 143 completed and kept in memory.\n",
      "🔹 Processing batch 144/400 (1000 APIs)...\n",
      "✅ Batch 144 completed and kept in memory.\n",
      "🔹 Processing batch 145/400 (1000 APIs)...\n",
      "✅ Batch 145 completed and kept in memory.\n",
      "🔹 Processing batch 146/400 (1000 APIs)...\n",
      "✅ Batch 146 completed and kept in memory.\n",
      "🔹 Processing batch 147/400 (1000 APIs)...\n",
      "✅ Batch 147 completed and kept in memory.\n",
      "🔹 Processing batch 148/400 (1000 APIs)...\n",
      "✅ Batch 148 completed and kept in memory.\n",
      "🔹 Processing batch 149/400 (1000 APIs)...\n",
      "✅ Batch 149 completed and kept in memory.\n",
      "🔹 Processing batch 150/400 (1000 APIs)...\n",
      "✅ Batch 150 completed and kept in memory.\n",
      "🔹 Processing batch 151/400 (1000 APIs)...\n",
      "✅ Batch 151 completed and kept in memory.\n",
      "🔹 Processing batch 152/400 (1000 APIs)...\n",
      "✅ Batch 152 completed and kept in memory.\n",
      "🔹 Processing batch 153/400 (1000 APIs)...\n",
      "✅ Batch 153 completed and kept in memory.\n",
      "🔹 Processing batch 154/400 (1000 APIs)...\n",
      "✅ Batch 154 completed and kept in memory.\n",
      "🔹 Processing batch 155/400 (1000 APIs)...\n",
      "✅ Batch 155 completed and kept in memory.\n",
      "🔹 Processing batch 156/400 (1000 APIs)...\n",
      "✅ Batch 156 completed and kept in memory.\n",
      "🔹 Processing batch 157/400 (1000 APIs)...\n",
      "✅ Batch 157 completed and kept in memory.\n",
      "🔹 Processing batch 158/400 (1000 APIs)...\n",
      "✅ Batch 158 completed and kept in memory.\n",
      "🔹 Processing batch 159/400 (1000 APIs)...\n",
      "✅ Batch 159 completed and kept in memory.\n",
      "🔹 Processing batch 160/400 (1000 APIs)...\n",
      "✅ Batch 160 completed and kept in memory.\n",
      "🔹 Processing batch 161/400 (1000 APIs)...\n",
      "✅ Batch 161 completed and kept in memory.\n",
      "🔹 Processing batch 162/400 (1000 APIs)...\n",
      "✅ Batch 162 completed and kept in memory.\n",
      "🔹 Processing batch 163/400 (1000 APIs)...\n",
      "✅ Batch 163 completed and kept in memory.\n",
      "🔹 Processing batch 164/400 (1000 APIs)...\n",
      "✅ Batch 164 completed and kept in memory.\n",
      "🔹 Processing batch 165/400 (1000 APIs)...\n",
      "✅ Batch 165 completed and kept in memory.\n",
      "🔹 Processing batch 166/400 (1000 APIs)...\n",
      "✅ Batch 166 completed and kept in memory.\n",
      "🔹 Processing batch 167/400 (1000 APIs)...\n",
      "✅ Batch 167 completed and kept in memory.\n",
      "🔹 Processing batch 168/400 (1000 APIs)...\n",
      "✅ Batch 168 completed and kept in memory.\n",
      "🔹 Processing batch 169/400 (1000 APIs)...\n",
      "✅ Batch 169 completed and kept in memory.\n",
      "🔹 Processing batch 170/400 (1000 APIs)...\n",
      "✅ Batch 170 completed and kept in memory.\n",
      "🔹 Processing batch 171/400 (1000 APIs)...\n",
      "✅ Batch 171 completed and kept in memory.\n",
      "🔹 Processing batch 172/400 (1000 APIs)...\n",
      "✅ Batch 172 completed and kept in memory.\n",
      "🔹 Processing batch 173/400 (1000 APIs)...\n",
      "✅ Batch 173 completed and kept in memory.\n",
      "🔹 Processing batch 174/400 (1000 APIs)...\n",
      "✅ Batch 174 completed and kept in memory.\n",
      "🔹 Processing batch 175/400 (1000 APIs)...\n",
      "✅ Batch 175 completed and kept in memory.\n",
      "🔹 Processing batch 176/400 (1000 APIs)...\n",
      "✅ Batch 176 completed and kept in memory.\n",
      "🔹 Processing batch 177/400 (1000 APIs)...\n",
      "✅ Batch 177 completed and kept in memory.\n",
      "🔹 Processing batch 178/400 (1000 APIs)...\n",
      "✅ Batch 178 completed and kept in memory.\n",
      "🔹 Processing batch 179/400 (1000 APIs)...\n",
      "✅ Batch 179 completed and kept in memory.\n",
      "🔹 Processing batch 180/400 (1000 APIs)...\n",
      "✅ Batch 180 completed and kept in memory.\n",
      "🔹 Processing batch 181/400 (1000 APIs)...\n",
      "✅ Batch 181 completed and kept in memory.\n",
      "🔹 Processing batch 182/400 (1000 APIs)...\n",
      "✅ Batch 182 completed and kept in memory.\n",
      "🔹 Processing batch 183/400 (1000 APIs)...\n",
      "✅ Batch 183 completed and kept in memory.\n",
      "🔹 Processing batch 184/400 (1000 APIs)...\n",
      "✅ Batch 184 completed and kept in memory.\n",
      "🔹 Processing batch 185/400 (1000 APIs)...\n",
      "✅ Batch 185 completed and kept in memory.\n",
      "🔹 Processing batch 186/400 (1000 APIs)...\n",
      "✅ Batch 186 completed and kept in memory.\n",
      "🔹 Processing batch 187/400 (1000 APIs)...\n",
      "✅ Batch 187 completed and kept in memory.\n",
      "🔹 Processing batch 188/400 (1000 APIs)...\n",
      "✅ Batch 188 completed and kept in memory.\n",
      "🔹 Processing batch 189/400 (1000 APIs)...\n",
      "✅ Batch 189 completed and kept in memory.\n",
      "🔹 Processing batch 190/400 (1000 APIs)...\n",
      "✅ Batch 190 completed and kept in memory.\n",
      "🔹 Processing batch 191/400 (1000 APIs)...\n",
      "✅ Batch 191 completed and kept in memory.\n",
      "🔹 Processing batch 192/400 (1000 APIs)...\n",
      "✅ Batch 192 completed and kept in memory.\n",
      "🔹 Processing batch 193/400 (1000 APIs)...\n",
      "✅ Batch 193 completed and kept in memory.\n",
      "🔹 Processing batch 194/400 (1000 APIs)...\n",
      "✅ Batch 194 completed and kept in memory.\n",
      "🔹 Processing batch 195/400 (1000 APIs)...\n",
      "✅ Batch 195 completed and kept in memory.\n",
      "🔹 Processing batch 196/400 (1000 APIs)...\n",
      "✅ Batch 196 completed and kept in memory.\n",
      "🔹 Processing batch 197/400 (1000 APIs)...\n",
      "✅ Batch 197 completed and kept in memory.\n",
      "🔹 Processing batch 198/400 (1000 APIs)...\n",
      "✅ Batch 198 completed and kept in memory.\n",
      "🔹 Processing batch 199/400 (1000 APIs)...\n",
      "✅ Batch 199 completed and kept in memory.\n",
      "🔹 Processing batch 200/400 (1000 APIs)...\n",
      "✅ Batch 200 completed and kept in memory.\n",
      "🔹 Processing batch 201/400 (1000 APIs)...\n",
      "✅ Batch 201 completed and kept in memory.\n",
      "🔹 Processing batch 202/400 (1000 APIs)...\n",
      "✅ Batch 202 completed and kept in memory.\n",
      "🔹 Processing batch 203/400 (1000 APIs)...\n",
      "✅ Batch 203 completed and kept in memory.\n",
      "🔹 Processing batch 204/400 (1000 APIs)...\n",
      "✅ Batch 204 completed and kept in memory.\n",
      "🔹 Processing batch 205/400 (1000 APIs)...\n",
      "✅ Batch 205 completed and kept in memory.\n",
      "🔹 Processing batch 206/400 (1000 APIs)...\n",
      "✅ Batch 206 completed and kept in memory.\n",
      "🔹 Processing batch 207/400 (1000 APIs)...\n",
      "✅ Batch 207 completed and kept in memory.\n",
      "🔹 Processing batch 208/400 (1000 APIs)...\n",
      "✅ Batch 208 completed and kept in memory.\n",
      "🔹 Processing batch 209/400 (1000 APIs)...\n",
      "✅ Batch 209 completed and kept in memory.\n",
      "🔹 Processing batch 210/400 (1000 APIs)...\n",
      "✅ Batch 210 completed and kept in memory.\n",
      "🔹 Processing batch 211/400 (1000 APIs)...\n",
      "✅ Batch 211 completed and kept in memory.\n",
      "🔹 Processing batch 212/400 (1000 APIs)...\n",
      "✅ Batch 212 completed and kept in memory.\n",
      "🔹 Processing batch 213/400 (1000 APIs)...\n",
      "✅ Batch 213 completed and kept in memory.\n",
      "🔹 Processing batch 214/400 (1000 APIs)...\n",
      "✅ Batch 214 completed and kept in memory.\n",
      "🔹 Processing batch 215/400 (1000 APIs)...\n",
      "✅ Batch 215 completed and kept in memory.\n",
      "🔹 Processing batch 216/400 (1000 APIs)...\n",
      "✅ Batch 216 completed and kept in memory.\n",
      "🔹 Processing batch 217/400 (1000 APIs)...\n",
      "✅ Batch 217 completed and kept in memory.\n",
      "🔹 Processing batch 218/400 (1000 APIs)...\n",
      "✅ Batch 218 completed and kept in memory.\n",
      "🔹 Processing batch 219/400 (1000 APIs)...\n",
      "✅ Batch 219 completed and kept in memory.\n",
      "🔹 Processing batch 220/400 (1000 APIs)...\n",
      "✅ Batch 220 completed and kept in memory.\n",
      "🔹 Processing batch 221/400 (1000 APIs)...\n",
      "✅ Batch 221 completed and kept in memory.\n",
      "🔹 Processing batch 222/400 (1000 APIs)...\n",
      "✅ Batch 222 completed and kept in memory.\n",
      "🔹 Processing batch 223/400 (1000 APIs)...\n",
      "✅ Batch 223 completed and kept in memory.\n",
      "🔹 Processing batch 224/400 (1000 APIs)...\n",
      "✅ Batch 224 completed and kept in memory.\n",
      "🔹 Processing batch 225/400 (1000 APIs)...\n",
      "✅ Batch 225 completed and kept in memory.\n",
      "🔹 Processing batch 226/400 (1000 APIs)...\n",
      "✅ Batch 226 completed and kept in memory.\n",
      "🔹 Processing batch 227/400 (1000 APIs)...\n",
      "✅ Batch 227 completed and kept in memory.\n",
      "🔹 Processing batch 228/400 (1000 APIs)...\n",
      "✅ Batch 228 completed and kept in memory.\n",
      "🔹 Processing batch 229/400 (1000 APIs)...\n",
      "✅ Batch 229 completed and kept in memory.\n",
      "🔹 Processing batch 230/400 (1000 APIs)...\n",
      "✅ Batch 230 completed and kept in memory.\n",
      "🔹 Processing batch 231/400 (1000 APIs)...\n",
      "✅ Batch 231 completed and kept in memory.\n",
      "🔹 Processing batch 232/400 (1000 APIs)...\n",
      "✅ Batch 232 completed and kept in memory.\n",
      "🔹 Processing batch 233/400 (1000 APIs)...\n",
      "✅ Batch 233 completed and kept in memory.\n",
      "🔹 Processing batch 234/400 (1000 APIs)...\n",
      "✅ Batch 234 completed and kept in memory.\n",
      "🔹 Processing batch 235/400 (1000 APIs)...\n",
      "✅ Batch 235 completed and kept in memory.\n",
      "🔹 Processing batch 236/400 (1000 APIs)...\n",
      "✅ Batch 236 completed and kept in memory.\n",
      "🔹 Processing batch 237/400 (1000 APIs)...\n",
      "✅ Batch 237 completed and kept in memory.\n",
      "🔹 Processing batch 238/400 (1000 APIs)...\n",
      "✅ Batch 238 completed and kept in memory.\n",
      "🔹 Processing batch 239/400 (1000 APIs)...\n",
      "✅ Batch 239 completed and kept in memory.\n",
      "🔹 Processing batch 240/400 (1000 APIs)...\n",
      "✅ Batch 240 completed and kept in memory.\n",
      "🔹 Processing batch 241/400 (1000 APIs)...\n",
      "✅ Batch 241 completed and kept in memory.\n",
      "🔹 Processing batch 242/400 (1000 APIs)...\n",
      "✅ Batch 242 completed and kept in memory.\n",
      "🔹 Processing batch 243/400 (1000 APIs)...\n",
      "✅ Batch 243 completed and kept in memory.\n",
      "🔹 Processing batch 244/400 (1000 APIs)...\n",
      "✅ Batch 244 completed and kept in memory.\n",
      "🔹 Processing batch 245/400 (1000 APIs)...\n",
      "✅ Batch 245 completed and kept in memory.\n",
      "🔹 Processing batch 246/400 (1000 APIs)...\n",
      "✅ Batch 246 completed and kept in memory.\n",
      "🔹 Processing batch 247/400 (1000 APIs)...\n",
      "✅ Batch 247 completed and kept in memory.\n",
      "🔹 Processing batch 248/400 (1000 APIs)...\n",
      "✅ Batch 248 completed and kept in memory.\n",
      "🔹 Processing batch 249/400 (1000 APIs)...\n",
      "✅ Batch 249 completed and kept in memory.\n",
      "🔹 Processing batch 250/400 (1000 APIs)...\n",
      "✅ Batch 250 completed and kept in memory.\n",
      "🔹 Processing batch 251/400 (1000 APIs)...\n",
      "✅ Batch 251 completed and kept in memory.\n",
      "🔹 Processing batch 252/400 (1000 APIs)...\n",
      "✅ Batch 252 completed and kept in memory.\n",
      "🔹 Processing batch 253/400 (1000 APIs)...\n",
      "✅ Batch 253 completed and kept in memory.\n",
      "🔹 Processing batch 254/400 (1000 APIs)...\n",
      "✅ Batch 254 completed and kept in memory.\n",
      "🔹 Processing batch 255/400 (1000 APIs)...\n",
      "✅ Batch 255 completed and kept in memory.\n",
      "🔹 Processing batch 256/400 (1000 APIs)...\n",
      "✅ Batch 256 completed and kept in memory.\n",
      "🔹 Processing batch 257/400 (1000 APIs)...\n",
      "✅ Batch 257 completed and kept in memory.\n",
      "🔹 Processing batch 258/400 (1000 APIs)...\n",
      "✅ Batch 258 completed and kept in memory.\n",
      "🔹 Processing batch 259/400 (1000 APIs)...\n",
      "✅ Batch 259 completed and kept in memory.\n",
      "🔹 Processing batch 260/400 (1000 APIs)...\n",
      "✅ Batch 260 completed and kept in memory.\n",
      "🔹 Processing batch 261/400 (1000 APIs)...\n",
      "✅ Batch 261 completed and kept in memory.\n",
      "🔹 Processing batch 262/400 (1000 APIs)...\n",
      "✅ Batch 262 completed and kept in memory.\n",
      "🔹 Processing batch 263/400 (1000 APIs)...\n",
      "✅ Batch 263 completed and kept in memory.\n",
      "🔹 Processing batch 264/400 (1000 APIs)...\n",
      "✅ Batch 264 completed and kept in memory.\n",
      "🔹 Processing batch 265/400 (1000 APIs)...\n",
      "✅ Batch 265 completed and kept in memory.\n",
      "🔹 Processing batch 266/400 (1000 APIs)...\n",
      "✅ Batch 266 completed and kept in memory.\n",
      "🔹 Processing batch 267/400 (1000 APIs)...\n",
      "✅ Batch 267 completed and kept in memory.\n",
      "🔹 Processing batch 268/400 (1000 APIs)...\n",
      "✅ Batch 268 completed and kept in memory.\n",
      "🔹 Processing batch 269/400 (1000 APIs)...\n",
      "✅ Batch 269 completed and kept in memory.\n",
      "🔹 Processing batch 270/400 (1000 APIs)...\n",
      "✅ Batch 270 completed and kept in memory.\n",
      "🔹 Processing batch 271/400 (1000 APIs)...\n",
      "✅ Batch 271 completed and kept in memory.\n",
      "🔹 Processing batch 272/400 (1000 APIs)...\n",
      "✅ Batch 272 completed and kept in memory.\n",
      "🔹 Processing batch 273/400 (1000 APIs)...\n",
      "✅ Batch 273 completed and kept in memory.\n",
      "🔹 Processing batch 274/400 (1000 APIs)...\n",
      "✅ Batch 274 completed and kept in memory.\n",
      "🔹 Processing batch 275/400 (1000 APIs)...\n",
      "✅ Batch 275 completed and kept in memory.\n",
      "🔹 Processing batch 276/400 (1000 APIs)...\n",
      "✅ Batch 276 completed and kept in memory.\n",
      "🔹 Processing batch 277/400 (1000 APIs)...\n",
      "✅ Batch 277 completed and kept in memory.\n",
      "🔹 Processing batch 278/400 (1000 APIs)...\n",
      "✅ Batch 278 completed and kept in memory.\n",
      "🔹 Processing batch 279/400 (1000 APIs)...\n",
      "✅ Batch 279 completed and kept in memory.\n",
      "🔹 Processing batch 280/400 (1000 APIs)...\n",
      "✅ Batch 280 completed and kept in memory.\n",
      "🔹 Processing batch 281/400 (1000 APIs)...\n",
      "✅ Batch 281 completed and kept in memory.\n",
      "🔹 Processing batch 282/400 (1000 APIs)...\n",
      "✅ Batch 282 completed and kept in memory.\n",
      "🔹 Processing batch 283/400 (1000 APIs)...\n",
      "✅ Batch 283 completed and kept in memory.\n",
      "🔹 Processing batch 284/400 (1000 APIs)...\n",
      "✅ Batch 284 completed and kept in memory.\n",
      "🔹 Processing batch 285/400 (1000 APIs)...\n",
      "✅ Batch 285 completed and kept in memory.\n",
      "🔹 Processing batch 286/400 (1000 APIs)...\n",
      "✅ Batch 286 completed and kept in memory.\n",
      "🔹 Processing batch 287/400 (1000 APIs)...\n",
      "✅ Batch 287 completed and kept in memory.\n",
      "🔹 Processing batch 288/400 (1000 APIs)...\n",
      "✅ Batch 288 completed and kept in memory.\n",
      "🔹 Processing batch 289/400 (1000 APIs)...\n",
      "✅ Batch 289 completed and kept in memory.\n",
      "🔹 Processing batch 290/400 (1000 APIs)...\n",
      "✅ Batch 290 completed and kept in memory.\n",
      "🔹 Processing batch 291/400 (1000 APIs)...\n",
      "✅ Batch 291 completed and kept in memory.\n",
      "🔹 Processing batch 292/400 (1000 APIs)...\n",
      "✅ Batch 292 completed and kept in memory.\n",
      "🔹 Processing batch 293/400 (1000 APIs)...\n",
      "✅ Batch 293 completed and kept in memory.\n",
      "🔹 Processing batch 294/400 (1000 APIs)...\n",
      "✅ Batch 294 completed and kept in memory.\n",
      "🔹 Processing batch 295/400 (1000 APIs)...\n",
      "✅ Batch 295 completed and kept in memory.\n",
      "🔹 Processing batch 296/400 (1000 APIs)...\n",
      "✅ Batch 296 completed and kept in memory.\n",
      "🔹 Processing batch 297/400 (1000 APIs)...\n",
      "✅ Batch 297 completed and kept in memory.\n",
      "🔹 Processing batch 298/400 (1000 APIs)...\n",
      "✅ Batch 298 completed and kept in memory.\n",
      "🔹 Processing batch 299/400 (1000 APIs)...\n",
      "✅ Batch 299 completed and kept in memory.\n",
      "🔹 Processing batch 300/400 (1000 APIs)...\n",
      "✅ Batch 300 completed and kept in memory.\n",
      "🔹 Processing batch 301/400 (1000 APIs)...\n",
      "✅ Batch 301 completed and kept in memory.\n",
      "🔹 Processing batch 302/400 (1000 APIs)...\n",
      "✅ Batch 302 completed and kept in memory.\n",
      "🔹 Processing batch 303/400 (1000 APIs)...\n",
      "✅ Batch 303 completed and kept in memory.\n",
      "🔹 Processing batch 304/400 (1000 APIs)...\n",
      "✅ Batch 304 completed and kept in memory.\n",
      "🔹 Processing batch 305/400 (1000 APIs)...\n",
      "✅ Batch 305 completed and kept in memory.\n",
      "🔹 Processing batch 306/400 (1000 APIs)...\n",
      "✅ Batch 306 completed and kept in memory.\n",
      "🔹 Processing batch 307/400 (1000 APIs)...\n",
      "✅ Batch 307 completed and kept in memory.\n",
      "🔹 Processing batch 308/400 (1000 APIs)...\n",
      "✅ Batch 308 completed and kept in memory.\n",
      "🔹 Processing batch 309/400 (1000 APIs)...\n",
      "✅ Batch 309 completed and kept in memory.\n",
      "🔹 Processing batch 310/400 (1000 APIs)...\n",
      "✅ Batch 310 completed and kept in memory.\n",
      "🔹 Processing batch 311/400 (1000 APIs)...\n",
      "✅ Batch 311 completed and kept in memory.\n",
      "🔹 Processing batch 312/400 (1000 APIs)...\n",
      "✅ Batch 312 completed and kept in memory.\n",
      "🔹 Processing batch 313/400 (1000 APIs)...\n",
      "✅ Batch 313 completed and kept in memory.\n",
      "🔹 Processing batch 314/400 (1000 APIs)...\n",
      "✅ Batch 314 completed and kept in memory.\n",
      "🔹 Processing batch 315/400 (1000 APIs)...\n",
      "✅ Batch 315 completed and kept in memory.\n",
      "🔹 Processing batch 316/400 (1000 APIs)...\n",
      "✅ Batch 316 completed and kept in memory.\n",
      "🔹 Processing batch 317/400 (1000 APIs)...\n",
      "✅ Batch 317 completed and kept in memory.\n",
      "🔹 Processing batch 318/400 (1000 APIs)...\n",
      "✅ Batch 318 completed and kept in memory.\n",
      "🔹 Processing batch 319/400 (1000 APIs)...\n",
      "✅ Batch 319 completed and kept in memory.\n",
      "🔹 Processing batch 320/400 (1000 APIs)...\n",
      "✅ Batch 320 completed and kept in memory.\n",
      "🔹 Processing batch 321/400 (1000 APIs)...\n",
      "✅ Batch 321 completed and kept in memory.\n",
      "🔹 Processing batch 322/400 (1000 APIs)...\n",
      "✅ Batch 322 completed and kept in memory.\n",
      "🔹 Processing batch 323/400 (1000 APIs)...\n",
      "✅ Batch 323 completed and kept in memory.\n",
      "🔹 Processing batch 324/400 (1000 APIs)...\n",
      "✅ Batch 324 completed and kept in memory.\n",
      "🔹 Processing batch 325/400 (1000 APIs)...\n",
      "✅ Batch 325 completed and kept in memory.\n",
      "🔹 Processing batch 326/400 (1000 APIs)...\n",
      "✅ Batch 326 completed and kept in memory.\n",
      "🔹 Processing batch 327/400 (1000 APIs)...\n",
      "✅ Batch 327 completed and kept in memory.\n",
      "🔹 Processing batch 328/400 (1000 APIs)...\n",
      "✅ Batch 328 completed and kept in memory.\n",
      "🔹 Processing batch 329/400 (1000 APIs)...\n",
      "✅ Batch 329 completed and kept in memory.\n",
      "🔹 Processing batch 330/400 (1000 APIs)...\n",
      "✅ Batch 330 completed and kept in memory.\n",
      "🔹 Processing batch 331/400 (1000 APIs)...\n",
      "✅ Batch 331 completed and kept in memory.\n",
      "🔹 Processing batch 332/400 (1000 APIs)...\n",
      "✅ Batch 332 completed and kept in memory.\n",
      "🔹 Processing batch 333/400 (1000 APIs)...\n",
      "✅ Batch 333 completed and kept in memory.\n",
      "🔹 Processing batch 334/400 (1000 APIs)...\n",
      "✅ Batch 334 completed and kept in memory.\n",
      "🔹 Processing batch 335/400 (1000 APIs)...\n",
      "✅ Batch 335 completed and kept in memory.\n",
      "🔹 Processing batch 336/400 (1000 APIs)...\n",
      "✅ Batch 336 completed and kept in memory.\n",
      "🔹 Processing batch 337/400 (1000 APIs)...\n",
      "✅ Batch 337 completed and kept in memory.\n",
      "🔹 Processing batch 338/400 (1000 APIs)...\n",
      "✅ Batch 338 completed and kept in memory.\n",
      "🔹 Processing batch 339/400 (1000 APIs)...\n",
      "✅ Batch 339 completed and kept in memory.\n",
      "🔹 Processing batch 340/400 (1000 APIs)...\n",
      "✅ Batch 340 completed and kept in memory.\n",
      "🔹 Processing batch 341/400 (1000 APIs)...\n",
      "✅ Batch 341 completed and kept in memory.\n",
      "🔹 Processing batch 342/400 (1000 APIs)...\n",
      "✅ Batch 342 completed and kept in memory.\n",
      "🔹 Processing batch 343/400 (1000 APIs)...\n",
      "✅ Batch 343 completed and kept in memory.\n",
      "🔹 Processing batch 344/400 (1000 APIs)...\n",
      "✅ Batch 344 completed and kept in memory.\n",
      "🔹 Processing batch 345/400 (1000 APIs)...\n",
      "✅ Batch 345 completed and kept in memory.\n",
      "🔹 Processing batch 346/400 (1000 APIs)...\n",
      "✅ Batch 346 completed and kept in memory.\n",
      "🔹 Processing batch 347/400 (1000 APIs)...\n",
      "✅ Batch 347 completed and kept in memory.\n",
      "🔹 Processing batch 348/400 (1000 APIs)...\n",
      "✅ Batch 348 completed and kept in memory.\n",
      "🔹 Processing batch 349/400 (1000 APIs)...\n",
      "✅ Batch 349 completed and kept in memory.\n",
      "🔹 Processing batch 350/400 (1000 APIs)...\n",
      "✅ Batch 350 completed and kept in memory.\n",
      "🔹 Processing batch 351/400 (1000 APIs)...\n",
      "✅ Batch 351 completed and kept in memory.\n",
      "🔹 Processing batch 352/400 (1000 APIs)...\n",
      "✅ Batch 352 completed and kept in memory.\n",
      "🔹 Processing batch 353/400 (1000 APIs)...\n",
      "✅ Batch 353 completed and kept in memory.\n",
      "🔹 Processing batch 354/400 (1000 APIs)...\n",
      "✅ Batch 354 completed and kept in memory.\n",
      "🔹 Processing batch 355/400 (1000 APIs)...\n",
      "✅ Batch 355 completed and kept in memory.\n",
      "🔹 Processing batch 356/400 (1000 APIs)...\n",
      "✅ Batch 356 completed and kept in memory.\n",
      "🔹 Processing batch 357/400 (1000 APIs)...\n",
      "✅ Batch 357 completed and kept in memory.\n",
      "🔹 Processing batch 358/400 (1000 APIs)...\n",
      "✅ Batch 358 completed and kept in memory.\n",
      "🔹 Processing batch 359/400 (1000 APIs)...\n",
      "✅ Batch 359 completed and kept in memory.\n",
      "🔹 Processing batch 360/400 (1000 APIs)...\n",
      "✅ Batch 360 completed and kept in memory.\n",
      "🔹 Processing batch 361/400 (1000 APIs)...\n",
      "✅ Batch 361 completed and kept in memory.\n",
      "🔹 Processing batch 362/400 (1000 APIs)...\n",
      "✅ Batch 362 completed and kept in memory.\n",
      "🔹 Processing batch 363/400 (1000 APIs)...\n",
      "✅ Batch 363 completed and kept in memory.\n",
      "🔹 Processing batch 364/400 (1000 APIs)...\n",
      "✅ Batch 364 completed and kept in memory.\n",
      "🔹 Processing batch 365/400 (1000 APIs)...\n",
      "✅ Batch 365 completed and kept in memory.\n",
      "🔹 Processing batch 366/400 (1000 APIs)...\n",
      "✅ Batch 366 completed and kept in memory.\n",
      "🔹 Processing batch 367/400 (1000 APIs)...\n",
      "✅ Batch 367 completed and kept in memory.\n",
      "🔹 Processing batch 368/400 (1000 APIs)...\n",
      "✅ Batch 368 completed and kept in memory.\n",
      "🔹 Processing batch 369/400 (1000 APIs)...\n",
      "✅ Batch 369 completed and kept in memory.\n",
      "🔹 Processing batch 370/400 (1000 APIs)...\n",
      "✅ Batch 370 completed and kept in memory.\n",
      "🔹 Processing batch 371/400 (1000 APIs)...\n",
      "✅ Batch 371 completed and kept in memory.\n",
      "🔹 Processing batch 372/400 (1000 APIs)...\n",
      "✅ Batch 372 completed and kept in memory.\n",
      "🔹 Processing batch 373/400 (1000 APIs)...\n",
      "✅ Batch 373 completed and kept in memory.\n",
      "🔹 Processing batch 374/400 (1000 APIs)...\n",
      "✅ Batch 374 completed and kept in memory.\n",
      "🔹 Processing batch 375/400 (1000 APIs)...\n",
      "✅ Batch 375 completed and kept in memory.\n",
      "🔹 Processing batch 376/400 (1000 APIs)...\n",
      "✅ Batch 376 completed and kept in memory.\n",
      "🔹 Processing batch 377/400 (1000 APIs)...\n",
      "✅ Batch 377 completed and kept in memory.\n",
      "🔹 Processing batch 378/400 (1000 APIs)...\n",
      "✅ Batch 378 completed and kept in memory.\n",
      "🔹 Processing batch 379/400 (1000 APIs)...\n",
      "✅ Batch 379 completed and kept in memory.\n",
      "🔹 Processing batch 380/400 (1000 APIs)...\n",
      "✅ Batch 380 completed and kept in memory.\n",
      "🔹 Processing batch 381/400 (1000 APIs)...\n",
      "✅ Batch 381 completed and kept in memory.\n",
      "🔹 Processing batch 382/400 (1000 APIs)...\n",
      "✅ Batch 382 completed and kept in memory.\n",
      "🔹 Processing batch 383/400 (1000 APIs)...\n",
      "✅ Batch 383 completed and kept in memory.\n",
      "🔹 Processing batch 384/400 (1000 APIs)...\n",
      "✅ Batch 384 completed and kept in memory.\n",
      "🔹 Processing batch 385/400 (1000 APIs)...\n",
      "✅ Batch 385 completed and kept in memory.\n",
      "🔹 Processing batch 386/400 (1000 APIs)...\n",
      "✅ Batch 386 completed and kept in memory.\n",
      "🔹 Processing batch 387/400 (1000 APIs)...\n",
      "✅ Batch 387 completed and kept in memory.\n",
      "🔹 Processing batch 388/400 (1000 APIs)...\n",
      "✅ Batch 388 completed and kept in memory.\n",
      "🔹 Processing batch 389/400 (1000 APIs)...\n",
      "✅ Batch 389 completed and kept in memory.\n",
      "🔹 Processing batch 390/400 (1000 APIs)...\n",
      "✅ Batch 390 completed and kept in memory.\n",
      "🔹 Processing batch 391/400 (1000 APIs)...\n",
      "✅ Batch 391 completed and kept in memory.\n",
      "🔹 Processing batch 392/400 (1000 APIs)...\n",
      "✅ Batch 392 completed and kept in memory.\n",
      "🔹 Processing batch 393/400 (1000 APIs)...\n",
      "✅ Batch 393 completed and kept in memory.\n",
      "🔹 Processing batch 394/400 (1000 APIs)...\n",
      "✅ Batch 394 completed and kept in memory.\n",
      "🔹 Processing batch 395/400 (1000 APIs)...\n",
      "✅ Batch 395 completed and kept in memory.\n",
      "🔹 Processing batch 396/400 (1000 APIs)...\n",
      "✅ Batch 396 completed and kept in memory.\n",
      "🔹 Processing batch 397/400 (1000 APIs)...\n",
      "✅ Batch 397 completed and kept in memory.\n",
      "🔹 Processing batch 398/400 (1000 APIs)...\n",
      "✅ Batch 398 completed and kept in memory.\n",
      "🔹 Processing batch 399/400 (1000 APIs)...\n",
      "✅ Batch 399 completed and kept in memory.\n",
      "🔹 Processing batch 400/400 (39 APIs)...\n",
      "✅ Batch 400 completed and kept in memory.\n",
      "✅ All 400 batches processed.\n",
      "🔄 Concatenating 400 batches into final DataFrame...\n"
     ]
    }
   ],
   "source": [
    "cols_to_fill = [\n",
    "    'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last',\n",
    "    'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6'\n",
    "]\n",
    "forecast_df = batch_merge_and_backfill_dask(forecast_df, bfill_helper, cols_to_fill, batch_size=1000, write_batches_to_disk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3942c0-4738-4d2f-8028-bcb410fcdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_parquet('../data/forecast_4_backfill.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6241f6-c8fb-4ab9-b11e-ceea20725d48",
   "metadata": {},
   "source": [
    "Since this is a dask dataframe and we do need to know its properties to know whether the function succeeded, let's implement a new version of comprehensive_data_overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "489c482e-5dd0-4660-9505-dcecf7b00124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "def comprehensive_data_overview_dask(datasets):\n",
    "    \"\"\"\n",
    "    Provide comprehensive overview of all Dask datasets including dtypes,\n",
    "    missing values, and basic stats.\n",
    "    \n",
    "    Args:\n",
    "        datasets (dict): Dictionary of Dask DataFrames\n",
    "        sample_rows (int): Number of rows to sample for numeric stats preview\n",
    "    \"\"\"\n",
    "    for name, df in datasets.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DATASET: {name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Shape\n",
    "        shape = df.shape\n",
    "        print(f\"Shape: ({shape})\")\n",
    "\n",
    "        # Column information\n",
    "        print(f\"\\nColumn Overview:\")\n",
    "        print(f\"{'Column':<25} {'Type':<15} {'Non-Null':<10} {'Unique':<10} {'Missing %':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        # Compute stats for all columns\n",
    "        counts = df.count()\n",
    "        nunique = df.nunique()\n",
    "        total_rows = shape[0]\n",
    "        missing = df.isnull().sum()\n",
    "\n",
    "        for col in df.columns:\n",
    "            dtype = str(df[col].dtype)\n",
    "            non_null = counts[col]\n",
    "            unique_count = nunique[col]\n",
    "            missing_pct = (missing[col] / total_rows) * 100\n",
    "\n",
    "            print(f\"{col:<25} {dtype:<15} {non_null:<10} {unique_count:<10} {missing_pct:<10.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3810bb-1d09-4fe4-8ae7-45aafaba529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: BACKFILL_DF\n",
      "============================================================\n",
      "Shape: ((19951950, 11))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 object          19951950   399039     0.0       %\n",
      "date_prod                 datetime64[ns]  19951950   50         0.0       %\n",
      "last_year                 float64         19951950   5          0.0       %\n",
      "last_month                float64         19951950   13         0.0       %\n",
      "last_gas                  float64         19951950   128036     0.0       %\n",
      "last_oil                  float64         19951950   38278      0.0       %\n",
      "months_since_last         float64         19951950   43         0.0       %\n",
      "gas_avg_3                 float64         19951950   262000     0.0       %\n",
      "oil_avg_3                 float64         19951950   95299      0.0       %\n",
      "gas_avg_6                 float64         19951950   430300     0.0       %\n",
      "oil_avg_6                 float64         19951950   172912     0.0       %\n"
     ]
    }
   ],
   "source": [
    "comprehensive_data_overview_dask({'backfill_df': forecast_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4beb95d3-cc6b-47d7-8c9f-b10ac82163ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       1000000\n",
       "mean     2022-10-27 02:54:56.908000\n",
       "min             2021-01-01 00:00:00\n",
       "25%             2021-12-01 00:00:00\n",
       "50%             2022-11-01 00:00:00\n",
       "75%             2023-10-01 00:00:00\n",
       "max             2024-11-01 00:00:00\n",
       "Name: date_prod, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfill_helper['date_prod'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25cd1ac-9e8f-4ea3-a8c5-c2c5d2a8d6c2",
   "metadata": {},
   "source": [
    "Unfortunately I accidentally only loaded the first 1000000 values of bfill data, so it won't be very accurate, I'll need to load all of it this time using dask and modify my function accordingly, but at least I know it works.\n",
    "\n",
    "!! I also shouldn't forget that I need to sort the original forecast_df values in the exact same way that I sort the filled features so that I know they match the correct api number and production date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bd3352-7673-40f9-8c25-4e1cfa204bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded joined_data as Dask DataFrame\n",
      "  Shape: (<dask_expr.expr.Scalar: expr=ReadParquetFSSpec(5910b21).size() // 11, dtype=int32>, 11)\n",
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 11 entries, api_no_10 to oil_avg_6\n",
      "dtypes: datetime64[ms](1), float64(6), int32(3), string(1)"
     ]
    }
   ],
   "source": [
    "bfill_helper = load_parquet_datasets({'joined_data': '../data/forecast_helper_1.parquet'}, use_dask=True)['joined_data']\n",
    "bfill_helper.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f47a0e-dee0-4613-a4d9-b0829bd111bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16564703 entries, 0 to 16603789\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   api_no_10          string        \n",
      " 1   date_prod          datetime64[ms]\n",
      " 2   last_year          int32         \n",
      " 3   last_month         int32         \n",
      " 4   last_gas           float64       \n",
      " 5   last_oil           float64       \n",
      " 6   months_since_last  int32         \n",
      " 7   gas_avg_3          float64       \n",
      " 8   oil_avg_3          float64       \n",
      " 9   gas_avg_6          float64       \n",
      " 10  oil_avg_6          float64       \n",
      "dtypes: datetime64[ms](1), float64(6), int32(3), string(1)\n",
      "memory usage: 1.4 GB\n"
     ]
    }
   ],
   "source": [
    "bfill_helper = bfill_helper.compute()\n",
    "bfill_helper.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebc2154c-36b5-4007-bbfe-e25bd7e81a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: BFILL_HELPER\n",
      "============================================================\n",
      "Shape: ((16564703, 11))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 string          16564703   399039     0.0       %\n",
      "date_prod                 datetime64[ms]  16564703   47         0.0       %\n",
      "last_year                 int32           16564703   5          0.0       %\n",
      "last_month                int32           16564703   13         0.0       %\n",
      "last_gas                  float64         16564703   128036     0.0       %\n",
      "last_oil                  float64         16564703   38278      0.0       %\n",
      "months_since_last         int32           16564703   43         0.0       %\n",
      "gas_avg_3                 float64         16564703   262000     0.0       %\n",
      "oil_avg_3                 float64         16564703   95299      0.0       %\n",
      "gas_avg_6                 float64         16564703   430300     0.0       %\n",
      "oil_avg_6                 float64         16564703   172912     0.0       %\n"
     ]
    }
   ],
   "source": [
    "comprehensive_data_overview_dask({'bfill_helper': bfill_helper})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3e9526-6014-401c-9f34-7a9840ea3c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded joined_data as Dask DataFrame\n",
      "  Shape: (<dask_expr.expr.Scalar: expr=ReadParquetFSSpec(1407f7b).size() // 38, dtype=int32>, 38)\n",
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 38 entries, api_no_10 to oil_avg_6\n",
      "dtypes: datetime64[ns](2), float64(32), int32(3), string(1)"
     ]
    }
   ],
   "source": [
    "forecast_df = load_parquet_datasets({'joined_data': '../data/forecast_3.parquet'}, use_dask=True)['joined_data']\n",
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27f01745-f3ef-4396-8294-fb0885a78c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399039"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forecast_df['api_no_10'].drop_duplicates().compute().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ba54d48-1dc4-44a1-b467-92cd7fb52331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(forecast_df[['api_no_10', 'date_prod']].compute().duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f032bff-7924-46e8-a3ab-787a02eaa19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forecast_df['date_prod'].drop_duplicates().compute().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17aa6a55-3f8e-43e9-8527-05190b832972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df['date_prod'].compute().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90dc90e5-4c9d-43ed-aa0a-066a9308e2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ms]')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfill_helper['date_prod'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5e3b418-da76-43fc-a414-7a566f962002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "string[pyarrow]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df['api_no_10'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "298e64c7-8095-4a9c-a7b6-26b9e5656348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "string[pyarrow]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfill_helper['api_no_10'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed36f305-6da3-456b-aa7a-118479cf1199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total unique APIs: 399039\n",
      "✅ Batch size: 1000\n",
      "✅ Total batches: 400\n",
      "🔹 Processing batch 1/400 (1000 APIs)...\n",
      "✅ Batch 1 completed and kept in memory.\n",
      "🔹 Processing batch 2/400 (1000 APIs)...\n",
      "✅ Batch 2 completed and kept in memory.\n",
      "🔹 Processing batch 3/400 (1000 APIs)...\n",
      "✅ Batch 3 completed and kept in memory.\n",
      "🔹 Processing batch 4/400 (1000 APIs)...\n",
      "✅ Batch 4 completed and kept in memory.\n",
      "🔹 Processing batch 5/400 (1000 APIs)...\n",
      "✅ Batch 5 completed and kept in memory.\n",
      "🔹 Processing batch 6/400 (1000 APIs)...\n",
      "✅ Batch 6 completed and kept in memory.\n",
      "🔹 Processing batch 7/400 (1000 APIs)...\n",
      "✅ Batch 7 completed and kept in memory.\n",
      "🔹 Processing batch 8/400 (1000 APIs)...\n",
      "✅ Batch 8 completed and kept in memory.\n",
      "🔹 Processing batch 9/400 (1000 APIs)...\n",
      "✅ Batch 9 completed and kept in memory.\n",
      "🔹 Processing batch 10/400 (1000 APIs)...\n",
      "✅ Batch 10 completed and kept in memory.\n",
      "🔹 Processing batch 11/400 (1000 APIs)...\n",
      "✅ Batch 11 completed and kept in memory.\n",
      "🔹 Processing batch 12/400 (1000 APIs)...\n",
      "✅ Batch 12 completed and kept in memory.\n",
      "🔹 Processing batch 13/400 (1000 APIs)...\n",
      "✅ Batch 13 completed and kept in memory.\n",
      "🔹 Processing batch 14/400 (1000 APIs)...\n",
      "✅ Batch 14 completed and kept in memory.\n",
      "🔹 Processing batch 15/400 (1000 APIs)...\n",
      "✅ Batch 15 completed and kept in memory.\n",
      "🔹 Processing batch 16/400 (1000 APIs)...\n",
      "✅ Batch 16 completed and kept in memory.\n",
      "🔹 Processing batch 17/400 (1000 APIs)...\n",
      "✅ Batch 17 completed and kept in memory.\n",
      "🔹 Processing batch 18/400 (1000 APIs)...\n",
      "✅ Batch 18 completed and kept in memory.\n",
      "🔹 Processing batch 19/400 (1000 APIs)...\n",
      "✅ Batch 19 completed and kept in memory.\n",
      "🔹 Processing batch 20/400 (1000 APIs)...\n",
      "✅ Batch 20 completed and kept in memory.\n",
      "🔹 Processing batch 21/400 (1000 APIs)...\n",
      "✅ Batch 21 completed and kept in memory.\n",
      "🔹 Processing batch 22/400 (1000 APIs)...\n",
      "✅ Batch 22 completed and kept in memory.\n",
      "🔹 Processing batch 23/400 (1000 APIs)...\n",
      "✅ Batch 23 completed and kept in memory.\n",
      "🔹 Processing batch 24/400 (1000 APIs)...\n",
      "✅ Batch 24 completed and kept in memory.\n",
      "🔹 Processing batch 25/400 (1000 APIs)...\n",
      "✅ Batch 25 completed and kept in memory.\n",
      "🔹 Processing batch 26/400 (1000 APIs)...\n",
      "✅ Batch 26 completed and kept in memory.\n",
      "🔹 Processing batch 27/400 (1000 APIs)...\n",
      "✅ Batch 27 completed and kept in memory.\n",
      "🔹 Processing batch 28/400 (1000 APIs)...\n",
      "✅ Batch 28 completed and kept in memory.\n",
      "🔹 Processing batch 29/400 (1000 APIs)...\n",
      "✅ Batch 29 completed and kept in memory.\n",
      "🔹 Processing batch 30/400 (1000 APIs)...\n",
      "✅ Batch 30 completed and kept in memory.\n",
      "🔹 Processing batch 31/400 (1000 APIs)...\n",
      "✅ Batch 31 completed and kept in memory.\n",
      "🔹 Processing batch 32/400 (1000 APIs)...\n",
      "✅ Batch 32 completed and kept in memory.\n",
      "🔹 Processing batch 33/400 (1000 APIs)...\n",
      "✅ Batch 33 completed and kept in memory.\n",
      "🔹 Processing batch 34/400 (1000 APIs)...\n",
      "✅ Batch 34 completed and kept in memory.\n",
      "🔹 Processing batch 35/400 (1000 APIs)...\n",
      "✅ Batch 35 completed and kept in memory.\n",
      "🔹 Processing batch 36/400 (1000 APIs)...\n",
      "✅ Batch 36 completed and kept in memory.\n",
      "🔹 Processing batch 37/400 (1000 APIs)...\n",
      "✅ Batch 37 completed and kept in memory.\n",
      "🔹 Processing batch 38/400 (1000 APIs)...\n",
      "✅ Batch 38 completed and kept in memory.\n",
      "🔹 Processing batch 39/400 (1000 APIs)...\n",
      "✅ Batch 39 completed and kept in memory.\n",
      "🔹 Processing batch 40/400 (1000 APIs)...\n",
      "✅ Batch 40 completed and kept in memory.\n",
      "🔹 Processing batch 41/400 (1000 APIs)...\n",
      "✅ Batch 41 completed and kept in memory.\n",
      "🔹 Processing batch 42/400 (1000 APIs)...\n",
      "✅ Batch 42 completed and kept in memory.\n",
      "🔹 Processing batch 43/400 (1000 APIs)...\n",
      "✅ Batch 43 completed and kept in memory.\n",
      "🔹 Processing batch 44/400 (1000 APIs)...\n",
      "✅ Batch 44 completed and kept in memory.\n",
      "🔹 Processing batch 45/400 (1000 APIs)...\n",
      "✅ Batch 45 completed and kept in memory.\n",
      "🔹 Processing batch 46/400 (1000 APIs)...\n",
      "✅ Batch 46 completed and kept in memory.\n",
      "🔹 Processing batch 47/400 (1000 APIs)...\n",
      "✅ Batch 47 completed and kept in memory.\n",
      "🔹 Processing batch 48/400 (1000 APIs)...\n",
      "✅ Batch 48 completed and kept in memory.\n",
      "🔹 Processing batch 49/400 (1000 APIs)...\n",
      "✅ Batch 49 completed and kept in memory.\n",
      "🔹 Processing batch 50/400 (1000 APIs)...\n",
      "✅ Batch 50 completed and kept in memory.\n",
      "🔹 Processing batch 51/400 (1000 APIs)...\n",
      "✅ Batch 51 completed and kept in memory.\n",
      "🔹 Processing batch 52/400 (1000 APIs)...\n",
      "✅ Batch 52 completed and kept in memory.\n",
      "🔹 Processing batch 53/400 (1000 APIs)...\n",
      "✅ Batch 53 completed and kept in memory.\n",
      "🔹 Processing batch 54/400 (1000 APIs)...\n",
      "✅ Batch 54 completed and kept in memory.\n",
      "🔹 Processing batch 55/400 (1000 APIs)...\n",
      "✅ Batch 55 completed and kept in memory.\n",
      "🔹 Processing batch 56/400 (1000 APIs)...\n",
      "✅ Batch 56 completed and kept in memory.\n",
      "🔹 Processing batch 57/400 (1000 APIs)...\n",
      "✅ Batch 57 completed and kept in memory.\n",
      "🔹 Processing batch 58/400 (1000 APIs)...\n",
      "✅ Batch 58 completed and kept in memory.\n",
      "🔹 Processing batch 59/400 (1000 APIs)...\n",
      "✅ Batch 59 completed and kept in memory.\n",
      "🔹 Processing batch 60/400 (1000 APIs)...\n",
      "✅ Batch 60 completed and kept in memory.\n",
      "🔹 Processing batch 61/400 (1000 APIs)...\n",
      "✅ Batch 61 completed and kept in memory.\n",
      "🔹 Processing batch 62/400 (1000 APIs)...\n",
      "✅ Batch 62 completed and kept in memory.\n",
      "🔹 Processing batch 63/400 (1000 APIs)...\n",
      "✅ Batch 63 completed and kept in memory.\n",
      "🔹 Processing batch 64/400 (1000 APIs)...\n",
      "✅ Batch 64 completed and kept in memory.\n",
      "🔹 Processing batch 65/400 (1000 APIs)...\n",
      "✅ Batch 65 completed and kept in memory.\n",
      "🔹 Processing batch 66/400 (1000 APIs)...\n",
      "✅ Batch 66 completed and kept in memory.\n",
      "🔹 Processing batch 67/400 (1000 APIs)...\n",
      "✅ Batch 67 completed and kept in memory.\n",
      "🔹 Processing batch 68/400 (1000 APIs)...\n",
      "✅ Batch 68 completed and kept in memory.\n",
      "🔹 Processing batch 69/400 (1000 APIs)...\n",
      "✅ Batch 69 completed and kept in memory.\n",
      "🔹 Processing batch 70/400 (1000 APIs)...\n",
      "✅ Batch 70 completed and kept in memory.\n",
      "🔹 Processing batch 71/400 (1000 APIs)...\n",
      "✅ Batch 71 completed and kept in memory.\n",
      "🔹 Processing batch 72/400 (1000 APIs)...\n",
      "✅ Batch 72 completed and kept in memory.\n",
      "🔹 Processing batch 73/400 (1000 APIs)...\n",
      "✅ Batch 73 completed and kept in memory.\n",
      "🔹 Processing batch 74/400 (1000 APIs)...\n",
      "✅ Batch 74 completed and kept in memory.\n",
      "🔹 Processing batch 75/400 (1000 APIs)...\n",
      "✅ Batch 75 completed and kept in memory.\n",
      "🔹 Processing batch 76/400 (1000 APIs)...\n",
      "✅ Batch 76 completed and kept in memory.\n",
      "🔹 Processing batch 77/400 (1000 APIs)...\n",
      "✅ Batch 77 completed and kept in memory.\n",
      "🔹 Processing batch 78/400 (1000 APIs)...\n",
      "✅ Batch 78 completed and kept in memory.\n",
      "🔹 Processing batch 79/400 (1000 APIs)...\n",
      "✅ Batch 79 completed and kept in memory.\n",
      "🔹 Processing batch 80/400 (1000 APIs)...\n",
      "✅ Batch 80 completed and kept in memory.\n",
      "🔹 Processing batch 81/400 (1000 APIs)...\n",
      "✅ Batch 81 completed and kept in memory.\n",
      "🔹 Processing batch 82/400 (1000 APIs)...\n",
      "✅ Batch 82 completed and kept in memory.\n",
      "🔹 Processing batch 83/400 (1000 APIs)...\n",
      "✅ Batch 83 completed and kept in memory.\n",
      "🔹 Processing batch 84/400 (1000 APIs)...\n",
      "✅ Batch 84 completed and kept in memory.\n",
      "🔹 Processing batch 85/400 (1000 APIs)...\n",
      "✅ Batch 85 completed and kept in memory.\n",
      "🔹 Processing batch 86/400 (1000 APIs)...\n",
      "✅ Batch 86 completed and kept in memory.\n",
      "🔹 Processing batch 87/400 (1000 APIs)...\n",
      "✅ Batch 87 completed and kept in memory.\n",
      "🔹 Processing batch 88/400 (1000 APIs)...\n",
      "✅ Batch 88 completed and kept in memory.\n",
      "🔹 Processing batch 89/400 (1000 APIs)...\n",
      "✅ Batch 89 completed and kept in memory.\n",
      "🔹 Processing batch 90/400 (1000 APIs)...\n",
      "✅ Batch 90 completed and kept in memory.\n",
      "🔹 Processing batch 91/400 (1000 APIs)...\n",
      "✅ Batch 91 completed and kept in memory.\n",
      "🔹 Processing batch 92/400 (1000 APIs)...\n",
      "✅ Batch 92 completed and kept in memory.\n",
      "🔹 Processing batch 93/400 (1000 APIs)...\n",
      "✅ Batch 93 completed and kept in memory.\n",
      "🔹 Processing batch 94/400 (1000 APIs)...\n",
      "✅ Batch 94 completed and kept in memory.\n",
      "🔹 Processing batch 95/400 (1000 APIs)...\n",
      "✅ Batch 95 completed and kept in memory.\n",
      "🔹 Processing batch 96/400 (1000 APIs)...\n",
      "✅ Batch 96 completed and kept in memory.\n",
      "🔹 Processing batch 97/400 (1000 APIs)...\n",
      "✅ Batch 97 completed and kept in memory.\n",
      "🔹 Processing batch 98/400 (1000 APIs)...\n",
      "✅ Batch 98 completed and kept in memory.\n",
      "🔹 Processing batch 99/400 (1000 APIs)...\n",
      "✅ Batch 99 completed and kept in memory.\n",
      "🔹 Processing batch 100/400 (1000 APIs)...\n",
      "✅ Batch 100 completed and kept in memory.\n",
      "🔹 Processing batch 101/400 (1000 APIs)...\n",
      "✅ Batch 101 completed and kept in memory.\n",
      "🔹 Processing batch 102/400 (1000 APIs)...\n",
      "✅ Batch 102 completed and kept in memory.\n",
      "🔹 Processing batch 103/400 (1000 APIs)...\n",
      "✅ Batch 103 completed and kept in memory.\n",
      "🔹 Processing batch 104/400 (1000 APIs)...\n",
      "✅ Batch 104 completed and kept in memory.\n",
      "🔹 Processing batch 105/400 (1000 APIs)...\n",
      "✅ Batch 105 completed and kept in memory.\n",
      "🔹 Processing batch 106/400 (1000 APIs)...\n",
      "✅ Batch 106 completed and kept in memory.\n",
      "🔹 Processing batch 107/400 (1000 APIs)...\n",
      "✅ Batch 107 completed and kept in memory.\n",
      "🔹 Processing batch 108/400 (1000 APIs)...\n",
      "✅ Batch 108 completed and kept in memory.\n",
      "🔹 Processing batch 109/400 (1000 APIs)...\n",
      "✅ Batch 109 completed and kept in memory.\n",
      "🔹 Processing batch 110/400 (1000 APIs)...\n",
      "✅ Batch 110 completed and kept in memory.\n",
      "🔹 Processing batch 111/400 (1000 APIs)...\n",
      "✅ Batch 111 completed and kept in memory.\n",
      "🔹 Processing batch 112/400 (1000 APIs)...\n",
      "✅ Batch 112 completed and kept in memory.\n",
      "🔹 Processing batch 113/400 (1000 APIs)...\n",
      "✅ Batch 113 completed and kept in memory.\n",
      "🔹 Processing batch 114/400 (1000 APIs)...\n",
      "✅ Batch 114 completed and kept in memory.\n",
      "🔹 Processing batch 115/400 (1000 APIs)...\n",
      "✅ Batch 115 completed and kept in memory.\n",
      "🔹 Processing batch 116/400 (1000 APIs)...\n",
      "✅ Batch 116 completed and kept in memory.\n",
      "🔹 Processing batch 117/400 (1000 APIs)...\n",
      "✅ Batch 117 completed and kept in memory.\n",
      "🔹 Processing batch 118/400 (1000 APIs)...\n",
      "✅ Batch 118 completed and kept in memory.\n",
      "🔹 Processing batch 119/400 (1000 APIs)...\n",
      "✅ Batch 119 completed and kept in memory.\n",
      "🔹 Processing batch 120/400 (1000 APIs)...\n",
      "✅ Batch 120 completed and kept in memory.\n",
      "🔹 Processing batch 121/400 (1000 APIs)...\n",
      "✅ Batch 121 completed and kept in memory.\n",
      "🔹 Processing batch 122/400 (1000 APIs)...\n",
      "✅ Batch 122 completed and kept in memory.\n",
      "🔹 Processing batch 123/400 (1000 APIs)...\n",
      "✅ Batch 123 completed and kept in memory.\n",
      "🔹 Processing batch 124/400 (1000 APIs)...\n",
      "✅ Batch 124 completed and kept in memory.\n",
      "🔹 Processing batch 125/400 (1000 APIs)...\n",
      "✅ Batch 125 completed and kept in memory.\n",
      "🔹 Processing batch 126/400 (1000 APIs)...\n",
      "✅ Batch 126 completed and kept in memory.\n",
      "🔹 Processing batch 127/400 (1000 APIs)...\n",
      "✅ Batch 127 completed and kept in memory.\n",
      "🔹 Processing batch 128/400 (1000 APIs)...\n",
      "✅ Batch 128 completed and kept in memory.\n",
      "🔹 Processing batch 129/400 (1000 APIs)...\n",
      "✅ Batch 129 completed and kept in memory.\n",
      "🔹 Processing batch 130/400 (1000 APIs)...\n",
      "✅ Batch 130 completed and kept in memory.\n",
      "🔹 Processing batch 131/400 (1000 APIs)...\n",
      "✅ Batch 131 completed and kept in memory.\n",
      "🔹 Processing batch 132/400 (1000 APIs)...\n",
      "✅ Batch 132 completed and kept in memory.\n",
      "🔹 Processing batch 133/400 (1000 APIs)...\n",
      "✅ Batch 133 completed and kept in memory.\n",
      "🔹 Processing batch 134/400 (1000 APIs)...\n",
      "✅ Batch 134 completed and kept in memory.\n",
      "🔹 Processing batch 135/400 (1000 APIs)...\n",
      "✅ Batch 135 completed and kept in memory.\n",
      "🔹 Processing batch 136/400 (1000 APIs)...\n",
      "✅ Batch 136 completed and kept in memory.\n",
      "🔹 Processing batch 137/400 (1000 APIs)...\n",
      "✅ Batch 137 completed and kept in memory.\n",
      "🔹 Processing batch 138/400 (1000 APIs)...\n",
      "✅ Batch 138 completed and kept in memory.\n",
      "🔹 Processing batch 139/400 (1000 APIs)...\n",
      "✅ Batch 139 completed and kept in memory.\n",
      "🔹 Processing batch 140/400 (1000 APIs)...\n",
      "✅ Batch 140 completed and kept in memory.\n",
      "🔹 Processing batch 141/400 (1000 APIs)...\n",
      "✅ Batch 141 completed and kept in memory.\n",
      "🔹 Processing batch 142/400 (1000 APIs)...\n",
      "✅ Batch 142 completed and kept in memory.\n",
      "🔹 Processing batch 143/400 (1000 APIs)...\n",
      "✅ Batch 143 completed and kept in memory.\n",
      "🔹 Processing batch 144/400 (1000 APIs)...\n",
      "✅ Batch 144 completed and kept in memory.\n",
      "🔹 Processing batch 145/400 (1000 APIs)...\n",
      "✅ Batch 145 completed and kept in memory.\n",
      "🔹 Processing batch 146/400 (1000 APIs)...\n",
      "✅ Batch 146 completed and kept in memory.\n",
      "🔹 Processing batch 147/400 (1000 APIs)...\n",
      "✅ Batch 147 completed and kept in memory.\n",
      "🔹 Processing batch 148/400 (1000 APIs)...\n",
      "✅ Batch 148 completed and kept in memory.\n",
      "🔹 Processing batch 149/400 (1000 APIs)...\n",
      "✅ Batch 149 completed and kept in memory.\n",
      "🔹 Processing batch 150/400 (1000 APIs)...\n",
      "✅ Batch 150 completed and kept in memory.\n",
      "🔹 Processing batch 151/400 (1000 APIs)...\n",
      "✅ Batch 151 completed and kept in memory.\n",
      "🔹 Processing batch 152/400 (1000 APIs)...\n",
      "✅ Batch 152 completed and kept in memory.\n",
      "🔹 Processing batch 153/400 (1000 APIs)...\n",
      "✅ Batch 153 completed and kept in memory.\n",
      "🔹 Processing batch 154/400 (1000 APIs)...\n",
      "✅ Batch 154 completed and kept in memory.\n",
      "🔹 Processing batch 155/400 (1000 APIs)...\n",
      "✅ Batch 155 completed and kept in memory.\n",
      "🔹 Processing batch 156/400 (1000 APIs)...\n",
      "✅ Batch 156 completed and kept in memory.\n",
      "🔹 Processing batch 157/400 (1000 APIs)...\n",
      "✅ Batch 157 completed and kept in memory.\n",
      "🔹 Processing batch 158/400 (1000 APIs)...\n",
      "✅ Batch 158 completed and kept in memory.\n",
      "🔹 Processing batch 159/400 (1000 APIs)...\n",
      "✅ Batch 159 completed and kept in memory.\n",
      "🔹 Processing batch 160/400 (1000 APIs)...\n",
      "✅ Batch 160 completed and kept in memory.\n",
      "🔹 Processing batch 161/400 (1000 APIs)...\n",
      "✅ Batch 161 completed and kept in memory.\n",
      "🔹 Processing batch 162/400 (1000 APIs)...\n",
      "✅ Batch 162 completed and kept in memory.\n",
      "🔹 Processing batch 163/400 (1000 APIs)...\n",
      "✅ Batch 163 completed and kept in memory.\n",
      "🔹 Processing batch 164/400 (1000 APIs)...\n",
      "✅ Batch 164 completed and kept in memory.\n",
      "🔹 Processing batch 165/400 (1000 APIs)...\n",
      "✅ Batch 165 completed and kept in memory.\n",
      "🔹 Processing batch 166/400 (1000 APIs)...\n",
      "✅ Batch 166 completed and kept in memory.\n",
      "🔹 Processing batch 167/400 (1000 APIs)...\n",
      "✅ Batch 167 completed and kept in memory.\n",
      "🔹 Processing batch 168/400 (1000 APIs)...\n",
      "✅ Batch 168 completed and kept in memory.\n",
      "🔹 Processing batch 169/400 (1000 APIs)...\n",
      "✅ Batch 169 completed and kept in memory.\n",
      "🔹 Processing batch 170/400 (1000 APIs)...\n",
      "✅ Batch 170 completed and kept in memory.\n",
      "🔹 Processing batch 171/400 (1000 APIs)...\n",
      "✅ Batch 171 completed and kept in memory.\n",
      "🔹 Processing batch 172/400 (1000 APIs)...\n",
      "✅ Batch 172 completed and kept in memory.\n",
      "🔹 Processing batch 173/400 (1000 APIs)...\n",
      "✅ Batch 173 completed and kept in memory.\n",
      "🔹 Processing batch 174/400 (1000 APIs)...\n",
      "✅ Batch 174 completed and kept in memory.\n",
      "🔹 Processing batch 175/400 (1000 APIs)...\n",
      "✅ Batch 175 completed and kept in memory.\n",
      "🔹 Processing batch 176/400 (1000 APIs)...\n",
      "✅ Batch 176 completed and kept in memory.\n",
      "🔹 Processing batch 177/400 (1000 APIs)...\n",
      "✅ Batch 177 completed and kept in memory.\n",
      "🔹 Processing batch 178/400 (1000 APIs)...\n",
      "✅ Batch 178 completed and kept in memory.\n",
      "🔹 Processing batch 179/400 (1000 APIs)...\n",
      "✅ Batch 179 completed and kept in memory.\n",
      "🔹 Processing batch 180/400 (1000 APIs)...\n",
      "✅ Batch 180 completed and kept in memory.\n",
      "🔹 Processing batch 181/400 (1000 APIs)...\n",
      "✅ Batch 181 completed and kept in memory.\n",
      "🔹 Processing batch 182/400 (1000 APIs)...\n",
      "✅ Batch 182 completed and kept in memory.\n",
      "🔹 Processing batch 183/400 (1000 APIs)...\n",
      "✅ Batch 183 completed and kept in memory.\n",
      "🔹 Processing batch 184/400 (1000 APIs)...\n",
      "✅ Batch 184 completed and kept in memory.\n",
      "🔹 Processing batch 185/400 (1000 APIs)...\n",
      "✅ Batch 185 completed and kept in memory.\n",
      "🔹 Processing batch 186/400 (1000 APIs)...\n",
      "✅ Batch 186 completed and kept in memory.\n",
      "🔹 Processing batch 187/400 (1000 APIs)...\n",
      "✅ Batch 187 completed and kept in memory.\n",
      "🔹 Processing batch 188/400 (1000 APIs)...\n",
      "✅ Batch 188 completed and kept in memory.\n",
      "🔹 Processing batch 189/400 (1000 APIs)...\n",
      "✅ Batch 189 completed and kept in memory.\n",
      "🔹 Processing batch 190/400 (1000 APIs)...\n",
      "✅ Batch 190 completed and kept in memory.\n",
      "🔹 Processing batch 191/400 (1000 APIs)...\n",
      "✅ Batch 191 completed and kept in memory.\n",
      "🔹 Processing batch 192/400 (1000 APIs)...\n",
      "✅ Batch 192 completed and kept in memory.\n",
      "🔹 Processing batch 193/400 (1000 APIs)...\n",
      "✅ Batch 193 completed and kept in memory.\n",
      "🔹 Processing batch 194/400 (1000 APIs)...\n",
      "✅ Batch 194 completed and kept in memory.\n",
      "🔹 Processing batch 195/400 (1000 APIs)...\n",
      "✅ Batch 195 completed and kept in memory.\n",
      "🔹 Processing batch 196/400 (1000 APIs)...\n",
      "✅ Batch 196 completed and kept in memory.\n",
      "🔹 Processing batch 197/400 (1000 APIs)...\n",
      "✅ Batch 197 completed and kept in memory.\n",
      "🔹 Processing batch 198/400 (1000 APIs)...\n",
      "✅ Batch 198 completed and kept in memory.\n",
      "🔹 Processing batch 199/400 (1000 APIs)...\n",
      "✅ Batch 199 completed and kept in memory.\n",
      "🔹 Processing batch 200/400 (1000 APIs)...\n",
      "✅ Batch 200 completed and kept in memory.\n",
      "🔹 Processing batch 201/400 (1000 APIs)...\n",
      "✅ Batch 201 completed and kept in memory.\n",
      "🔹 Processing batch 202/400 (1000 APIs)...\n",
      "✅ Batch 202 completed and kept in memory.\n",
      "🔹 Processing batch 203/400 (1000 APIs)...\n",
      "✅ Batch 203 completed and kept in memory.\n",
      "🔹 Processing batch 204/400 (1000 APIs)...\n",
      "✅ Batch 204 completed and kept in memory.\n",
      "🔹 Processing batch 205/400 (1000 APIs)...\n",
      "✅ Batch 205 completed and kept in memory.\n",
      "🔹 Processing batch 206/400 (1000 APIs)...\n",
      "✅ Batch 206 completed and kept in memory.\n",
      "🔹 Processing batch 207/400 (1000 APIs)...\n",
      "✅ Batch 207 completed and kept in memory.\n",
      "🔹 Processing batch 208/400 (1000 APIs)...\n",
      "✅ Batch 208 completed and kept in memory.\n",
      "🔹 Processing batch 209/400 (1000 APIs)...\n",
      "✅ Batch 209 completed and kept in memory.\n",
      "🔹 Processing batch 210/400 (1000 APIs)...\n",
      "✅ Batch 210 completed and kept in memory.\n",
      "🔹 Processing batch 211/400 (1000 APIs)...\n",
      "✅ Batch 211 completed and kept in memory.\n",
      "🔹 Processing batch 212/400 (1000 APIs)...\n",
      "✅ Batch 212 completed and kept in memory.\n",
      "🔹 Processing batch 213/400 (1000 APIs)...\n",
      "✅ Batch 213 completed and kept in memory.\n",
      "🔹 Processing batch 214/400 (1000 APIs)...\n",
      "✅ Batch 214 completed and kept in memory.\n",
      "🔹 Processing batch 215/400 (1000 APIs)...\n",
      "✅ Batch 215 completed and kept in memory.\n",
      "🔹 Processing batch 216/400 (1000 APIs)...\n",
      "✅ Batch 216 completed and kept in memory.\n",
      "🔹 Processing batch 217/400 (1000 APIs)...\n",
      "✅ Batch 217 completed and kept in memory.\n",
      "🔹 Processing batch 218/400 (1000 APIs)...\n",
      "✅ Batch 218 completed and kept in memory.\n",
      "🔹 Processing batch 219/400 (1000 APIs)...\n",
      "✅ Batch 219 completed and kept in memory.\n",
      "🔹 Processing batch 220/400 (1000 APIs)...\n",
      "✅ Batch 220 completed and kept in memory.\n",
      "🔹 Processing batch 221/400 (1000 APIs)...\n",
      "✅ Batch 221 completed and kept in memory.\n",
      "🔹 Processing batch 222/400 (1000 APIs)...\n",
      "✅ Batch 222 completed and kept in memory.\n",
      "🔹 Processing batch 223/400 (1000 APIs)...\n",
      "✅ Batch 223 completed and kept in memory.\n",
      "🔹 Processing batch 224/400 (1000 APIs)...\n",
      "✅ Batch 224 completed and kept in memory.\n",
      "🔹 Processing batch 225/400 (1000 APIs)...\n",
      "✅ Batch 225 completed and kept in memory.\n",
      "🔹 Processing batch 226/400 (1000 APIs)...\n",
      "✅ Batch 226 completed and kept in memory.\n",
      "🔹 Processing batch 227/400 (1000 APIs)...\n",
      "✅ Batch 227 completed and kept in memory.\n",
      "🔹 Processing batch 228/400 (1000 APIs)...\n",
      "✅ Batch 228 completed and kept in memory.\n",
      "🔹 Processing batch 229/400 (1000 APIs)...\n",
      "✅ Batch 229 completed and kept in memory.\n",
      "🔹 Processing batch 230/400 (1000 APIs)...\n",
      "✅ Batch 230 completed and kept in memory.\n",
      "🔹 Processing batch 231/400 (1000 APIs)...\n",
      "✅ Batch 231 completed and kept in memory.\n",
      "🔹 Processing batch 232/400 (1000 APIs)...\n",
      "✅ Batch 232 completed and kept in memory.\n",
      "🔹 Processing batch 233/400 (1000 APIs)...\n",
      "✅ Batch 233 completed and kept in memory.\n",
      "🔹 Processing batch 234/400 (1000 APIs)...\n",
      "✅ Batch 234 completed and kept in memory.\n",
      "🔹 Processing batch 235/400 (1000 APIs)...\n",
      "✅ Batch 235 completed and kept in memory.\n",
      "🔹 Processing batch 236/400 (1000 APIs)...\n",
      "✅ Batch 236 completed and kept in memory.\n",
      "🔹 Processing batch 237/400 (1000 APIs)...\n",
      "✅ Batch 237 completed and kept in memory.\n",
      "🔹 Processing batch 238/400 (1000 APIs)...\n",
      "✅ Batch 238 completed and kept in memory.\n",
      "🔹 Processing batch 239/400 (1000 APIs)...\n",
      "✅ Batch 239 completed and kept in memory.\n",
      "🔹 Processing batch 240/400 (1000 APIs)...\n",
      "✅ Batch 240 completed and kept in memory.\n",
      "🔹 Processing batch 241/400 (1000 APIs)...\n",
      "✅ Batch 241 completed and kept in memory.\n",
      "🔹 Processing batch 242/400 (1000 APIs)...\n",
      "✅ Batch 242 completed and kept in memory.\n",
      "🔹 Processing batch 243/400 (1000 APIs)...\n",
      "✅ Batch 243 completed and kept in memory.\n",
      "🔹 Processing batch 244/400 (1000 APIs)...\n",
      "✅ Batch 244 completed and kept in memory.\n",
      "🔹 Processing batch 245/400 (1000 APIs)...\n",
      "✅ Batch 245 completed and kept in memory.\n",
      "🔹 Processing batch 246/400 (1000 APIs)...\n",
      "✅ Batch 246 completed and kept in memory.\n",
      "🔹 Processing batch 247/400 (1000 APIs)...\n",
      "✅ Batch 247 completed and kept in memory.\n",
      "🔹 Processing batch 248/400 (1000 APIs)...\n",
      "✅ Batch 248 completed and kept in memory.\n",
      "🔹 Processing batch 249/400 (1000 APIs)...\n",
      "✅ Batch 249 completed and kept in memory.\n",
      "🔹 Processing batch 250/400 (1000 APIs)...\n",
      "✅ Batch 250 completed and kept in memory.\n",
      "🔹 Processing batch 251/400 (1000 APIs)...\n",
      "✅ Batch 251 completed and kept in memory.\n",
      "🔹 Processing batch 252/400 (1000 APIs)...\n",
      "✅ Batch 252 completed and kept in memory.\n",
      "🔹 Processing batch 253/400 (1000 APIs)...\n",
      "✅ Batch 253 completed and kept in memory.\n",
      "🔹 Processing batch 254/400 (1000 APIs)...\n",
      "✅ Batch 254 completed and kept in memory.\n",
      "🔹 Processing batch 255/400 (1000 APIs)...\n",
      "✅ Batch 255 completed and kept in memory.\n",
      "🔹 Processing batch 256/400 (1000 APIs)...\n",
      "✅ Batch 256 completed and kept in memory.\n",
      "🔹 Processing batch 257/400 (1000 APIs)...\n",
      "✅ Batch 257 completed and kept in memory.\n",
      "🔹 Processing batch 258/400 (1000 APIs)...\n",
      "✅ Batch 258 completed and kept in memory.\n",
      "🔹 Processing batch 259/400 (1000 APIs)...\n",
      "✅ Batch 259 completed and kept in memory.\n",
      "🔹 Processing batch 260/400 (1000 APIs)...\n",
      "✅ Batch 260 completed and kept in memory.\n",
      "🔹 Processing batch 261/400 (1000 APIs)...\n",
      "✅ Batch 261 completed and kept in memory.\n",
      "🔹 Processing batch 262/400 (1000 APIs)...\n",
      "✅ Batch 262 completed and kept in memory.\n",
      "🔹 Processing batch 263/400 (1000 APIs)...\n",
      "✅ Batch 263 completed and kept in memory.\n",
      "🔹 Processing batch 264/400 (1000 APIs)...\n",
      "✅ Batch 264 completed and kept in memory.\n",
      "🔹 Processing batch 265/400 (1000 APIs)...\n",
      "✅ Batch 265 completed and kept in memory.\n",
      "🔹 Processing batch 266/400 (1000 APIs)...\n",
      "✅ Batch 266 completed and kept in memory.\n",
      "🔹 Processing batch 267/400 (1000 APIs)...\n",
      "✅ Batch 267 completed and kept in memory.\n",
      "🔹 Processing batch 268/400 (1000 APIs)...\n",
      "✅ Batch 268 completed and kept in memory.\n",
      "🔹 Processing batch 269/400 (1000 APIs)...\n",
      "✅ Batch 269 completed and kept in memory.\n",
      "🔹 Processing batch 270/400 (1000 APIs)...\n",
      "✅ Batch 270 completed and kept in memory.\n",
      "🔹 Processing batch 271/400 (1000 APIs)...\n",
      "✅ Batch 271 completed and kept in memory.\n",
      "🔹 Processing batch 272/400 (1000 APIs)...\n",
      "✅ Batch 272 completed and kept in memory.\n",
      "🔹 Processing batch 273/400 (1000 APIs)...\n",
      "✅ Batch 273 completed and kept in memory.\n",
      "🔹 Processing batch 274/400 (1000 APIs)...\n",
      "✅ Batch 274 completed and kept in memory.\n",
      "🔹 Processing batch 275/400 (1000 APIs)...\n",
      "✅ Batch 275 completed and kept in memory.\n",
      "🔹 Processing batch 276/400 (1000 APIs)...\n",
      "✅ Batch 276 completed and kept in memory.\n",
      "🔹 Processing batch 277/400 (1000 APIs)...\n",
      "✅ Batch 277 completed and kept in memory.\n",
      "🔹 Processing batch 278/400 (1000 APIs)...\n",
      "✅ Batch 278 completed and kept in memory.\n",
      "🔹 Processing batch 279/400 (1000 APIs)...\n",
      "✅ Batch 279 completed and kept in memory.\n",
      "🔹 Processing batch 280/400 (1000 APIs)...\n",
      "✅ Batch 280 completed and kept in memory.\n",
      "🔹 Processing batch 281/400 (1000 APIs)...\n",
      "✅ Batch 281 completed and kept in memory.\n",
      "🔹 Processing batch 282/400 (1000 APIs)...\n",
      "✅ Batch 282 completed and kept in memory.\n",
      "🔹 Processing batch 283/400 (1000 APIs)...\n",
      "✅ Batch 283 completed and kept in memory.\n",
      "🔹 Processing batch 284/400 (1000 APIs)...\n",
      "✅ Batch 284 completed and kept in memory.\n",
      "🔹 Processing batch 285/400 (1000 APIs)...\n",
      "✅ Batch 285 completed and kept in memory.\n",
      "🔹 Processing batch 286/400 (1000 APIs)...\n",
      "✅ Batch 286 completed and kept in memory.\n",
      "🔹 Processing batch 287/400 (1000 APIs)...\n",
      "✅ Batch 287 completed and kept in memory.\n",
      "🔹 Processing batch 288/400 (1000 APIs)...\n",
      "✅ Batch 288 completed and kept in memory.\n",
      "🔹 Processing batch 289/400 (1000 APIs)...\n",
      "✅ Batch 289 completed and kept in memory.\n",
      "🔹 Processing batch 290/400 (1000 APIs)...\n",
      "✅ Batch 290 completed and kept in memory.\n",
      "🔹 Processing batch 291/400 (1000 APIs)...\n",
      "✅ Batch 291 completed and kept in memory.\n",
      "🔹 Processing batch 292/400 (1000 APIs)...\n",
      "✅ Batch 292 completed and kept in memory.\n",
      "🔹 Processing batch 293/400 (1000 APIs)...\n",
      "✅ Batch 293 completed and kept in memory.\n",
      "🔹 Processing batch 294/400 (1000 APIs)...\n",
      "✅ Batch 294 completed and kept in memory.\n",
      "🔹 Processing batch 295/400 (1000 APIs)...\n",
      "✅ Batch 295 completed and kept in memory.\n",
      "🔹 Processing batch 296/400 (1000 APIs)...\n",
      "✅ Batch 296 completed and kept in memory.\n",
      "🔹 Processing batch 297/400 (1000 APIs)...\n",
      "✅ Batch 297 completed and kept in memory.\n",
      "🔹 Processing batch 298/400 (1000 APIs)...\n",
      "✅ Batch 298 completed and kept in memory.\n",
      "🔹 Processing batch 299/400 (1000 APIs)...\n",
      "✅ Batch 299 completed and kept in memory.\n",
      "🔹 Processing batch 300/400 (1000 APIs)...\n",
      "✅ Batch 300 completed and kept in memory.\n",
      "🔹 Processing batch 301/400 (1000 APIs)...\n",
      "✅ Batch 301 completed and kept in memory.\n",
      "🔹 Processing batch 302/400 (1000 APIs)...\n",
      "✅ Batch 302 completed and kept in memory.\n",
      "🔹 Processing batch 303/400 (1000 APIs)...\n",
      "✅ Batch 303 completed and kept in memory.\n",
      "🔹 Processing batch 304/400 (1000 APIs)...\n",
      "✅ Batch 304 completed and kept in memory.\n",
      "🔹 Processing batch 305/400 (1000 APIs)...\n",
      "✅ Batch 305 completed and kept in memory.\n",
      "🔹 Processing batch 306/400 (1000 APIs)...\n",
      "✅ Batch 306 completed and kept in memory.\n",
      "🔹 Processing batch 307/400 (1000 APIs)...\n",
      "✅ Batch 307 completed and kept in memory.\n",
      "🔹 Processing batch 308/400 (1000 APIs)...\n",
      "✅ Batch 308 completed and kept in memory.\n",
      "🔹 Processing batch 309/400 (1000 APIs)...\n",
      "✅ Batch 309 completed and kept in memory.\n",
      "🔹 Processing batch 310/400 (1000 APIs)...\n",
      "✅ Batch 310 completed and kept in memory.\n",
      "🔹 Processing batch 311/400 (1000 APIs)...\n",
      "✅ Batch 311 completed and kept in memory.\n",
      "🔹 Processing batch 312/400 (1000 APIs)...\n",
      "✅ Batch 312 completed and kept in memory.\n",
      "🔹 Processing batch 313/400 (1000 APIs)...\n",
      "✅ Batch 313 completed and kept in memory.\n",
      "🔹 Processing batch 314/400 (1000 APIs)...\n",
      "✅ Batch 314 completed and kept in memory.\n",
      "🔹 Processing batch 315/400 (1000 APIs)...\n",
      "✅ Batch 315 completed and kept in memory.\n",
      "🔹 Processing batch 316/400 (1000 APIs)...\n",
      "✅ Batch 316 completed and kept in memory.\n",
      "🔹 Processing batch 317/400 (1000 APIs)...\n",
      "✅ Batch 317 completed and kept in memory.\n",
      "🔹 Processing batch 318/400 (1000 APIs)...\n",
      "✅ Batch 318 completed and kept in memory.\n",
      "🔹 Processing batch 319/400 (1000 APIs)...\n",
      "✅ Batch 319 completed and kept in memory.\n",
      "🔹 Processing batch 320/400 (1000 APIs)...\n",
      "✅ Batch 320 completed and kept in memory.\n",
      "🔹 Processing batch 321/400 (1000 APIs)...\n",
      "✅ Batch 321 completed and kept in memory.\n",
      "🔹 Processing batch 322/400 (1000 APIs)...\n",
      "✅ Batch 322 completed and kept in memory.\n",
      "🔹 Processing batch 323/400 (1000 APIs)...\n",
      "✅ Batch 323 completed and kept in memory.\n",
      "🔹 Processing batch 324/400 (1000 APIs)...\n",
      "✅ Batch 324 completed and kept in memory.\n",
      "🔹 Processing batch 325/400 (1000 APIs)...\n",
      "✅ Batch 325 completed and kept in memory.\n",
      "🔹 Processing batch 326/400 (1000 APIs)...\n",
      "✅ Batch 326 completed and kept in memory.\n",
      "🔹 Processing batch 327/400 (1000 APIs)...\n",
      "✅ Batch 327 completed and kept in memory.\n",
      "🔹 Processing batch 328/400 (1000 APIs)...\n",
      "✅ Batch 328 completed and kept in memory.\n",
      "🔹 Processing batch 329/400 (1000 APIs)...\n",
      "✅ Batch 329 completed and kept in memory.\n",
      "🔹 Processing batch 330/400 (1000 APIs)...\n",
      "✅ Batch 330 completed and kept in memory.\n",
      "🔹 Processing batch 331/400 (1000 APIs)...\n",
      "✅ Batch 331 completed and kept in memory.\n",
      "🔹 Processing batch 332/400 (1000 APIs)...\n",
      "✅ Batch 332 completed and kept in memory.\n",
      "🔹 Processing batch 333/400 (1000 APIs)...\n",
      "✅ Batch 333 completed and kept in memory.\n",
      "🔹 Processing batch 334/400 (1000 APIs)...\n",
      "✅ Batch 334 completed and kept in memory.\n",
      "🔹 Processing batch 335/400 (1000 APIs)...\n",
      "✅ Batch 335 completed and kept in memory.\n",
      "🔹 Processing batch 336/400 (1000 APIs)...\n",
      "✅ Batch 336 completed and kept in memory.\n",
      "🔹 Processing batch 337/400 (1000 APIs)...\n",
      "✅ Batch 337 completed and kept in memory.\n",
      "🔹 Processing batch 338/400 (1000 APIs)...\n",
      "✅ Batch 338 completed and kept in memory.\n",
      "🔹 Processing batch 339/400 (1000 APIs)...\n",
      "✅ Batch 339 completed and kept in memory.\n",
      "🔹 Processing batch 340/400 (1000 APIs)...\n",
      "✅ Batch 340 completed and kept in memory.\n",
      "🔹 Processing batch 341/400 (1000 APIs)...\n",
      "✅ Batch 341 completed and kept in memory.\n",
      "🔹 Processing batch 342/400 (1000 APIs)...\n",
      "✅ Batch 342 completed and kept in memory.\n",
      "🔹 Processing batch 343/400 (1000 APIs)...\n",
      "✅ Batch 343 completed and kept in memory.\n",
      "🔹 Processing batch 344/400 (1000 APIs)...\n",
      "✅ Batch 344 completed and kept in memory.\n",
      "🔹 Processing batch 345/400 (1000 APIs)...\n",
      "✅ Batch 345 completed and kept in memory.\n",
      "🔹 Processing batch 346/400 (1000 APIs)...\n",
      "✅ Batch 346 completed and kept in memory.\n",
      "🔹 Processing batch 347/400 (1000 APIs)...\n",
      "✅ Batch 347 completed and kept in memory.\n",
      "🔹 Processing batch 348/400 (1000 APIs)...\n",
      "✅ Batch 348 completed and kept in memory.\n",
      "🔹 Processing batch 349/400 (1000 APIs)...\n",
      "✅ Batch 349 completed and kept in memory.\n",
      "🔹 Processing batch 350/400 (1000 APIs)...\n",
      "✅ Batch 350 completed and kept in memory.\n",
      "🔹 Processing batch 351/400 (1000 APIs)...\n",
      "✅ Batch 351 completed and kept in memory.\n",
      "🔹 Processing batch 352/400 (1000 APIs)...\n",
      "✅ Batch 352 completed and kept in memory.\n",
      "🔹 Processing batch 353/400 (1000 APIs)...\n",
      "✅ Batch 353 completed and kept in memory.\n",
      "🔹 Processing batch 354/400 (1000 APIs)...\n",
      "✅ Batch 354 completed and kept in memory.\n",
      "🔹 Processing batch 355/400 (1000 APIs)...\n",
      "✅ Batch 355 completed and kept in memory.\n",
      "🔹 Processing batch 356/400 (1000 APIs)...\n",
      "✅ Batch 356 completed and kept in memory.\n",
      "🔹 Processing batch 357/400 (1000 APIs)...\n",
      "✅ Batch 357 completed and kept in memory.\n",
      "🔹 Processing batch 358/400 (1000 APIs)...\n",
      "✅ Batch 358 completed and kept in memory.\n",
      "🔹 Processing batch 359/400 (1000 APIs)...\n",
      "✅ Batch 359 completed and kept in memory.\n",
      "🔹 Processing batch 360/400 (1000 APIs)...\n",
      "✅ Batch 360 completed and kept in memory.\n",
      "🔹 Processing batch 361/400 (1000 APIs)...\n",
      "✅ Batch 361 completed and kept in memory.\n",
      "🔹 Processing batch 362/400 (1000 APIs)...\n",
      "✅ Batch 362 completed and kept in memory.\n",
      "🔹 Processing batch 363/400 (1000 APIs)...\n",
      "✅ Batch 363 completed and kept in memory.\n",
      "🔹 Processing batch 364/400 (1000 APIs)...\n",
      "✅ Batch 364 completed and kept in memory.\n",
      "🔹 Processing batch 365/400 (1000 APIs)...\n",
      "✅ Batch 365 completed and kept in memory.\n",
      "🔹 Processing batch 366/400 (1000 APIs)...\n",
      "✅ Batch 366 completed and kept in memory.\n",
      "🔹 Processing batch 367/400 (1000 APIs)...\n",
      "✅ Batch 367 completed and kept in memory.\n",
      "🔹 Processing batch 368/400 (1000 APIs)...\n",
      "✅ Batch 368 completed and kept in memory.\n",
      "🔹 Processing batch 369/400 (1000 APIs)...\n",
      "✅ Batch 369 completed and kept in memory.\n",
      "🔹 Processing batch 370/400 (1000 APIs)...\n",
      "✅ Batch 370 completed and kept in memory.\n",
      "🔹 Processing batch 371/400 (1000 APIs)...\n",
      "✅ Batch 371 completed and kept in memory.\n",
      "🔹 Processing batch 372/400 (1000 APIs)...\n",
      "✅ Batch 372 completed and kept in memory.\n",
      "🔹 Processing batch 373/400 (1000 APIs)...\n",
      "✅ Batch 373 completed and kept in memory.\n",
      "🔹 Processing batch 374/400 (1000 APIs)...\n",
      "✅ Batch 374 completed and kept in memory.\n",
      "🔹 Processing batch 375/400 (1000 APIs)...\n",
      "✅ Batch 375 completed and kept in memory.\n",
      "🔹 Processing batch 376/400 (1000 APIs)...\n",
      "✅ Batch 376 completed and kept in memory.\n",
      "🔹 Processing batch 377/400 (1000 APIs)...\n",
      "✅ Batch 377 completed and kept in memory.\n",
      "🔹 Processing batch 378/400 (1000 APIs)...\n",
      "✅ Batch 378 completed and kept in memory.\n",
      "🔹 Processing batch 379/400 (1000 APIs)...\n",
      "✅ Batch 379 completed and kept in memory.\n",
      "🔹 Processing batch 380/400 (1000 APIs)...\n",
      "✅ Batch 380 completed and kept in memory.\n",
      "🔹 Processing batch 381/400 (1000 APIs)...\n",
      "✅ Batch 381 completed and kept in memory.\n",
      "🔹 Processing batch 382/400 (1000 APIs)...\n",
      "✅ Batch 382 completed and kept in memory.\n",
      "🔹 Processing batch 383/400 (1000 APIs)...\n",
      "✅ Batch 383 completed and kept in memory.\n",
      "🔹 Processing batch 384/400 (1000 APIs)...\n",
      "✅ Batch 384 completed and kept in memory.\n",
      "🔹 Processing batch 385/400 (1000 APIs)...\n",
      "✅ Batch 385 completed and kept in memory.\n",
      "🔹 Processing batch 386/400 (1000 APIs)...\n",
      "✅ Batch 386 completed and kept in memory.\n",
      "🔹 Processing batch 387/400 (1000 APIs)...\n",
      "✅ Batch 387 completed and kept in memory.\n",
      "🔹 Processing batch 388/400 (1000 APIs)...\n",
      "✅ Batch 388 completed and kept in memory.\n",
      "🔹 Processing batch 389/400 (1000 APIs)...\n",
      "✅ Batch 389 completed and kept in memory.\n",
      "🔹 Processing batch 390/400 (1000 APIs)...\n",
      "✅ Batch 390 completed and kept in memory.\n",
      "🔹 Processing batch 391/400 (1000 APIs)...\n",
      "✅ Batch 391 completed and kept in memory.\n",
      "🔹 Processing batch 392/400 (1000 APIs)...\n",
      "✅ Batch 392 completed and kept in memory.\n",
      "🔹 Processing batch 393/400 (1000 APIs)...\n",
      "✅ Batch 393 completed and kept in memory.\n",
      "🔹 Processing batch 394/400 (1000 APIs)...\n",
      "✅ Batch 394 completed and kept in memory.\n",
      "🔹 Processing batch 395/400 (1000 APIs)...\n",
      "✅ Batch 395 completed and kept in memory.\n",
      "🔹 Processing batch 396/400 (1000 APIs)...\n",
      "✅ Batch 396 completed and kept in memory.\n",
      "🔹 Processing batch 397/400 (1000 APIs)...\n",
      "✅ Batch 397 completed and kept in memory.\n",
      "🔹 Processing batch 398/400 (1000 APIs)...\n",
      "✅ Batch 398 completed and kept in memory.\n",
      "🔹 Processing batch 399/400 (1000 APIs)...\n",
      "✅ Batch 399 completed and kept in memory.\n",
      "🔹 Processing batch 400/400 (39 APIs)...\n",
      "✅ Batch 400 completed and kept in memory.\n",
      "✅ All 400 batches processed.\n",
      "🔄 Concatenating 400 batches into final DataFrame...\n"
     ]
    }
   ],
   "source": [
    "cols_to_fill = [\n",
    "    'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last',\n",
    "    'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6'\n",
    "]\n",
    "backfill_df = batch_merge_and_backfill_dask(forecast_df, bfill_helper, cols_to_fill, batch_size=1000, write_batches_to_disk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "576a0108-6ecf-455b-8a69-8bd7cec83c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "backfill_df.to_parquet('../data/forecast_4_backfill.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bb26466-a676-4468-9b75-f23a23f5cd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: BACKFILL_DF\n",
      "============================================================\n",
      "Shape: ((20000000, 11))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 string          20000000   1000       0.0       %\n",
      "date_prod                 datetime64[ns]  20000000   50         0.0       %\n",
      "last_year                 float64         20000000   5          0.0       %\n",
      "last_month                float64         20000000   13         0.0       %\n",
      "last_gas                  float64         20000000   7337       0.0       %\n",
      "last_oil                  float64         20000000   2939       0.0       %\n",
      "months_since_last         float64         20000000   4          0.0       %\n",
      "gas_avg_3                 float64         20000000   11575      0.0       %\n",
      "oil_avg_3                 float64         20000000   4893       0.0       %\n",
      "gas_avg_6                 float64         20000000   14699      0.0       %\n",
      "oil_avg_6                 float64         20000000   6824       0.0       %\n"
     ]
    }
   ],
   "source": [
    "comprehensive_data_overview_dask({'backfill_df': backfill_df})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca033f-dbf7-4064-8ce7-ec6eac0d3728",
   "metadata": {},
   "source": [
    "Something looks very wrong here, there are 1000 api_no_10 as if only one batch of apis was processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca46e2f2-0b7b-412c-858b-96eb116bcc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backfill_df['api_no_10'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c421097-f728-48f2-9b8c-2b02efa8a247",
   "metadata": {},
   "source": [
    "The take column do have a subtle mismatch in datatype, I'm not sure that's the problem but I can't think of anything else so let's try fixing this and then running again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9609d32-67f7-4878-925c-a683145b8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df['date_prod'] = forecast_df['date_prod'].astype('datetime64[ns]')\n",
    "bfill_helper['date_prod'] = bfill_helper['date_prod'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa590b97-b3ac-4062-947d-bf7ad2e3b252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total unique APIs: 399039\n",
      "✅ Batch size: 1000\n",
      "✅ Total batches: 400\n",
      "🔹 Processing batch 1/400 (1000 APIs)...\n",
      "✅ Batch 1 completed and kept in memory.\n",
      "🔹 Processing batch 2/400 (1000 APIs)...\n",
      "✅ Batch 2 completed and kept in memory.\n",
      "🔹 Processing batch 3/400 (1000 APIs)...\n",
      "✅ Batch 3 completed and kept in memory.\n",
      "🔹 Processing batch 4/400 (1000 APIs)...\n",
      "✅ Batch 4 completed and kept in memory.\n",
      "🔹 Processing batch 5/400 (1000 APIs)...\n",
      "✅ Batch 5 completed and kept in memory.\n",
      "🔹 Processing batch 6/400 (1000 APIs)...\n",
      "✅ Batch 6 completed and kept in memory.\n",
      "🔹 Processing batch 7/400 (1000 APIs)...\n",
      "✅ Batch 7 completed and kept in memory.\n",
      "🔹 Processing batch 8/400 (1000 APIs)...\n",
      "✅ Batch 8 completed and kept in memory.\n",
      "🔹 Processing batch 9/400 (1000 APIs)...\n",
      "✅ Batch 9 completed and kept in memory.\n",
      "🔹 Processing batch 10/400 (1000 APIs)...\n",
      "✅ Batch 10 completed and kept in memory.\n",
      "🔹 Processing batch 11/400 (1000 APIs)...\n",
      "✅ Batch 11 completed and kept in memory.\n",
      "🔹 Processing batch 12/400 (1000 APIs)...\n",
      "✅ Batch 12 completed and kept in memory.\n",
      "🔹 Processing batch 13/400 (1000 APIs)...\n",
      "✅ Batch 13 completed and kept in memory.\n",
      "🔹 Processing batch 14/400 (1000 APIs)...\n",
      "✅ Batch 14 completed and kept in memory.\n",
      "🔹 Processing batch 15/400 (1000 APIs)...\n",
      "✅ Batch 15 completed and kept in memory.\n",
      "🔹 Processing batch 16/400 (1000 APIs)...\n",
      "✅ Batch 16 completed and kept in memory.\n",
      "🔹 Processing batch 17/400 (1000 APIs)...\n",
      "✅ Batch 17 completed and kept in memory.\n",
      "🔹 Processing batch 18/400 (1000 APIs)...\n",
      "✅ Batch 18 completed and kept in memory.\n",
      "🔹 Processing batch 19/400 (1000 APIs)...\n",
      "✅ Batch 19 completed and kept in memory.\n",
      "🔹 Processing batch 20/400 (1000 APIs)...\n",
      "✅ Batch 20 completed and kept in memory.\n",
      "🔹 Processing batch 21/400 (1000 APIs)...\n",
      "✅ Batch 21 completed and kept in memory.\n",
      "🔹 Processing batch 22/400 (1000 APIs)...\n",
      "✅ Batch 22 completed and kept in memory.\n",
      "🔹 Processing batch 23/400 (1000 APIs)...\n",
      "✅ Batch 23 completed and kept in memory.\n",
      "🔹 Processing batch 24/400 (1000 APIs)...\n",
      "✅ Batch 24 completed and kept in memory.\n",
      "🔹 Processing batch 25/400 (1000 APIs)...\n",
      "✅ Batch 25 completed and kept in memory.\n",
      "🔹 Processing batch 26/400 (1000 APIs)...\n",
      "✅ Batch 26 completed and kept in memory.\n",
      "🔹 Processing batch 27/400 (1000 APIs)...\n",
      "✅ Batch 27 completed and kept in memory.\n",
      "🔹 Processing batch 28/400 (1000 APIs)...\n",
      "✅ Batch 28 completed and kept in memory.\n",
      "🔹 Processing batch 29/400 (1000 APIs)...\n",
      "✅ Batch 29 completed and kept in memory.\n",
      "🔹 Processing batch 30/400 (1000 APIs)...\n",
      "✅ Batch 30 completed and kept in memory.\n",
      "🔹 Processing batch 31/400 (1000 APIs)...\n",
      "✅ Batch 31 completed and kept in memory.\n",
      "🔹 Processing batch 32/400 (1000 APIs)...\n",
      "✅ Batch 32 completed and kept in memory.\n",
      "🔹 Processing batch 33/400 (1000 APIs)...\n",
      "✅ Batch 33 completed and kept in memory.\n",
      "🔹 Processing batch 34/400 (1000 APIs)...\n",
      "✅ Batch 34 completed and kept in memory.\n",
      "🔹 Processing batch 35/400 (1000 APIs)...\n",
      "✅ Batch 35 completed and kept in memory.\n",
      "🔹 Processing batch 36/400 (1000 APIs)...\n",
      "✅ Batch 36 completed and kept in memory.\n",
      "🔹 Processing batch 37/400 (1000 APIs)...\n",
      "✅ Batch 37 completed and kept in memory.\n",
      "🔹 Processing batch 38/400 (1000 APIs)...\n",
      "✅ Batch 38 completed and kept in memory.\n",
      "🔹 Processing batch 39/400 (1000 APIs)...\n",
      "✅ Batch 39 completed and kept in memory.\n",
      "🔹 Processing batch 40/400 (1000 APIs)...\n",
      "✅ Batch 40 completed and kept in memory.\n",
      "🔹 Processing batch 41/400 (1000 APIs)...\n",
      "✅ Batch 41 completed and kept in memory.\n",
      "🔹 Processing batch 42/400 (1000 APIs)...\n",
      "✅ Batch 42 completed and kept in memory.\n",
      "🔹 Processing batch 43/400 (1000 APIs)...\n",
      "✅ Batch 43 completed and kept in memory.\n",
      "🔹 Processing batch 44/400 (1000 APIs)...\n",
      "✅ Batch 44 completed and kept in memory.\n",
      "🔹 Processing batch 45/400 (1000 APIs)...\n",
      "✅ Batch 45 completed and kept in memory.\n",
      "🔹 Processing batch 46/400 (1000 APIs)...\n",
      "✅ Batch 46 completed and kept in memory.\n",
      "🔹 Processing batch 47/400 (1000 APIs)...\n",
      "✅ Batch 47 completed and kept in memory.\n",
      "🔹 Processing batch 48/400 (1000 APIs)...\n",
      "✅ Batch 48 completed and kept in memory.\n",
      "🔹 Processing batch 49/400 (1000 APIs)...\n",
      "✅ Batch 49 completed and kept in memory.\n",
      "🔹 Processing batch 50/400 (1000 APIs)...\n",
      "✅ Batch 50 completed and kept in memory.\n",
      "🔹 Processing batch 51/400 (1000 APIs)...\n",
      "✅ Batch 51 completed and kept in memory.\n",
      "🔹 Processing batch 52/400 (1000 APIs)...\n",
      "✅ Batch 52 completed and kept in memory.\n",
      "🔹 Processing batch 53/400 (1000 APIs)...\n",
      "✅ Batch 53 completed and kept in memory.\n",
      "🔹 Processing batch 54/400 (1000 APIs)...\n",
      "✅ Batch 54 completed and kept in memory.\n",
      "🔹 Processing batch 55/400 (1000 APIs)...\n",
      "✅ Batch 55 completed and kept in memory.\n",
      "🔹 Processing batch 56/400 (1000 APIs)...\n",
      "✅ Batch 56 completed and kept in memory.\n",
      "🔹 Processing batch 57/400 (1000 APIs)...\n",
      "✅ Batch 57 completed and kept in memory.\n",
      "🔹 Processing batch 58/400 (1000 APIs)...\n",
      "✅ Batch 58 completed and kept in memory.\n",
      "🔹 Processing batch 59/400 (1000 APIs)...\n",
      "✅ Batch 59 completed and kept in memory.\n",
      "🔹 Processing batch 60/400 (1000 APIs)...\n",
      "✅ Batch 60 completed and kept in memory.\n",
      "🔹 Processing batch 61/400 (1000 APIs)...\n",
      "✅ Batch 61 completed and kept in memory.\n",
      "🔹 Processing batch 62/400 (1000 APIs)...\n",
      "✅ Batch 62 completed and kept in memory.\n",
      "🔹 Processing batch 63/400 (1000 APIs)...\n",
      "✅ Batch 63 completed and kept in memory.\n",
      "🔹 Processing batch 64/400 (1000 APIs)...\n",
      "✅ Batch 64 completed and kept in memory.\n",
      "🔹 Processing batch 65/400 (1000 APIs)...\n",
      "✅ Batch 65 completed and kept in memory.\n",
      "🔹 Processing batch 66/400 (1000 APIs)...\n",
      "✅ Batch 66 completed and kept in memory.\n",
      "🔹 Processing batch 67/400 (1000 APIs)...\n",
      "✅ Batch 67 completed and kept in memory.\n",
      "🔹 Processing batch 68/400 (1000 APIs)...\n",
      "✅ Batch 68 completed and kept in memory.\n",
      "🔹 Processing batch 69/400 (1000 APIs)...\n",
      "✅ Batch 69 completed and kept in memory.\n",
      "🔹 Processing batch 70/400 (1000 APIs)...\n",
      "✅ Batch 70 completed and kept in memory.\n",
      "🔹 Processing batch 71/400 (1000 APIs)...\n",
      "✅ Batch 71 completed and kept in memory.\n",
      "🔹 Processing batch 72/400 (1000 APIs)...\n",
      "✅ Batch 72 completed and kept in memory.\n",
      "🔹 Processing batch 73/400 (1000 APIs)...\n",
      "✅ Batch 73 completed and kept in memory.\n",
      "🔹 Processing batch 74/400 (1000 APIs)...\n",
      "✅ Batch 74 completed and kept in memory.\n",
      "🔹 Processing batch 75/400 (1000 APIs)...\n",
      "✅ Batch 75 completed and kept in memory.\n",
      "🔹 Processing batch 76/400 (1000 APIs)...\n",
      "✅ Batch 76 completed and kept in memory.\n",
      "🔹 Processing batch 77/400 (1000 APIs)...\n",
      "✅ Batch 77 completed and kept in memory.\n",
      "🔹 Processing batch 78/400 (1000 APIs)...\n",
      "✅ Batch 78 completed and kept in memory.\n",
      "🔹 Processing batch 79/400 (1000 APIs)...\n",
      "✅ Batch 79 completed and kept in memory.\n",
      "🔹 Processing batch 80/400 (1000 APIs)...\n",
      "✅ Batch 80 completed and kept in memory.\n",
      "🔹 Processing batch 81/400 (1000 APIs)...\n",
      "✅ Batch 81 completed and kept in memory.\n",
      "🔹 Processing batch 82/400 (1000 APIs)...\n",
      "✅ Batch 82 completed and kept in memory.\n",
      "🔹 Processing batch 83/400 (1000 APIs)...\n",
      "✅ Batch 83 completed and kept in memory.\n",
      "🔹 Processing batch 84/400 (1000 APIs)...\n",
      "✅ Batch 84 completed and kept in memory.\n",
      "🔹 Processing batch 85/400 (1000 APIs)...\n",
      "✅ Batch 85 completed and kept in memory.\n",
      "🔹 Processing batch 86/400 (1000 APIs)...\n",
      "✅ Batch 86 completed and kept in memory.\n",
      "🔹 Processing batch 87/400 (1000 APIs)...\n",
      "✅ Batch 87 completed and kept in memory.\n",
      "🔹 Processing batch 88/400 (1000 APIs)...\n",
      "✅ Batch 88 completed and kept in memory.\n",
      "🔹 Processing batch 89/400 (1000 APIs)...\n",
      "✅ Batch 89 completed and kept in memory.\n",
      "🔹 Processing batch 90/400 (1000 APIs)...\n",
      "✅ Batch 90 completed and kept in memory.\n",
      "🔹 Processing batch 91/400 (1000 APIs)...\n",
      "✅ Batch 91 completed and kept in memory.\n",
      "🔹 Processing batch 92/400 (1000 APIs)...\n",
      "✅ Batch 92 completed and kept in memory.\n",
      "🔹 Processing batch 93/400 (1000 APIs)...\n",
      "✅ Batch 93 completed and kept in memory.\n",
      "🔹 Processing batch 94/400 (1000 APIs)...\n",
      "✅ Batch 94 completed and kept in memory.\n",
      "🔹 Processing batch 95/400 (1000 APIs)...\n",
      "✅ Batch 95 completed and kept in memory.\n",
      "🔹 Processing batch 96/400 (1000 APIs)...\n",
      "✅ Batch 96 completed and kept in memory.\n",
      "🔹 Processing batch 97/400 (1000 APIs)...\n",
      "✅ Batch 97 completed and kept in memory.\n",
      "🔹 Processing batch 98/400 (1000 APIs)...\n",
      "✅ Batch 98 completed and kept in memory.\n",
      "🔹 Processing batch 99/400 (1000 APIs)...\n",
      "✅ Batch 99 completed and kept in memory.\n",
      "🔹 Processing batch 100/400 (1000 APIs)...\n",
      "✅ Batch 100 completed and kept in memory.\n",
      "🔹 Processing batch 101/400 (1000 APIs)...\n",
      "✅ Batch 101 completed and kept in memory.\n",
      "🔹 Processing batch 102/400 (1000 APIs)...\n",
      "✅ Batch 102 completed and kept in memory.\n",
      "🔹 Processing batch 103/400 (1000 APIs)...\n",
      "✅ Batch 103 completed and kept in memory.\n",
      "🔹 Processing batch 104/400 (1000 APIs)...\n",
      "✅ Batch 104 completed and kept in memory.\n",
      "🔹 Processing batch 105/400 (1000 APIs)...\n",
      "✅ Batch 105 completed and kept in memory.\n",
      "🔹 Processing batch 106/400 (1000 APIs)...\n",
      "✅ Batch 106 completed and kept in memory.\n",
      "🔹 Processing batch 107/400 (1000 APIs)...\n",
      "✅ Batch 107 completed and kept in memory.\n",
      "🔹 Processing batch 108/400 (1000 APIs)...\n",
      "✅ Batch 108 completed and kept in memory.\n",
      "🔹 Processing batch 109/400 (1000 APIs)...\n",
      "✅ Batch 109 completed and kept in memory.\n",
      "🔹 Processing batch 110/400 (1000 APIs)...\n",
      "✅ Batch 110 completed and kept in memory.\n",
      "🔹 Processing batch 111/400 (1000 APIs)...\n",
      "✅ Batch 111 completed and kept in memory.\n",
      "🔹 Processing batch 112/400 (1000 APIs)...\n",
      "✅ Batch 112 completed and kept in memory.\n",
      "🔹 Processing batch 113/400 (1000 APIs)...\n",
      "✅ Batch 113 completed and kept in memory.\n",
      "🔹 Processing batch 114/400 (1000 APIs)...\n",
      "✅ Batch 114 completed and kept in memory.\n",
      "🔹 Processing batch 115/400 (1000 APIs)...\n",
      "✅ Batch 115 completed and kept in memory.\n",
      "🔹 Processing batch 116/400 (1000 APIs)...\n",
      "✅ Batch 116 completed and kept in memory.\n",
      "🔹 Processing batch 117/400 (1000 APIs)...\n",
      "✅ Batch 117 completed and kept in memory.\n",
      "🔹 Processing batch 118/400 (1000 APIs)...\n",
      "✅ Batch 118 completed and kept in memory.\n",
      "🔹 Processing batch 119/400 (1000 APIs)...\n",
      "✅ Batch 119 completed and kept in memory.\n",
      "🔹 Processing batch 120/400 (1000 APIs)...\n",
      "✅ Batch 120 completed and kept in memory.\n",
      "🔹 Processing batch 121/400 (1000 APIs)...\n",
      "✅ Batch 121 completed and kept in memory.\n",
      "🔹 Processing batch 122/400 (1000 APIs)...\n",
      "✅ Batch 122 completed and kept in memory.\n",
      "🔹 Processing batch 123/400 (1000 APIs)...\n",
      "✅ Batch 123 completed and kept in memory.\n",
      "🔹 Processing batch 124/400 (1000 APIs)...\n",
      "✅ Batch 124 completed and kept in memory.\n",
      "🔹 Processing batch 125/400 (1000 APIs)...\n",
      "✅ Batch 125 completed and kept in memory.\n",
      "🔹 Processing batch 126/400 (1000 APIs)...\n",
      "✅ Batch 126 completed and kept in memory.\n",
      "🔹 Processing batch 127/400 (1000 APIs)...\n",
      "✅ Batch 127 completed and kept in memory.\n",
      "🔹 Processing batch 128/400 (1000 APIs)...\n",
      "✅ Batch 128 completed and kept in memory.\n",
      "🔹 Processing batch 129/400 (1000 APIs)...\n",
      "✅ Batch 129 completed and kept in memory.\n",
      "🔹 Processing batch 130/400 (1000 APIs)...\n",
      "✅ Batch 130 completed and kept in memory.\n",
      "🔹 Processing batch 131/400 (1000 APIs)...\n",
      "✅ Batch 131 completed and kept in memory.\n",
      "🔹 Processing batch 132/400 (1000 APIs)...\n",
      "✅ Batch 132 completed and kept in memory.\n",
      "🔹 Processing batch 133/400 (1000 APIs)...\n",
      "✅ Batch 133 completed and kept in memory.\n",
      "🔹 Processing batch 134/400 (1000 APIs)...\n",
      "✅ Batch 134 completed and kept in memory.\n",
      "🔹 Processing batch 135/400 (1000 APIs)...\n",
      "✅ Batch 135 completed and kept in memory.\n",
      "🔹 Processing batch 136/400 (1000 APIs)...\n",
      "✅ Batch 136 completed and kept in memory.\n",
      "🔹 Processing batch 137/400 (1000 APIs)...\n",
      "✅ Batch 137 completed and kept in memory.\n",
      "🔹 Processing batch 138/400 (1000 APIs)...\n",
      "✅ Batch 138 completed and kept in memory.\n",
      "🔹 Processing batch 139/400 (1000 APIs)...\n",
      "✅ Batch 139 completed and kept in memory.\n",
      "🔹 Processing batch 140/400 (1000 APIs)...\n",
      "✅ Batch 140 completed and kept in memory.\n",
      "🔹 Processing batch 141/400 (1000 APIs)...\n",
      "✅ Batch 141 completed and kept in memory.\n",
      "🔹 Processing batch 142/400 (1000 APIs)...\n",
      "✅ Batch 142 completed and kept in memory.\n",
      "🔹 Processing batch 143/400 (1000 APIs)...\n",
      "✅ Batch 143 completed and kept in memory.\n",
      "🔹 Processing batch 144/400 (1000 APIs)...\n",
      "✅ Batch 144 completed and kept in memory.\n",
      "🔹 Processing batch 145/400 (1000 APIs)...\n",
      "✅ Batch 145 completed and kept in memory.\n",
      "🔹 Processing batch 146/400 (1000 APIs)...\n",
      "✅ Batch 146 completed and kept in memory.\n",
      "🔹 Processing batch 147/400 (1000 APIs)...\n",
      "✅ Batch 147 completed and kept in memory.\n",
      "🔹 Processing batch 148/400 (1000 APIs)...\n",
      "✅ Batch 148 completed and kept in memory.\n",
      "🔹 Processing batch 149/400 (1000 APIs)...\n",
      "✅ Batch 149 completed and kept in memory.\n",
      "🔹 Processing batch 150/400 (1000 APIs)...\n",
      "✅ Batch 150 completed and kept in memory.\n",
      "🔹 Processing batch 151/400 (1000 APIs)...\n",
      "✅ Batch 151 completed and kept in memory.\n",
      "🔹 Processing batch 152/400 (1000 APIs)...\n",
      "✅ Batch 152 completed and kept in memory.\n",
      "🔹 Processing batch 153/400 (1000 APIs)...\n",
      "✅ Batch 153 completed and kept in memory.\n",
      "🔹 Processing batch 154/400 (1000 APIs)...\n",
      "✅ Batch 154 completed and kept in memory.\n",
      "🔹 Processing batch 155/400 (1000 APIs)...\n",
      "✅ Batch 155 completed and kept in memory.\n",
      "🔹 Processing batch 156/400 (1000 APIs)...\n",
      "✅ Batch 156 completed and kept in memory.\n",
      "🔹 Processing batch 157/400 (1000 APIs)...\n",
      "✅ Batch 157 completed and kept in memory.\n",
      "🔹 Processing batch 158/400 (1000 APIs)...\n",
      "✅ Batch 158 completed and kept in memory.\n",
      "🔹 Processing batch 159/400 (1000 APIs)...\n",
      "✅ Batch 159 completed and kept in memory.\n",
      "🔹 Processing batch 160/400 (1000 APIs)...\n",
      "✅ Batch 160 completed and kept in memory.\n",
      "🔹 Processing batch 161/400 (1000 APIs)...\n",
      "✅ Batch 161 completed and kept in memory.\n",
      "🔹 Processing batch 162/400 (1000 APIs)...\n",
      "✅ Batch 162 completed and kept in memory.\n",
      "🔹 Processing batch 163/400 (1000 APIs)...\n",
      "✅ Batch 163 completed and kept in memory.\n",
      "🔹 Processing batch 164/400 (1000 APIs)...\n",
      "✅ Batch 164 completed and kept in memory.\n",
      "🔹 Processing batch 165/400 (1000 APIs)...\n",
      "✅ Batch 165 completed and kept in memory.\n",
      "🔹 Processing batch 166/400 (1000 APIs)...\n",
      "✅ Batch 166 completed and kept in memory.\n",
      "🔹 Processing batch 167/400 (1000 APIs)...\n",
      "✅ Batch 167 completed and kept in memory.\n",
      "🔹 Processing batch 168/400 (1000 APIs)...\n",
      "✅ Batch 168 completed and kept in memory.\n",
      "🔹 Processing batch 169/400 (1000 APIs)...\n",
      "✅ Batch 169 completed and kept in memory.\n",
      "🔹 Processing batch 170/400 (1000 APIs)...\n",
      "✅ Batch 170 completed and kept in memory.\n",
      "🔹 Processing batch 171/400 (1000 APIs)...\n",
      "✅ Batch 171 completed and kept in memory.\n",
      "🔹 Processing batch 172/400 (1000 APIs)...\n",
      "✅ Batch 172 completed and kept in memory.\n",
      "🔹 Processing batch 173/400 (1000 APIs)...\n",
      "✅ Batch 173 completed and kept in memory.\n",
      "🔹 Processing batch 174/400 (1000 APIs)...\n",
      "✅ Batch 174 completed and kept in memory.\n",
      "🔹 Processing batch 175/400 (1000 APIs)...\n",
      "✅ Batch 175 completed and kept in memory.\n",
      "🔹 Processing batch 176/400 (1000 APIs)...\n",
      "✅ Batch 176 completed and kept in memory.\n",
      "🔹 Processing batch 177/400 (1000 APIs)...\n",
      "✅ Batch 177 completed and kept in memory.\n",
      "🔹 Processing batch 178/400 (1000 APIs)...\n",
      "✅ Batch 178 completed and kept in memory.\n",
      "🔹 Processing batch 179/400 (1000 APIs)...\n",
      "✅ Batch 179 completed and kept in memory.\n",
      "🔹 Processing batch 180/400 (1000 APIs)...\n",
      "✅ Batch 180 completed and kept in memory.\n",
      "🔹 Processing batch 181/400 (1000 APIs)...\n",
      "✅ Batch 181 completed and kept in memory.\n",
      "🔹 Processing batch 182/400 (1000 APIs)...\n",
      "✅ Batch 182 completed and kept in memory.\n",
      "🔹 Processing batch 183/400 (1000 APIs)...\n",
      "✅ Batch 183 completed and kept in memory.\n",
      "🔹 Processing batch 184/400 (1000 APIs)...\n",
      "✅ Batch 184 completed and kept in memory.\n",
      "🔹 Processing batch 185/400 (1000 APIs)...\n",
      "✅ Batch 185 completed and kept in memory.\n",
      "🔹 Processing batch 186/400 (1000 APIs)...\n",
      "✅ Batch 186 completed and kept in memory.\n",
      "🔹 Processing batch 187/400 (1000 APIs)...\n",
      "✅ Batch 187 completed and kept in memory.\n",
      "🔹 Processing batch 188/400 (1000 APIs)...\n",
      "✅ Batch 188 completed and kept in memory.\n",
      "🔹 Processing batch 189/400 (1000 APIs)...\n",
      "✅ Batch 189 completed and kept in memory.\n",
      "🔹 Processing batch 190/400 (1000 APIs)...\n",
      "✅ Batch 190 completed and kept in memory.\n",
      "🔹 Processing batch 191/400 (1000 APIs)...\n",
      "✅ Batch 191 completed and kept in memory.\n",
      "🔹 Processing batch 192/400 (1000 APIs)...\n",
      "✅ Batch 192 completed and kept in memory.\n",
      "🔹 Processing batch 193/400 (1000 APIs)...\n",
      "✅ Batch 193 completed and kept in memory.\n",
      "🔹 Processing batch 194/400 (1000 APIs)...\n",
      "✅ Batch 194 completed and kept in memory.\n",
      "🔹 Processing batch 195/400 (1000 APIs)...\n",
      "✅ Batch 195 completed and kept in memory.\n",
      "🔹 Processing batch 196/400 (1000 APIs)...\n",
      "✅ Batch 196 completed and kept in memory.\n",
      "🔹 Processing batch 197/400 (1000 APIs)...\n",
      "✅ Batch 197 completed and kept in memory.\n",
      "🔹 Processing batch 198/400 (1000 APIs)...\n",
      "✅ Batch 198 completed and kept in memory.\n",
      "🔹 Processing batch 199/400 (1000 APIs)...\n",
      "✅ Batch 199 completed and kept in memory.\n",
      "🔹 Processing batch 200/400 (1000 APIs)...\n",
      "✅ Batch 200 completed and kept in memory.\n",
      "🔹 Processing batch 201/400 (1000 APIs)...\n",
      "✅ Batch 201 completed and kept in memory.\n",
      "🔹 Processing batch 202/400 (1000 APIs)...\n",
      "✅ Batch 202 completed and kept in memory.\n",
      "🔹 Processing batch 203/400 (1000 APIs)...\n",
      "✅ Batch 203 completed and kept in memory.\n",
      "🔹 Processing batch 204/400 (1000 APIs)...\n",
      "✅ Batch 204 completed and kept in memory.\n",
      "🔹 Processing batch 205/400 (1000 APIs)...\n",
      "✅ Batch 205 completed and kept in memory.\n",
      "🔹 Processing batch 206/400 (1000 APIs)...\n",
      "✅ Batch 206 completed and kept in memory.\n",
      "🔹 Processing batch 207/400 (1000 APIs)...\n",
      "✅ Batch 207 completed and kept in memory.\n",
      "🔹 Processing batch 208/400 (1000 APIs)...\n",
      "✅ Batch 208 completed and kept in memory.\n",
      "🔹 Processing batch 209/400 (1000 APIs)...\n",
      "✅ Batch 209 completed and kept in memory.\n",
      "🔹 Processing batch 210/400 (1000 APIs)...\n",
      "✅ Batch 210 completed and kept in memory.\n",
      "🔹 Processing batch 211/400 (1000 APIs)...\n",
      "✅ Batch 211 completed and kept in memory.\n",
      "🔹 Processing batch 212/400 (1000 APIs)...\n",
      "✅ Batch 212 completed and kept in memory.\n",
      "🔹 Processing batch 213/400 (1000 APIs)...\n",
      "✅ Batch 213 completed and kept in memory.\n",
      "🔹 Processing batch 214/400 (1000 APIs)...\n",
      "✅ Batch 214 completed and kept in memory.\n",
      "🔹 Processing batch 215/400 (1000 APIs)...\n",
      "✅ Batch 215 completed and kept in memory.\n",
      "🔹 Processing batch 216/400 (1000 APIs)...\n",
      "✅ Batch 216 completed and kept in memory.\n",
      "🔹 Processing batch 217/400 (1000 APIs)...\n",
      "✅ Batch 217 completed and kept in memory.\n",
      "🔹 Processing batch 218/400 (1000 APIs)...\n",
      "✅ Batch 218 completed and kept in memory.\n",
      "🔹 Processing batch 219/400 (1000 APIs)...\n",
      "✅ Batch 219 completed and kept in memory.\n",
      "🔹 Processing batch 220/400 (1000 APIs)...\n",
      "✅ Batch 220 completed and kept in memory.\n",
      "🔹 Processing batch 221/400 (1000 APIs)...\n",
      "✅ Batch 221 completed and kept in memory.\n",
      "🔹 Processing batch 222/400 (1000 APIs)...\n",
      "✅ Batch 222 completed and kept in memory.\n",
      "🔹 Processing batch 223/400 (1000 APIs)...\n",
      "✅ Batch 223 completed and kept in memory.\n",
      "🔹 Processing batch 224/400 (1000 APIs)...\n",
      "✅ Batch 224 completed and kept in memory.\n",
      "🔹 Processing batch 225/400 (1000 APIs)...\n",
      "✅ Batch 225 completed and kept in memory.\n",
      "🔹 Processing batch 226/400 (1000 APIs)...\n",
      "✅ Batch 226 completed and kept in memory.\n",
      "🔹 Processing batch 227/400 (1000 APIs)...\n",
      "✅ Batch 227 completed and kept in memory.\n",
      "🔹 Processing batch 228/400 (1000 APIs)...\n",
      "✅ Batch 228 completed and kept in memory.\n",
      "🔹 Processing batch 229/400 (1000 APIs)...\n",
      "✅ Batch 229 completed and kept in memory.\n",
      "🔹 Processing batch 230/400 (1000 APIs)...\n",
      "✅ Batch 230 completed and kept in memory.\n",
      "🔹 Processing batch 231/400 (1000 APIs)...\n",
      "✅ Batch 231 completed and kept in memory.\n",
      "🔹 Processing batch 232/400 (1000 APIs)...\n",
      "✅ Batch 232 completed and kept in memory.\n",
      "🔹 Processing batch 233/400 (1000 APIs)...\n",
      "✅ Batch 233 completed and kept in memory.\n",
      "🔹 Processing batch 234/400 (1000 APIs)...\n",
      "✅ Batch 234 completed and kept in memory.\n",
      "🔹 Processing batch 235/400 (1000 APIs)...\n",
      "✅ Batch 235 completed and kept in memory.\n",
      "🔹 Processing batch 236/400 (1000 APIs)...\n",
      "✅ Batch 236 completed and kept in memory.\n",
      "🔹 Processing batch 237/400 (1000 APIs)...\n",
      "✅ Batch 237 completed and kept in memory.\n",
      "🔹 Processing batch 238/400 (1000 APIs)...\n",
      "✅ Batch 238 completed and kept in memory.\n",
      "🔹 Processing batch 239/400 (1000 APIs)...\n",
      "✅ Batch 239 completed and kept in memory.\n",
      "🔹 Processing batch 240/400 (1000 APIs)...\n",
      "✅ Batch 240 completed and kept in memory.\n",
      "🔹 Processing batch 241/400 (1000 APIs)...\n",
      "✅ Batch 241 completed and kept in memory.\n",
      "🔹 Processing batch 242/400 (1000 APIs)...\n",
      "✅ Batch 242 completed and kept in memory.\n",
      "🔹 Processing batch 243/400 (1000 APIs)...\n",
      "✅ Batch 243 completed and kept in memory.\n",
      "🔹 Processing batch 244/400 (1000 APIs)...\n",
      "✅ Batch 244 completed and kept in memory.\n",
      "🔹 Processing batch 245/400 (1000 APIs)...\n",
      "✅ Batch 245 completed and kept in memory.\n",
      "🔹 Processing batch 246/400 (1000 APIs)...\n",
      "✅ Batch 246 completed and kept in memory.\n",
      "🔹 Processing batch 247/400 (1000 APIs)...\n",
      "✅ Batch 247 completed and kept in memory.\n",
      "🔹 Processing batch 248/400 (1000 APIs)...\n",
      "✅ Batch 248 completed and kept in memory.\n",
      "🔹 Processing batch 249/400 (1000 APIs)...\n",
      "✅ Batch 249 completed and kept in memory.\n",
      "🔹 Processing batch 250/400 (1000 APIs)...\n",
      "✅ Batch 250 completed and kept in memory.\n",
      "🔹 Processing batch 251/400 (1000 APIs)...\n",
      "✅ Batch 251 completed and kept in memory.\n",
      "🔹 Processing batch 252/400 (1000 APIs)...\n",
      "✅ Batch 252 completed and kept in memory.\n",
      "🔹 Processing batch 253/400 (1000 APIs)...\n",
      "✅ Batch 253 completed and kept in memory.\n",
      "🔹 Processing batch 254/400 (1000 APIs)...\n",
      "✅ Batch 254 completed and kept in memory.\n",
      "🔹 Processing batch 255/400 (1000 APIs)...\n",
      "✅ Batch 255 completed and kept in memory.\n",
      "🔹 Processing batch 256/400 (1000 APIs)...\n",
      "✅ Batch 256 completed and kept in memory.\n",
      "🔹 Processing batch 257/400 (1000 APIs)...\n",
      "✅ Batch 257 completed and kept in memory.\n",
      "🔹 Processing batch 258/400 (1000 APIs)...\n",
      "✅ Batch 258 completed and kept in memory.\n",
      "🔹 Processing batch 259/400 (1000 APIs)...\n",
      "✅ Batch 259 completed and kept in memory.\n",
      "🔹 Processing batch 260/400 (1000 APIs)...\n",
      "✅ Batch 260 completed and kept in memory.\n",
      "🔹 Processing batch 261/400 (1000 APIs)...\n",
      "✅ Batch 261 completed and kept in memory.\n",
      "🔹 Processing batch 262/400 (1000 APIs)...\n",
      "✅ Batch 262 completed and kept in memory.\n",
      "🔹 Processing batch 263/400 (1000 APIs)...\n",
      "✅ Batch 263 completed and kept in memory.\n",
      "🔹 Processing batch 264/400 (1000 APIs)...\n",
      "✅ Batch 264 completed and kept in memory.\n",
      "🔹 Processing batch 265/400 (1000 APIs)...\n",
      "✅ Batch 265 completed and kept in memory.\n",
      "🔹 Processing batch 266/400 (1000 APIs)...\n",
      "✅ Batch 266 completed and kept in memory.\n",
      "🔹 Processing batch 267/400 (1000 APIs)...\n",
      "✅ Batch 267 completed and kept in memory.\n",
      "🔹 Processing batch 268/400 (1000 APIs)...\n",
      "✅ Batch 268 completed and kept in memory.\n",
      "🔹 Processing batch 269/400 (1000 APIs)...\n",
      "✅ Batch 269 completed and kept in memory.\n",
      "🔹 Processing batch 270/400 (1000 APIs)...\n",
      "✅ Batch 270 completed and kept in memory.\n",
      "🔹 Processing batch 271/400 (1000 APIs)...\n",
      "✅ Batch 271 completed and kept in memory.\n",
      "🔹 Processing batch 272/400 (1000 APIs)...\n",
      "✅ Batch 272 completed and kept in memory.\n",
      "🔹 Processing batch 273/400 (1000 APIs)...\n",
      "✅ Batch 273 completed and kept in memory.\n",
      "🔹 Processing batch 274/400 (1000 APIs)...\n",
      "✅ Batch 274 completed and kept in memory.\n",
      "🔹 Processing batch 275/400 (1000 APIs)...\n",
      "✅ Batch 275 completed and kept in memory.\n",
      "🔹 Processing batch 276/400 (1000 APIs)...\n",
      "✅ Batch 276 completed and kept in memory.\n",
      "🔹 Processing batch 277/400 (1000 APIs)...\n",
      "✅ Batch 277 completed and kept in memory.\n",
      "🔹 Processing batch 278/400 (1000 APIs)...\n",
      "✅ Batch 278 completed and kept in memory.\n",
      "🔹 Processing batch 279/400 (1000 APIs)...\n",
      "✅ Batch 279 completed and kept in memory.\n",
      "🔹 Processing batch 280/400 (1000 APIs)...\n",
      "✅ Batch 280 completed and kept in memory.\n",
      "🔹 Processing batch 281/400 (1000 APIs)...\n",
      "✅ Batch 281 completed and kept in memory.\n",
      "🔹 Processing batch 282/400 (1000 APIs)...\n",
      "✅ Batch 282 completed and kept in memory.\n",
      "🔹 Processing batch 283/400 (1000 APIs)...\n",
      "✅ Batch 283 completed and kept in memory.\n",
      "🔹 Processing batch 284/400 (1000 APIs)...\n",
      "✅ Batch 284 completed and kept in memory.\n",
      "🔹 Processing batch 285/400 (1000 APIs)...\n",
      "✅ Batch 285 completed and kept in memory.\n",
      "🔹 Processing batch 286/400 (1000 APIs)...\n",
      "✅ Batch 286 completed and kept in memory.\n",
      "🔹 Processing batch 287/400 (1000 APIs)...\n",
      "✅ Batch 287 completed and kept in memory.\n",
      "🔹 Processing batch 288/400 (1000 APIs)...\n",
      "✅ Batch 288 completed and kept in memory.\n",
      "🔹 Processing batch 289/400 (1000 APIs)...\n",
      "✅ Batch 289 completed and kept in memory.\n",
      "🔹 Processing batch 290/400 (1000 APIs)...\n",
      "✅ Batch 290 completed and kept in memory.\n",
      "🔹 Processing batch 291/400 (1000 APIs)...\n",
      "✅ Batch 291 completed and kept in memory.\n",
      "🔹 Processing batch 292/400 (1000 APIs)...\n",
      "✅ Batch 292 completed and kept in memory.\n",
      "🔹 Processing batch 293/400 (1000 APIs)...\n",
      "✅ Batch 293 completed and kept in memory.\n",
      "🔹 Processing batch 294/400 (1000 APIs)...\n",
      "✅ Batch 294 completed and kept in memory.\n",
      "🔹 Processing batch 295/400 (1000 APIs)...\n",
      "✅ Batch 295 completed and kept in memory.\n",
      "🔹 Processing batch 296/400 (1000 APIs)...\n",
      "✅ Batch 296 completed and kept in memory.\n",
      "🔹 Processing batch 297/400 (1000 APIs)...\n",
      "✅ Batch 297 completed and kept in memory.\n",
      "🔹 Processing batch 298/400 (1000 APIs)...\n",
      "✅ Batch 298 completed and kept in memory.\n",
      "🔹 Processing batch 299/400 (1000 APIs)...\n",
      "✅ Batch 299 completed and kept in memory.\n",
      "🔹 Processing batch 300/400 (1000 APIs)...\n",
      "✅ Batch 300 completed and kept in memory.\n",
      "🔹 Processing batch 301/400 (1000 APIs)...\n",
      "✅ Batch 301 completed and kept in memory.\n",
      "🔹 Processing batch 302/400 (1000 APIs)...\n",
      "✅ Batch 302 completed and kept in memory.\n",
      "🔹 Processing batch 303/400 (1000 APIs)...\n",
      "✅ Batch 303 completed and kept in memory.\n",
      "🔹 Processing batch 304/400 (1000 APIs)...\n",
      "✅ Batch 304 completed and kept in memory.\n",
      "🔹 Processing batch 305/400 (1000 APIs)...\n",
      "✅ Batch 305 completed and kept in memory.\n",
      "🔹 Processing batch 306/400 (1000 APIs)...\n",
      "✅ Batch 306 completed and kept in memory.\n",
      "🔹 Processing batch 307/400 (1000 APIs)...\n",
      "✅ Batch 307 completed and kept in memory.\n",
      "🔹 Processing batch 308/400 (1000 APIs)...\n",
      "✅ Batch 308 completed and kept in memory.\n",
      "🔹 Processing batch 309/400 (1000 APIs)...\n",
      "✅ Batch 309 completed and kept in memory.\n",
      "🔹 Processing batch 310/400 (1000 APIs)...\n",
      "✅ Batch 310 completed and kept in memory.\n",
      "🔹 Processing batch 311/400 (1000 APIs)...\n",
      "✅ Batch 311 completed and kept in memory.\n",
      "🔹 Processing batch 312/400 (1000 APIs)...\n",
      "✅ Batch 312 completed and kept in memory.\n",
      "🔹 Processing batch 313/400 (1000 APIs)...\n",
      "✅ Batch 313 completed and kept in memory.\n",
      "🔹 Processing batch 314/400 (1000 APIs)...\n",
      "✅ Batch 314 completed and kept in memory.\n",
      "🔹 Processing batch 315/400 (1000 APIs)...\n",
      "✅ Batch 315 completed and kept in memory.\n",
      "🔹 Processing batch 316/400 (1000 APIs)...\n",
      "✅ Batch 316 completed and kept in memory.\n",
      "🔹 Processing batch 317/400 (1000 APIs)...\n",
      "✅ Batch 317 completed and kept in memory.\n",
      "🔹 Processing batch 318/400 (1000 APIs)...\n",
      "✅ Batch 318 completed and kept in memory.\n",
      "🔹 Processing batch 319/400 (1000 APIs)...\n",
      "✅ Batch 319 completed and kept in memory.\n",
      "🔹 Processing batch 320/400 (1000 APIs)...\n",
      "✅ Batch 320 completed and kept in memory.\n",
      "🔹 Processing batch 321/400 (1000 APIs)...\n",
      "✅ Batch 321 completed and kept in memory.\n",
      "🔹 Processing batch 322/400 (1000 APIs)...\n",
      "✅ Batch 322 completed and kept in memory.\n",
      "🔹 Processing batch 323/400 (1000 APIs)...\n",
      "✅ Batch 323 completed and kept in memory.\n",
      "🔹 Processing batch 324/400 (1000 APIs)...\n",
      "✅ Batch 324 completed and kept in memory.\n",
      "🔹 Processing batch 325/400 (1000 APIs)...\n",
      "✅ Batch 325 completed and kept in memory.\n",
      "🔹 Processing batch 326/400 (1000 APIs)...\n",
      "✅ Batch 326 completed and kept in memory.\n",
      "🔹 Processing batch 327/400 (1000 APIs)...\n",
      "✅ Batch 327 completed and kept in memory.\n",
      "🔹 Processing batch 328/400 (1000 APIs)...\n",
      "✅ Batch 328 completed and kept in memory.\n",
      "🔹 Processing batch 329/400 (1000 APIs)...\n",
      "✅ Batch 329 completed and kept in memory.\n",
      "🔹 Processing batch 330/400 (1000 APIs)...\n",
      "✅ Batch 330 completed and kept in memory.\n",
      "🔹 Processing batch 331/400 (1000 APIs)...\n",
      "✅ Batch 331 completed and kept in memory.\n",
      "🔹 Processing batch 332/400 (1000 APIs)...\n",
      "✅ Batch 332 completed and kept in memory.\n",
      "🔹 Processing batch 333/400 (1000 APIs)...\n",
      "✅ Batch 333 completed and kept in memory.\n",
      "🔹 Processing batch 334/400 (1000 APIs)...\n",
      "✅ Batch 334 completed and kept in memory.\n",
      "🔹 Processing batch 335/400 (1000 APIs)...\n",
      "✅ Batch 335 completed and kept in memory.\n",
      "🔹 Processing batch 336/400 (1000 APIs)...\n",
      "✅ Batch 336 completed and kept in memory.\n",
      "🔹 Processing batch 337/400 (1000 APIs)...\n",
      "✅ Batch 337 completed and kept in memory.\n",
      "🔹 Processing batch 338/400 (1000 APIs)...\n",
      "✅ Batch 338 completed and kept in memory.\n",
      "🔹 Processing batch 339/400 (1000 APIs)...\n",
      "✅ Batch 339 completed and kept in memory.\n",
      "🔹 Processing batch 340/400 (1000 APIs)...\n",
      "✅ Batch 340 completed and kept in memory.\n",
      "🔹 Processing batch 341/400 (1000 APIs)...\n",
      "✅ Batch 341 completed and kept in memory.\n",
      "🔹 Processing batch 342/400 (1000 APIs)...\n",
      "✅ Batch 342 completed and kept in memory.\n",
      "🔹 Processing batch 343/400 (1000 APIs)...\n",
      "✅ Batch 343 completed and kept in memory.\n",
      "🔹 Processing batch 344/400 (1000 APIs)...\n",
      "✅ Batch 344 completed and kept in memory.\n",
      "🔹 Processing batch 345/400 (1000 APIs)...\n",
      "✅ Batch 345 completed and kept in memory.\n",
      "🔹 Processing batch 346/400 (1000 APIs)...\n",
      "✅ Batch 346 completed and kept in memory.\n",
      "🔹 Processing batch 347/400 (1000 APIs)...\n",
      "✅ Batch 347 completed and kept in memory.\n",
      "🔹 Processing batch 348/400 (1000 APIs)...\n",
      "✅ Batch 348 completed and kept in memory.\n",
      "🔹 Processing batch 349/400 (1000 APIs)...\n",
      "✅ Batch 349 completed and kept in memory.\n",
      "🔹 Processing batch 350/400 (1000 APIs)...\n",
      "✅ Batch 350 completed and kept in memory.\n",
      "🔹 Processing batch 351/400 (1000 APIs)...\n",
      "✅ Batch 351 completed and kept in memory.\n",
      "🔹 Processing batch 352/400 (1000 APIs)...\n",
      "✅ Batch 352 completed and kept in memory.\n",
      "🔹 Processing batch 353/400 (1000 APIs)...\n",
      "✅ Batch 353 completed and kept in memory.\n",
      "🔹 Processing batch 354/400 (1000 APIs)...\n",
      "✅ Batch 354 completed and kept in memory.\n",
      "🔹 Processing batch 355/400 (1000 APIs)...\n",
      "✅ Batch 355 completed and kept in memory.\n",
      "🔹 Processing batch 356/400 (1000 APIs)...\n",
      "✅ Batch 356 completed and kept in memory.\n",
      "🔹 Processing batch 357/400 (1000 APIs)...\n",
      "✅ Batch 357 completed and kept in memory.\n",
      "🔹 Processing batch 358/400 (1000 APIs)...\n",
      "✅ Batch 358 completed and kept in memory.\n",
      "🔹 Processing batch 359/400 (1000 APIs)...\n",
      "✅ Batch 359 completed and kept in memory.\n",
      "🔹 Processing batch 360/400 (1000 APIs)...\n",
      "✅ Batch 360 completed and kept in memory.\n",
      "🔹 Processing batch 361/400 (1000 APIs)...\n",
      "✅ Batch 361 completed and kept in memory.\n",
      "🔹 Processing batch 362/400 (1000 APIs)...\n",
      "✅ Batch 362 completed and kept in memory.\n",
      "🔹 Processing batch 363/400 (1000 APIs)...\n",
      "✅ Batch 363 completed and kept in memory.\n",
      "🔹 Processing batch 364/400 (1000 APIs)...\n",
      "✅ Batch 364 completed and kept in memory.\n",
      "🔹 Processing batch 365/400 (1000 APIs)...\n",
      "✅ Batch 365 completed and kept in memory.\n",
      "🔹 Processing batch 366/400 (1000 APIs)...\n",
      "✅ Batch 366 completed and kept in memory.\n",
      "🔹 Processing batch 367/400 (1000 APIs)...\n",
      "✅ Batch 367 completed and kept in memory.\n",
      "🔹 Processing batch 368/400 (1000 APIs)...\n",
      "✅ Batch 368 completed and kept in memory.\n",
      "🔹 Processing batch 369/400 (1000 APIs)...\n",
      "✅ Batch 369 completed and kept in memory.\n",
      "🔹 Processing batch 370/400 (1000 APIs)...\n",
      "✅ Batch 370 completed and kept in memory.\n",
      "🔹 Processing batch 371/400 (1000 APIs)...\n",
      "✅ Batch 371 completed and kept in memory.\n",
      "🔹 Processing batch 372/400 (1000 APIs)...\n",
      "✅ Batch 372 completed and kept in memory.\n",
      "🔹 Processing batch 373/400 (1000 APIs)...\n",
      "✅ Batch 373 completed and kept in memory.\n",
      "🔹 Processing batch 374/400 (1000 APIs)...\n",
      "✅ Batch 374 completed and kept in memory.\n",
      "🔹 Processing batch 375/400 (1000 APIs)...\n",
      "✅ Batch 375 completed and kept in memory.\n",
      "🔹 Processing batch 376/400 (1000 APIs)...\n",
      "✅ Batch 376 completed and kept in memory.\n",
      "🔹 Processing batch 377/400 (1000 APIs)...\n",
      "✅ Batch 377 completed and kept in memory.\n",
      "🔹 Processing batch 378/400 (1000 APIs)...\n",
      "✅ Batch 378 completed and kept in memory.\n",
      "🔹 Processing batch 379/400 (1000 APIs)...\n",
      "✅ Batch 379 completed and kept in memory.\n",
      "🔹 Processing batch 380/400 (1000 APIs)...\n",
      "✅ Batch 380 completed and kept in memory.\n",
      "🔹 Processing batch 381/400 (1000 APIs)...\n",
      "✅ Batch 381 completed and kept in memory.\n",
      "🔹 Processing batch 382/400 (1000 APIs)...\n",
      "✅ Batch 382 completed and kept in memory.\n",
      "🔹 Processing batch 383/400 (1000 APIs)...\n",
      "✅ Batch 383 completed and kept in memory.\n",
      "🔹 Processing batch 384/400 (1000 APIs)...\n",
      "✅ Batch 384 completed and kept in memory.\n",
      "🔹 Processing batch 385/400 (1000 APIs)...\n",
      "✅ Batch 385 completed and kept in memory.\n",
      "🔹 Processing batch 386/400 (1000 APIs)...\n",
      "✅ Batch 386 completed and kept in memory.\n",
      "🔹 Processing batch 387/400 (1000 APIs)...\n",
      "✅ Batch 387 completed and kept in memory.\n",
      "🔹 Processing batch 388/400 (1000 APIs)...\n",
      "✅ Batch 388 completed and kept in memory.\n",
      "🔹 Processing batch 389/400 (1000 APIs)...\n",
      "✅ Batch 389 completed and kept in memory.\n",
      "🔹 Processing batch 390/400 (1000 APIs)...\n",
      "✅ Batch 390 completed and kept in memory.\n",
      "🔹 Processing batch 391/400 (1000 APIs)...\n",
      "✅ Batch 391 completed and kept in memory.\n",
      "🔹 Processing batch 392/400 (1000 APIs)...\n",
      "✅ Batch 392 completed and kept in memory.\n",
      "🔹 Processing batch 393/400 (1000 APIs)...\n",
      "✅ Batch 393 completed and kept in memory.\n",
      "🔹 Processing batch 394/400 (1000 APIs)...\n",
      "✅ Batch 394 completed and kept in memory.\n",
      "🔹 Processing batch 395/400 (1000 APIs)...\n",
      "✅ Batch 395 completed and kept in memory.\n",
      "🔹 Processing batch 396/400 (1000 APIs)...\n",
      "✅ Batch 396 completed and kept in memory.\n",
      "🔹 Processing batch 397/400 (1000 APIs)...\n",
      "✅ Batch 397 completed and kept in memory.\n",
      "🔹 Processing batch 398/400 (1000 APIs)...\n",
      "✅ Batch 398 completed and kept in memory.\n",
      "🔹 Processing batch 399/400 (1000 APIs)...\n",
      "✅ Batch 399 completed and kept in memory.\n",
      "🔹 Processing batch 400/400 (39 APIs)...\n",
      "✅ Batch 400 completed and kept in memory.\n",
      "✅ All 400 batches processed.\n",
      "🔄 Concatenating 400 batches into final DataFrame...\n"
     ]
    }
   ],
   "source": [
    "cols_to_fill = [\n",
    "    'last_year', 'last_month', 'last_gas', 'last_oil', 'months_since_last',\n",
    "    'gas_avg_3', 'oil_avg_3', 'gas_avg_6', 'oil_avg_6'\n",
    "]\n",
    "backfill_df = batch_merge_and_backfill_dask(forecast_df, bfill_helper, cols_to_fill, batch_size=1000, write_batches_to_disk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d031080-ed28-474b-9fff-a3d38bb83206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: BACKFILL_DF\n",
      "============================================================\n",
      "Shape: ((19951950, 11))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 string          19951950   399039     0.0       %\n",
      "date_prod                 datetime64[ns]  19951950   50         0.0       %\n",
      "last_year                 float64         19951950   5          0.0       %\n",
      "last_month                float64         19951950   13         0.0       %\n",
      "last_gas                  float64         19951950   128036     0.0       %\n",
      "last_oil                  float64         19951950   38278      0.0       %\n",
      "months_since_last         float64         19951950   43         0.0       %\n",
      "gas_avg_3                 float64         19951950   262000     0.0       %\n",
      "oil_avg_3                 float64         19951950   95299      0.0       %\n",
      "gas_avg_6                 float64         19951950   430300     0.0       %\n",
      "oil_avg_6                 float64         19951950   172912     0.0       %\n"
     ]
    }
   ],
   "source": [
    "comprehensive_data_overview_dask({'backfill_df': backfill_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9612bacd-b613-4b6a-b8da-45e1fe86bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "backfill_df.to_parquet('../data/forecast_4_backfill.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e2093-04fc-41c9-b5ba-ff9e623b10a7",
   "metadata": {},
   "source": [
    "This seems to have worked to solve the issue and now we properly included all backfill values for maximum accuracy! The problem was that when I load the backfill helper dataset in with dask and then compute it back into a pandas dataframe, it subtly changed the datasets of some columns (some didn't matter like api being a string instead of an object, but the datetime[ns] was converted to datetime[ms] and this was creating problems with merging its batches with those of forecast_df\n",
    "\n",
    "Next I just need to sort the forecast_df values in the same way I sorted for backfill_df (realistically I can probably combine that step in the future), and then I'll be able to add these columns from backfill_df directly (number of rows should be the same and api and date prod should match for each row)\n",
    "\n",
    "In case I want to re-create anything, I need to remember that the datasets I used to create backfill_df (saved as forecast_4_backfill.parquet) are forecast_df (saved as forecast_3.parquet) and bfill_helper (saved as forecast_helper_1.parquet)... and that is also the version of forecast_df I will be moving forward with:\n",
    "- forecast_4.parquet = forecast_3.parquet(sorted) + forecast_4_backfill.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c47265d-0b07-4bba-8ff6-412ba857d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded joined_data as Dask DataFrame\n",
      "  Shape: (<dask_expr.expr.Scalar: expr=ReadParquetFSSpec(8d1cbf6).size() // 11, dtype=int32>, 11)\n",
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 11 entries, api_no_10 to oil_avg_6\n",
      "dtypes: datetime64[ns](1), float64(9), string(1)"
     ]
    }
   ],
   "source": [
    "backfill_df = load_parquet_datasets({'joined_data': '../data/forecast_4_backfill.parquet'}, use_dask=True)['joined_data']\n",
    "backfill_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209ad4bb-ca1b-4762-8bde-657660049402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19951950 entries, 0 to 19951949\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   api_no_10          string        \n",
      " 1   date_prod          datetime64[ns]\n",
      " 2   last_year          float64       \n",
      " 3   last_month         float64       \n",
      " 4   last_gas           float64       \n",
      " 5   last_oil           float64       \n",
      " 6   months_since_last  float64       \n",
      " 7   gas_avg_3          float64       \n",
      " 8   oil_avg_3          float64       \n",
      " 9   gas_avg_6          float64       \n",
      " 10  oil_avg_6          float64       \n",
      "dtypes: datetime64[ns](1), float64(9), string(1)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "backfill_df = backfill_df.compute()\n",
    "backfill_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c9f44-71a6-4919-accf-f9627c221e89",
   "metadata": {},
   "source": [
    "Now it's time to sort forecast_df in the same way that I sorted it when creating backfill_df, so I can properly add the backfill_df columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d78ec562-9a02-4ebc-93dc-fa6c63992007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import gc\n",
    "\n",
    "def batch_sort_forecast_df(\n",
    "    forecast_df, batch_size=10000, batch_output_prefix=\"sorted_batch\", write_batches_to_disk=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Memory-efficient batch sorter for Dask DataFrame (forecast_df).\n",
    "    Sorts by ['api_no_10', 'date_prod'] in the same batching as the merge/backfill.\n",
    "    \"\"\"\n",
    "    unique_apis = forecast_df['api_no_10'].drop_duplicates().compute().values\n",
    "    total_apis = len(unique_apis)\n",
    "    num_batches = (total_apis + batch_size - 1) // batch_size\n",
    "\n",
    "    print(f\"✅ Total unique APIs: {total_apis}\")\n",
    "    print(f\"✅ Batch size: {batch_size}\")\n",
    "    print(f\"✅ Total batches: {num_batches}\")\n",
    "\n",
    "    batch_filepaths = []\n",
    "    sorted_batches = []\n",
    "\n",
    "    for batch_num, start in enumerate(range(0, total_apis, batch_size), start=1):\n",
    "        end = min(start + batch_size, total_apis)\n",
    "        batch_apis = unique_apis[start:end]\n",
    "\n",
    "        print(f\"🔹 Sorting batch {batch_num}/{num_batches} ({len(batch_apis)} APIs)...\")\n",
    "\n",
    "        # Subset and load this batch into pandas\n",
    "        batch = forecast_df[forecast_df['api_no_10'].isin(batch_apis)].compute()\n",
    "\n",
    "        # Sort\n",
    "        batch = batch.sort_values(['api_no_10', 'date_prod'])\n",
    "\n",
    "        if write_batches_to_disk:\n",
    "            filepath = f\"../batch_data/{batch_output_prefix}_{batch_num}.parquet\"\n",
    "            batch.to_parquet(filepath, index=False)\n",
    "            batch_filepaths.append(filepath)\n",
    "            print(f\"✅ Sorted batch {batch_num} written to {filepath}\")\n",
    "            del batch\n",
    "        else:\n",
    "            sorted_batches.append(batch)\n",
    "            print(f\"✅ Sorted batch {batch_num} kept in memory.\")\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ All {num_batches} batches sorted.\")\n",
    "\n",
    "    if write_batches_to_disk:\n",
    "        print(f\"🔄 Combining {len(batch_filepaths)} sorted batch files into Dask DataFrame...\")\n",
    "        sorted_ddf = dd.read_parquet(batch_filepaths)\n",
    "        return sorted_ddf\n",
    "    else:\n",
    "        print(f\"🔄 Concatenating {len(sorted_batches)} batches into final sorted DataFrame...\")\n",
    "        sorted_df = pd.concat(sorted_batches, ignore_index=True)\n",
    "        return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9bcf21-2789-4d98-908a-a83030e158ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to use the same respective parameters as I did to create backfill_df\n",
    "forecast_df = batch_sort_forecast_df(forecast_df, batch_size=1000, write_batches_to_disk=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf91bd6-7a32-4cc4-8ffb-0de4166250e9",
   "metadata": {},
   "source": [
    "Even this function unfortunately doesn't work, even though it's only computing and sorting, it is freezing my computer and is unable to hold so much in memory (it manages to sort just one time, which in itself takes a long time, and freezes on the 2nd sort out of 400). But I noticed that the function worked fine before when I was sorting only a limited number of columns, so I'm thinking of re-creating the function to work with a limited subset of columns each time (it will always need api_no_10 and date_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31319143-1a3e-451f-8f50-508c944c654a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<dask_expr.expr.Scalar: expr=Assign(frame=ReadParquetFSSpec(1407f7b)).size() // 38, dtype=int32>,\n",
       " 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad075fa-a54d-495f-9aed-9b8e8eda5734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19951950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.shape[0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c5a51-4d8b-4698-89f7-ef191d370685",
   "metadata": {},
   "source": [
    "That is the same number as backfill_df, which is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7fc0e6-4df6-4f53-b70a-b1185bec644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['api_no_10', 'date_prod', 'gas_monthly', 'oil_monthly', 'start_date',\n",
       "       'wellbore_type', 'Quality_Quant', 'Production_Age',\n",
       "       'Well_Production_Type', 'reservoir type', 'arps model',\n",
       "       'Production_Status', 'lat_surface', 'lon_surface', 'lat_bottomhole',\n",
       "       'lon_bottomhole', 'basin', 'formation_group', 'horizontal_length',\n",
       "       'measured_depth', 'depth_tvd', 'operator_cluster', 'well_generation',\n",
       "       'well_density_1km', 'nearest_well_distance_km', 'prod_year',\n",
       "       'prod_month', 'month_sin', 'month_cos', 'last_year', 'last_month',\n",
       "       'last_gas', 'last_oil', 'months_since_last', 'gas_avg_3', 'oil_avg_3',\n",
       "       'gas_avg_6', 'oil_avg_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c13437-eb37-47b3-8621-050b441b9a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forecast_df.columns) - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d4cf6-ba65-4967-b846-bd66463ac22f",
   "metadata": {},
   "source": [
    "There are a total of 36 columns in forecast_df, which divides neatly by 9 (the exact number sorted effectively before), and we don't even need to sort the last batch since we already are going to replace it with backfill_df. So I'm going to try to create another version of the batch sort function which will only compute, and only sort, a max of 9 columns at once, and then will simply add all columns at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413de8ec-ccc1-496e-b547-447b9d7c87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import gc\n",
    "\n",
    "# new parameter!\n",
    "def batch_sort_forecast_df(\n",
    "    forecast_df, max_sort_columns=9, batch_size=10000, batch_output_prefix=\"sorted_batch\", write_batches_to_disk=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Memory-efficient batch sorter for Dask DataFrame (forecast_df).\n",
    "    Sorts by ['api_no_10', 'date_prod'] in the same batching as the merge/backfill.\n",
    "    \"\"\"\n",
    "    unique_apis = forecast_df['api_no_10'].drop_duplicates().compute().values\n",
    "    total_apis = len(unique_apis)\n",
    "    num_batches = (total_apis + batch_size - 1) // batch_size\n",
    "\n",
    "    print(f\"✅ Total unique APIs: {total_apis}\")\n",
    "    print(f\"✅ Batch size: {batch_size}\")\n",
    "    print(f\"✅ Total batches: {num_batches}\")\n",
    "\n",
    "    # this is a bit clumsy and non-pythonic but we know what we need in this specific case\n",
    "    col_batch_1 = ['api_no_10', 'date_prod']\n",
    "    col_batch_2 = ['api_no_10', 'date_prod']\n",
    "    col_batch_3 = ['api_no_10', 'date_prod']\n",
    "    col_batch_1.extend(forecast_df.columns[2:2+max_sort_columns])\n",
    "    col_batch_2.extend(forecast_df.columns[2+max_sort_columns:2+max_sort_columns*2])\n",
    "    col_batch_3.extend(forecast_df.columns[2+max_sort_columns*2:2+max_sort_columns*3])\n",
    "\n",
    "    print(f\"✅ Column Batch 1: {col_batch_1}\")\n",
    "    print(f\"✅ Column Batch 2: {col_batch_2}\")\n",
    "    print(f\"✅ Column Batch 3: {col_batch_3}\")\n",
    "\n",
    "    batch_filepaths = []\n",
    "    sorted_batches_1 = []\n",
    "    sorted_batches_2 = []\n",
    "    sorted_batches_3 = []\n",
    "\n",
    "    for batch_num, start in enumerate(range(0, total_apis, batch_size), start=1):\n",
    "        end = min(start + batch_size, total_apis)\n",
    "        batch_apis = unique_apis[start:end]\n",
    "\n",
    "        print(f\"🔹 Sorting batch {batch_num}/{num_batches} ({len(batch_apis)} APIs)...\")\n",
    "\n",
    "        # Subset and load this batch into pandas\n",
    "        batch_1 = forecast_df[forecast_df['api_no_10'].isin(batch_apis)][col_batch_1].compute()\n",
    "        batch_2 = forecast_df[forecast_df['api_no_10'].isin(batch_apis)][col_batch_2].compute()\n",
    "        batch_3 = forecast_df[forecast_df['api_no_10'].isin(batch_apis)][col_batch_3].compute()\n",
    "\n",
    "        # Sort\n",
    "        batch_1 = batch_1.sort_values(['api_no_10', 'date_prod'])\n",
    "        batch_2 = batch_2.sort_values(['api_no_10', 'date_prod'])\n",
    "        batch_3 = batch_3.sort_values(['api_no_10', 'date_prod'])\n",
    "\n",
    "        if write_batches_to_disk:\n",
    "            filepath = f\"../batch_data/{batch_output_prefix}_{batch_num}.parquet\"\n",
    "            batch.to_parquet(filepath, index=False)\n",
    "            batch_filepaths.append(filepath)\n",
    "            print(f\"✅ Sorted batch {batch_num} written to {filepath}\")\n",
    "            del batch\n",
    "        else:\n",
    "            sorted_batches_1.append(batch_1)\n",
    "            sorted_batches_2.append(batch_2)\n",
    "            sorted_batches_3.append(batch_3)\n",
    "            print(f\"✅ Sorted batch {batch_num} kept in memory.\")\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ All {num_batches} batches sorted.\")\n",
    "\n",
    "    if write_batches_to_disk:\n",
    "        print(f\"🔄 Combining {len(batch_filepaths)} sorted batch files into Dask DataFrame...\")\n",
    "        sorted_ddf = dd.read_parquet(batch_filepaths)\n",
    "        return sorted_ddf\n",
    "    else:\n",
    "        print(f\"🔄 Concatenating {len(sorted_batches_1)} batches into final sorted DataFrame...\")\n",
    "        sorted_df_1 = pd.concat(sorted_batches_1, ignore_index=True)\n",
    "        sorted_df_2 = pd.concat(sorted_batches_2, ignore_index=True)\n",
    "        sorted_df_3 = pd.concat(sorted_batches_3, ignore_index=True)\n",
    "        for col in sorted_df_2.columns[2:]:\n",
    "            sorted_df_1[col] = sorted_df_2[col]\n",
    "        for col in sorted_df_3.columns[2:]:\n",
    "            sorted_df_1[col] = sorted_df_3[col]\n",
    "        return sorted_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0daefbf-a78d-42d9-a574-186544bbb4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total unique APIs: 399039\n",
      "✅ Batch size: 1000\n",
      "✅ Total batches: 400\n",
      "✅ Column Batch 1: ['api_no_10', 'date_prod', 'gas_monthly', 'oil_monthly', 'start_date', 'wellbore_type', 'Quality_Quant', 'Production_Age', 'Well_Production_Type', 'reservoir type', 'arps model']\n",
      "✅ Column Batch 2: ['api_no_10', 'date_prod', 'Production_Status', 'lat_surface', 'lon_surface', 'lat_bottomhole', 'lon_bottomhole', 'basin', 'formation_group', 'horizontal_length', 'measured_depth']\n",
      "✅ Column Batch 3: ['api_no_10', 'date_prod', 'depth_tvd', 'operator_cluster', 'well_generation', 'well_density_1km', 'nearest_well_distance_km', 'prod_year', 'prod_month', 'month_sin', 'month_cos']\n",
      "🔹 Sorting batch 1/400 (1000 APIs)...\n",
      "✅ Sorted batch 1 kept in memory.\n",
      "🔹 Sorting batch 2/400 (1000 APIs)...\n",
      "✅ Sorted batch 2 kept in memory.\n",
      "🔹 Sorting batch 3/400 (1000 APIs)...\n",
      "✅ Sorted batch 3 kept in memory.\n",
      "🔹 Sorting batch 4/400 (1000 APIs)...\n",
      "✅ Sorted batch 4 kept in memory.\n",
      "🔹 Sorting batch 5/400 (1000 APIs)...\n",
      "✅ Sorted batch 5 kept in memory.\n",
      "🔹 Sorting batch 6/400 (1000 APIs)...\n",
      "✅ Sorted batch 6 kept in memory.\n",
      "🔹 Sorting batch 7/400 (1000 APIs)...\n",
      "✅ Sorted batch 7 kept in memory.\n",
      "🔹 Sorting batch 8/400 (1000 APIs)...\n",
      "✅ Sorted batch 8 kept in memory.\n",
      "🔹 Sorting batch 9/400 (1000 APIs)...\n",
      "✅ Sorted batch 9 kept in memory.\n",
      "🔹 Sorting batch 10/400 (1000 APIs)...\n",
      "✅ Sorted batch 10 kept in memory.\n",
      "🔹 Sorting batch 11/400 (1000 APIs)...\n",
      "✅ Sorted batch 11 kept in memory.\n",
      "🔹 Sorting batch 12/400 (1000 APIs)...\n",
      "✅ Sorted batch 12 kept in memory.\n",
      "🔹 Sorting batch 13/400 (1000 APIs)...\n",
      "✅ Sorted batch 13 kept in memory.\n",
      "🔹 Sorting batch 14/400 (1000 APIs)...\n",
      "✅ Sorted batch 14 kept in memory.\n",
      "🔹 Sorting batch 15/400 (1000 APIs)...\n",
      "✅ Sorted batch 15 kept in memory.\n",
      "🔹 Sorting batch 16/400 (1000 APIs)...\n",
      "✅ Sorted batch 16 kept in memory.\n",
      "🔹 Sorting batch 17/400 (1000 APIs)...\n",
      "✅ Sorted batch 17 kept in memory.\n",
      "🔹 Sorting batch 18/400 (1000 APIs)...\n",
      "✅ Sorted batch 18 kept in memory.\n",
      "🔹 Sorting batch 19/400 (1000 APIs)...\n",
      "✅ Sorted batch 19 kept in memory.\n",
      "🔹 Sorting batch 20/400 (1000 APIs)...\n",
      "✅ Sorted batch 20 kept in memory.\n",
      "🔹 Sorting batch 21/400 (1000 APIs)...\n",
      "✅ Sorted batch 21 kept in memory.\n",
      "🔹 Sorting batch 22/400 (1000 APIs)...\n",
      "✅ Sorted batch 22 kept in memory.\n",
      "🔹 Sorting batch 23/400 (1000 APIs)...\n",
      "✅ Sorted batch 23 kept in memory.\n",
      "🔹 Sorting batch 24/400 (1000 APIs)...\n",
      "✅ Sorted batch 24 kept in memory.\n",
      "🔹 Sorting batch 25/400 (1000 APIs)...\n",
      "✅ Sorted batch 25 kept in memory.\n",
      "🔹 Sorting batch 26/400 (1000 APIs)...\n",
      "✅ Sorted batch 26 kept in memory.\n",
      "🔹 Sorting batch 27/400 (1000 APIs)...\n",
      "✅ Sorted batch 27 kept in memory.\n",
      "🔹 Sorting batch 28/400 (1000 APIs)...\n",
      "✅ Sorted batch 28 kept in memory.\n",
      "🔹 Sorting batch 29/400 (1000 APIs)...\n",
      "✅ Sorted batch 29 kept in memory.\n",
      "🔹 Sorting batch 30/400 (1000 APIs)...\n",
      "✅ Sorted batch 30 kept in memory.\n",
      "🔹 Sorting batch 31/400 (1000 APIs)...\n",
      "✅ Sorted batch 31 kept in memory.\n",
      "🔹 Sorting batch 32/400 (1000 APIs)...\n",
      "✅ Sorted batch 32 kept in memory.\n",
      "🔹 Sorting batch 33/400 (1000 APIs)...\n",
      "✅ Sorted batch 33 kept in memory.\n",
      "🔹 Sorting batch 34/400 (1000 APIs)...\n",
      "✅ Sorted batch 34 kept in memory.\n",
      "🔹 Sorting batch 35/400 (1000 APIs)...\n",
      "✅ Sorted batch 35 kept in memory.\n",
      "🔹 Sorting batch 36/400 (1000 APIs)...\n",
      "✅ Sorted batch 36 kept in memory.\n",
      "🔹 Sorting batch 37/400 (1000 APIs)...\n",
      "✅ Sorted batch 37 kept in memory.\n",
      "🔹 Sorting batch 38/400 (1000 APIs)...\n",
      "✅ Sorted batch 38 kept in memory.\n",
      "🔹 Sorting batch 39/400 (1000 APIs)...\n",
      "✅ Sorted batch 39 kept in memory.\n",
      "🔹 Sorting batch 40/400 (1000 APIs)...\n",
      "✅ Sorted batch 40 kept in memory.\n",
      "🔹 Sorting batch 41/400 (1000 APIs)...\n",
      "✅ Sorted batch 41 kept in memory.\n",
      "🔹 Sorting batch 42/400 (1000 APIs)...\n",
      "✅ Sorted batch 42 kept in memory.\n",
      "🔹 Sorting batch 43/400 (1000 APIs)...\n",
      "✅ Sorted batch 43 kept in memory.\n",
      "🔹 Sorting batch 44/400 (1000 APIs)...\n",
      "✅ Sorted batch 44 kept in memory.\n",
      "🔹 Sorting batch 45/400 (1000 APIs)...\n",
      "✅ Sorted batch 45 kept in memory.\n",
      "🔹 Sorting batch 46/400 (1000 APIs)...\n",
      "✅ Sorted batch 46 kept in memory.\n",
      "🔹 Sorting batch 47/400 (1000 APIs)...\n",
      "✅ Sorted batch 47 kept in memory.\n",
      "🔹 Sorting batch 48/400 (1000 APIs)...\n",
      "✅ Sorted batch 48 kept in memory.\n",
      "🔹 Sorting batch 49/400 (1000 APIs)...\n",
      "✅ Sorted batch 49 kept in memory.\n",
      "🔹 Sorting batch 50/400 (1000 APIs)...\n",
      "✅ Sorted batch 50 kept in memory.\n",
      "🔹 Sorting batch 51/400 (1000 APIs)...\n",
      "✅ Sorted batch 51 kept in memory.\n",
      "🔹 Sorting batch 52/400 (1000 APIs)...\n",
      "✅ Sorted batch 52 kept in memory.\n",
      "🔹 Sorting batch 53/400 (1000 APIs)...\n",
      "✅ Sorted batch 53 kept in memory.\n",
      "🔹 Sorting batch 54/400 (1000 APIs)...\n",
      "✅ Sorted batch 54 kept in memory.\n",
      "🔹 Sorting batch 55/400 (1000 APIs)...\n",
      "✅ Sorted batch 55 kept in memory.\n",
      "🔹 Sorting batch 56/400 (1000 APIs)...\n",
      "✅ Sorted batch 56 kept in memory.\n",
      "🔹 Sorting batch 57/400 (1000 APIs)...\n",
      "✅ Sorted batch 57 kept in memory.\n",
      "🔹 Sorting batch 58/400 (1000 APIs)...\n",
      "✅ Sorted batch 58 kept in memory.\n",
      "🔹 Sorting batch 59/400 (1000 APIs)...\n",
      "✅ Sorted batch 59 kept in memory.\n",
      "🔹 Sorting batch 60/400 (1000 APIs)...\n",
      "✅ Sorted batch 60 kept in memory.\n",
      "🔹 Sorting batch 61/400 (1000 APIs)...\n",
      "✅ Sorted batch 61 kept in memory.\n",
      "🔹 Sorting batch 62/400 (1000 APIs)...\n",
      "✅ Sorted batch 62 kept in memory.\n",
      "🔹 Sorting batch 63/400 (1000 APIs)...\n",
      "✅ Sorted batch 63 kept in memory.\n",
      "🔹 Sorting batch 64/400 (1000 APIs)...\n",
      "✅ Sorted batch 64 kept in memory.\n",
      "🔹 Sorting batch 65/400 (1000 APIs)...\n",
      "✅ Sorted batch 65 kept in memory.\n",
      "🔹 Sorting batch 66/400 (1000 APIs)...\n",
      "✅ Sorted batch 66 kept in memory.\n",
      "🔹 Sorting batch 67/400 (1000 APIs)...\n",
      "✅ Sorted batch 67 kept in memory.\n",
      "🔹 Sorting batch 68/400 (1000 APIs)...\n",
      "✅ Sorted batch 68 kept in memory.\n",
      "🔹 Sorting batch 69/400 (1000 APIs)...\n",
      "✅ Sorted batch 69 kept in memory.\n",
      "🔹 Sorting batch 70/400 (1000 APIs)...\n",
      "✅ Sorted batch 70 kept in memory.\n",
      "🔹 Sorting batch 71/400 (1000 APIs)...\n",
      "✅ Sorted batch 71 kept in memory.\n",
      "🔹 Sorting batch 72/400 (1000 APIs)...\n",
      "✅ Sorted batch 72 kept in memory.\n",
      "🔹 Sorting batch 73/400 (1000 APIs)...\n",
      "✅ Sorted batch 73 kept in memory.\n",
      "🔹 Sorting batch 74/400 (1000 APIs)...\n",
      "✅ Sorted batch 74 kept in memory.\n",
      "🔹 Sorting batch 75/400 (1000 APIs)...\n",
      "✅ Sorted batch 75 kept in memory.\n",
      "🔹 Sorting batch 76/400 (1000 APIs)...\n",
      "✅ Sorted batch 76 kept in memory.\n",
      "🔹 Sorting batch 77/400 (1000 APIs)...\n",
      "✅ Sorted batch 77 kept in memory.\n",
      "🔹 Sorting batch 78/400 (1000 APIs)...\n",
      "✅ Sorted batch 78 kept in memory.\n",
      "🔹 Sorting batch 79/400 (1000 APIs)...\n",
      "✅ Sorted batch 79 kept in memory.\n",
      "🔹 Sorting batch 80/400 (1000 APIs)...\n",
      "✅ Sorted batch 80 kept in memory.\n",
      "🔹 Sorting batch 81/400 (1000 APIs)...\n",
      "✅ Sorted batch 81 kept in memory.\n",
      "🔹 Sorting batch 82/400 (1000 APIs)...\n",
      "✅ Sorted batch 82 kept in memory.\n",
      "🔹 Sorting batch 83/400 (1000 APIs)...\n",
      "✅ Sorted batch 83 kept in memory.\n",
      "🔹 Sorting batch 84/400 (1000 APIs)...\n",
      "✅ Sorted batch 84 kept in memory.\n",
      "🔹 Sorting batch 85/400 (1000 APIs)...\n",
      "✅ Sorted batch 85 kept in memory.\n",
      "🔹 Sorting batch 86/400 (1000 APIs)...\n",
      "✅ Sorted batch 86 kept in memory.\n",
      "🔹 Sorting batch 87/400 (1000 APIs)...\n",
      "✅ Sorted batch 87 kept in memory.\n",
      "🔹 Sorting batch 88/400 (1000 APIs)...\n",
      "✅ Sorted batch 88 kept in memory.\n",
      "🔹 Sorting batch 89/400 (1000 APIs)...\n",
      "✅ Sorted batch 89 kept in memory.\n",
      "🔹 Sorting batch 90/400 (1000 APIs)...\n",
      "✅ Sorted batch 90 kept in memory.\n",
      "🔹 Sorting batch 91/400 (1000 APIs)...\n",
      "✅ Sorted batch 91 kept in memory.\n",
      "🔹 Sorting batch 92/400 (1000 APIs)...\n",
      "✅ Sorted batch 92 kept in memory.\n",
      "🔹 Sorting batch 93/400 (1000 APIs)...\n",
      "✅ Sorted batch 93 kept in memory.\n",
      "🔹 Sorting batch 94/400 (1000 APIs)...\n",
      "✅ Sorted batch 94 kept in memory.\n",
      "🔹 Sorting batch 95/400 (1000 APIs)...\n",
      "✅ Sorted batch 95 kept in memory.\n",
      "🔹 Sorting batch 96/400 (1000 APIs)...\n",
      "✅ Sorted batch 96 kept in memory.\n",
      "🔹 Sorting batch 97/400 (1000 APIs)...\n",
      "✅ Sorted batch 97 kept in memory.\n",
      "🔹 Sorting batch 98/400 (1000 APIs)...\n",
      "✅ Sorted batch 98 kept in memory.\n",
      "🔹 Sorting batch 99/400 (1000 APIs)...\n",
      "✅ Sorted batch 99 kept in memory.\n",
      "🔹 Sorting batch 100/400 (1000 APIs)...\n",
      "✅ Sorted batch 100 kept in memory.\n",
      "🔹 Sorting batch 101/400 (1000 APIs)...\n",
      "✅ Sorted batch 101 kept in memory.\n",
      "🔹 Sorting batch 102/400 (1000 APIs)...\n",
      "✅ Sorted batch 102 kept in memory.\n",
      "🔹 Sorting batch 103/400 (1000 APIs)...\n",
      "✅ Sorted batch 103 kept in memory.\n",
      "🔹 Sorting batch 104/400 (1000 APIs)...\n",
      "✅ Sorted batch 104 kept in memory.\n",
      "🔹 Sorting batch 105/400 (1000 APIs)...\n",
      "✅ Sorted batch 105 kept in memory.\n",
      "🔹 Sorting batch 106/400 (1000 APIs)...\n",
      "✅ Sorted batch 106 kept in memory.\n",
      "🔹 Sorting batch 107/400 (1000 APIs)...\n",
      "✅ Sorted batch 107 kept in memory.\n",
      "🔹 Sorting batch 108/400 (1000 APIs)...\n",
      "✅ Sorted batch 108 kept in memory.\n",
      "🔹 Sorting batch 109/400 (1000 APIs)...\n",
      "✅ Sorted batch 109 kept in memory.\n",
      "🔹 Sorting batch 110/400 (1000 APIs)...\n",
      "✅ Sorted batch 110 kept in memory.\n",
      "🔹 Sorting batch 111/400 (1000 APIs)...\n",
      "✅ Sorted batch 111 kept in memory.\n",
      "🔹 Sorting batch 112/400 (1000 APIs)...\n",
      "✅ Sorted batch 112 kept in memory.\n",
      "🔹 Sorting batch 113/400 (1000 APIs)...\n",
      "✅ Sorted batch 113 kept in memory.\n",
      "🔹 Sorting batch 114/400 (1000 APIs)...\n",
      "✅ Sorted batch 114 kept in memory.\n",
      "🔹 Sorting batch 115/400 (1000 APIs)...\n",
      "✅ Sorted batch 115 kept in memory.\n",
      "🔹 Sorting batch 116/400 (1000 APIs)...\n",
      "✅ Sorted batch 116 kept in memory.\n",
      "🔹 Sorting batch 117/400 (1000 APIs)...\n",
      "✅ Sorted batch 117 kept in memory.\n",
      "🔹 Sorting batch 118/400 (1000 APIs)...\n",
      "✅ Sorted batch 118 kept in memory.\n",
      "🔹 Sorting batch 119/400 (1000 APIs)...\n",
      "✅ Sorted batch 119 kept in memory.\n",
      "🔹 Sorting batch 120/400 (1000 APIs)...\n",
      "✅ Sorted batch 120 kept in memory.\n",
      "🔹 Sorting batch 121/400 (1000 APIs)...\n",
      "✅ Sorted batch 121 kept in memory.\n",
      "🔹 Sorting batch 122/400 (1000 APIs)...\n",
      "✅ Sorted batch 122 kept in memory.\n",
      "🔹 Sorting batch 123/400 (1000 APIs)...\n",
      "✅ Sorted batch 123 kept in memory.\n",
      "🔹 Sorting batch 124/400 (1000 APIs)...\n",
      "✅ Sorted batch 124 kept in memory.\n",
      "🔹 Sorting batch 125/400 (1000 APIs)...\n",
      "✅ Sorted batch 125 kept in memory.\n",
      "🔹 Sorting batch 126/400 (1000 APIs)...\n",
      "✅ Sorted batch 126 kept in memory.\n",
      "🔹 Sorting batch 127/400 (1000 APIs)...\n",
      "✅ Sorted batch 127 kept in memory.\n",
      "🔹 Sorting batch 128/400 (1000 APIs)...\n",
      "✅ Sorted batch 128 kept in memory.\n",
      "🔹 Sorting batch 129/400 (1000 APIs)...\n",
      "✅ Sorted batch 129 kept in memory.\n",
      "🔹 Sorting batch 130/400 (1000 APIs)...\n",
      "✅ Sorted batch 130 kept in memory.\n",
      "🔹 Sorting batch 131/400 (1000 APIs)...\n",
      "✅ Sorted batch 131 kept in memory.\n",
      "🔹 Sorting batch 132/400 (1000 APIs)...\n",
      "✅ Sorted batch 132 kept in memory.\n",
      "🔹 Sorting batch 133/400 (1000 APIs)...\n",
      "✅ Sorted batch 133 kept in memory.\n",
      "🔹 Sorting batch 134/400 (1000 APIs)...\n",
      "✅ Sorted batch 134 kept in memory.\n",
      "🔹 Sorting batch 135/400 (1000 APIs)...\n",
      "✅ Sorted batch 135 kept in memory.\n",
      "🔹 Sorting batch 136/400 (1000 APIs)...\n",
      "✅ Sorted batch 136 kept in memory.\n",
      "🔹 Sorting batch 137/400 (1000 APIs)...\n",
      "✅ Sorted batch 137 kept in memory.\n",
      "🔹 Sorting batch 138/400 (1000 APIs)...\n",
      "✅ Sorted batch 138 kept in memory.\n",
      "🔹 Sorting batch 139/400 (1000 APIs)...\n",
      "✅ Sorted batch 139 kept in memory.\n",
      "🔹 Sorting batch 140/400 (1000 APIs)...\n",
      "✅ Sorted batch 140 kept in memory.\n",
      "🔹 Sorting batch 141/400 (1000 APIs)...\n",
      "✅ Sorted batch 141 kept in memory.\n",
      "🔹 Sorting batch 142/400 (1000 APIs)...\n",
      "✅ Sorted batch 142 kept in memory.\n",
      "🔹 Sorting batch 143/400 (1000 APIs)...\n",
      "✅ Sorted batch 143 kept in memory.\n",
      "🔹 Sorting batch 144/400 (1000 APIs)...\n",
      "✅ Sorted batch 144 kept in memory.\n",
      "🔹 Sorting batch 145/400 (1000 APIs)...\n",
      "✅ Sorted batch 145 kept in memory.\n",
      "🔹 Sorting batch 146/400 (1000 APIs)...\n",
      "✅ Sorted batch 146 kept in memory.\n",
      "🔹 Sorting batch 147/400 (1000 APIs)...\n",
      "✅ Sorted batch 147 kept in memory.\n",
      "🔹 Sorting batch 148/400 (1000 APIs)...\n",
      "✅ Sorted batch 148 kept in memory.\n",
      "🔹 Sorting batch 149/400 (1000 APIs)...\n",
      "✅ Sorted batch 149 kept in memory.\n",
      "🔹 Sorting batch 150/400 (1000 APIs)...\n",
      "✅ Sorted batch 150 kept in memory.\n",
      "🔹 Sorting batch 151/400 (1000 APIs)...\n",
      "✅ Sorted batch 151 kept in memory.\n",
      "🔹 Sorting batch 152/400 (1000 APIs)...\n",
      "✅ Sorted batch 152 kept in memory.\n",
      "🔹 Sorting batch 153/400 (1000 APIs)...\n",
      "✅ Sorted batch 153 kept in memory.\n",
      "🔹 Sorting batch 154/400 (1000 APIs)...\n",
      "✅ Sorted batch 154 kept in memory.\n",
      "🔹 Sorting batch 155/400 (1000 APIs)...\n",
      "✅ Sorted batch 155 kept in memory.\n",
      "🔹 Sorting batch 156/400 (1000 APIs)...\n",
      "✅ Sorted batch 156 kept in memory.\n",
      "🔹 Sorting batch 157/400 (1000 APIs)...\n",
      "✅ Sorted batch 157 kept in memory.\n",
      "🔹 Sorting batch 158/400 (1000 APIs)...\n",
      "✅ Sorted batch 158 kept in memory.\n",
      "🔹 Sorting batch 159/400 (1000 APIs)...\n",
      "✅ Sorted batch 159 kept in memory.\n",
      "🔹 Sorting batch 160/400 (1000 APIs)...\n",
      "✅ Sorted batch 160 kept in memory.\n",
      "🔹 Sorting batch 161/400 (1000 APIs)...\n",
      "✅ Sorted batch 161 kept in memory.\n",
      "🔹 Sorting batch 162/400 (1000 APIs)...\n",
      "✅ Sorted batch 162 kept in memory.\n",
      "🔹 Sorting batch 163/400 (1000 APIs)...\n",
      "✅ Sorted batch 163 kept in memory.\n",
      "🔹 Sorting batch 164/400 (1000 APIs)...\n",
      "✅ Sorted batch 164 kept in memory.\n",
      "🔹 Sorting batch 165/400 (1000 APIs)...\n",
      "✅ Sorted batch 165 kept in memory.\n",
      "🔹 Sorting batch 166/400 (1000 APIs)...\n",
      "✅ Sorted batch 166 kept in memory.\n",
      "🔹 Sorting batch 167/400 (1000 APIs)...\n",
      "✅ Sorted batch 167 kept in memory.\n",
      "🔹 Sorting batch 168/400 (1000 APIs)...\n",
      "✅ Sorted batch 168 kept in memory.\n",
      "🔹 Sorting batch 169/400 (1000 APIs)...\n",
      "✅ Sorted batch 169 kept in memory.\n",
      "🔹 Sorting batch 170/400 (1000 APIs)...\n",
      "✅ Sorted batch 170 kept in memory.\n",
      "🔹 Sorting batch 171/400 (1000 APIs)...\n",
      "✅ Sorted batch 171 kept in memory.\n",
      "🔹 Sorting batch 172/400 (1000 APIs)...\n",
      "✅ Sorted batch 172 kept in memory.\n",
      "🔹 Sorting batch 173/400 (1000 APIs)...\n",
      "✅ Sorted batch 173 kept in memory.\n",
      "🔹 Sorting batch 174/400 (1000 APIs)...\n",
      "✅ Sorted batch 174 kept in memory.\n",
      "🔹 Sorting batch 175/400 (1000 APIs)...\n",
      "✅ Sorted batch 175 kept in memory.\n",
      "🔹 Sorting batch 176/400 (1000 APIs)...\n",
      "✅ Sorted batch 176 kept in memory.\n",
      "🔹 Sorting batch 177/400 (1000 APIs)...\n",
      "✅ Sorted batch 177 kept in memory.\n",
      "🔹 Sorting batch 178/400 (1000 APIs)...\n",
      "✅ Sorted batch 178 kept in memory.\n",
      "🔹 Sorting batch 179/400 (1000 APIs)...\n",
      "✅ Sorted batch 179 kept in memory.\n",
      "🔹 Sorting batch 180/400 (1000 APIs)...\n",
      "✅ Sorted batch 180 kept in memory.\n",
      "🔹 Sorting batch 181/400 (1000 APIs)...\n",
      "✅ Sorted batch 181 kept in memory.\n",
      "🔹 Sorting batch 182/400 (1000 APIs)...\n",
      "✅ Sorted batch 182 kept in memory.\n",
      "🔹 Sorting batch 183/400 (1000 APIs)...\n",
      "✅ Sorted batch 183 kept in memory.\n",
      "🔹 Sorting batch 184/400 (1000 APIs)...\n",
      "✅ Sorted batch 184 kept in memory.\n",
      "🔹 Sorting batch 185/400 (1000 APIs)...\n",
      "✅ Sorted batch 185 kept in memory.\n",
      "🔹 Sorting batch 186/400 (1000 APIs)...\n",
      "✅ Sorted batch 186 kept in memory.\n",
      "🔹 Sorting batch 187/400 (1000 APIs)...\n",
      "✅ Sorted batch 187 kept in memory.\n",
      "🔹 Sorting batch 188/400 (1000 APIs)...\n",
      "✅ Sorted batch 188 kept in memory.\n",
      "🔹 Sorting batch 189/400 (1000 APIs)...\n",
      "✅ Sorted batch 189 kept in memory.\n",
      "🔹 Sorting batch 190/400 (1000 APIs)...\n",
      "✅ Sorted batch 190 kept in memory.\n",
      "🔹 Sorting batch 191/400 (1000 APIs)...\n",
      "✅ Sorted batch 191 kept in memory.\n",
      "🔹 Sorting batch 192/400 (1000 APIs)...\n",
      "✅ Sorted batch 192 kept in memory.\n",
      "🔹 Sorting batch 193/400 (1000 APIs)...\n",
      "✅ Sorted batch 193 kept in memory.\n",
      "🔹 Sorting batch 194/400 (1000 APIs)...\n",
      "✅ Sorted batch 194 kept in memory.\n",
      "🔹 Sorting batch 195/400 (1000 APIs)...\n",
      "✅ Sorted batch 195 kept in memory.\n",
      "🔹 Sorting batch 196/400 (1000 APIs)...\n",
      "✅ Sorted batch 196 kept in memory.\n",
      "🔹 Sorting batch 197/400 (1000 APIs)...\n",
      "✅ Sorted batch 197 kept in memory.\n",
      "🔹 Sorting batch 198/400 (1000 APIs)...\n",
      "✅ Sorted batch 198 kept in memory.\n",
      "🔹 Sorting batch 199/400 (1000 APIs)...\n",
      "✅ Sorted batch 199 kept in memory.\n",
      "🔹 Sorting batch 200/400 (1000 APIs)...\n",
      "✅ Sorted batch 200 kept in memory.\n",
      "🔹 Sorting batch 201/400 (1000 APIs)...\n",
      "✅ Sorted batch 201 kept in memory.\n",
      "🔹 Sorting batch 202/400 (1000 APIs)...\n",
      "✅ Sorted batch 202 kept in memory.\n",
      "🔹 Sorting batch 203/400 (1000 APIs)...\n",
      "✅ Sorted batch 203 kept in memory.\n",
      "🔹 Sorting batch 204/400 (1000 APIs)...\n",
      "✅ Sorted batch 204 kept in memory.\n",
      "🔹 Sorting batch 205/400 (1000 APIs)...\n",
      "✅ Sorted batch 205 kept in memory.\n",
      "🔹 Sorting batch 206/400 (1000 APIs)...\n",
      "✅ Sorted batch 206 kept in memory.\n",
      "🔹 Sorting batch 207/400 (1000 APIs)...\n",
      "✅ Sorted batch 207 kept in memory.\n",
      "🔹 Sorting batch 208/400 (1000 APIs)...\n",
      "✅ Sorted batch 208 kept in memory.\n",
      "🔹 Sorting batch 209/400 (1000 APIs)...\n",
      "✅ Sorted batch 209 kept in memory.\n",
      "🔹 Sorting batch 210/400 (1000 APIs)...\n",
      "✅ Sorted batch 210 kept in memory.\n",
      "🔹 Sorting batch 211/400 (1000 APIs)...\n",
      "✅ Sorted batch 211 kept in memory.\n",
      "🔹 Sorting batch 212/400 (1000 APIs)...\n",
      "✅ Sorted batch 212 kept in memory.\n",
      "🔹 Sorting batch 213/400 (1000 APIs)...\n",
      "✅ Sorted batch 213 kept in memory.\n",
      "🔹 Sorting batch 214/400 (1000 APIs)...\n",
      "✅ Sorted batch 214 kept in memory.\n",
      "🔹 Sorting batch 215/400 (1000 APIs)...\n",
      "✅ Sorted batch 215 kept in memory.\n",
      "🔹 Sorting batch 216/400 (1000 APIs)...\n",
      "✅ Sorted batch 216 kept in memory.\n",
      "🔹 Sorting batch 217/400 (1000 APIs)...\n",
      "✅ Sorted batch 217 kept in memory.\n",
      "🔹 Sorting batch 218/400 (1000 APIs)...\n",
      "✅ Sorted batch 218 kept in memory.\n",
      "🔹 Sorting batch 219/400 (1000 APIs)...\n",
      "✅ Sorted batch 219 kept in memory.\n",
      "🔹 Sorting batch 220/400 (1000 APIs)...\n",
      "✅ Sorted batch 220 kept in memory.\n",
      "🔹 Sorting batch 221/400 (1000 APIs)...\n",
      "✅ Sorted batch 221 kept in memory.\n",
      "🔹 Sorting batch 222/400 (1000 APIs)...\n",
      "✅ Sorted batch 222 kept in memory.\n",
      "🔹 Sorting batch 223/400 (1000 APIs)...\n",
      "✅ Sorted batch 223 kept in memory.\n",
      "🔹 Sorting batch 224/400 (1000 APIs)...\n",
      "✅ Sorted batch 224 kept in memory.\n",
      "🔹 Sorting batch 225/400 (1000 APIs)...\n",
      "✅ Sorted batch 225 kept in memory.\n",
      "🔹 Sorting batch 226/400 (1000 APIs)...\n",
      "✅ Sorted batch 226 kept in memory.\n",
      "🔹 Sorting batch 227/400 (1000 APIs)...\n",
      "✅ Sorted batch 227 kept in memory.\n",
      "🔹 Sorting batch 228/400 (1000 APIs)...\n",
      "✅ Sorted batch 228 kept in memory.\n",
      "🔹 Sorting batch 229/400 (1000 APIs)...\n",
      "✅ Sorted batch 229 kept in memory.\n",
      "🔹 Sorting batch 230/400 (1000 APIs)...\n",
      "✅ Sorted batch 230 kept in memory.\n",
      "🔹 Sorting batch 231/400 (1000 APIs)...\n",
      "✅ Sorted batch 231 kept in memory.\n",
      "🔹 Sorting batch 232/400 (1000 APIs)...\n",
      "✅ Sorted batch 232 kept in memory.\n",
      "🔹 Sorting batch 233/400 (1000 APIs)...\n",
      "✅ Sorted batch 233 kept in memory.\n",
      "🔹 Sorting batch 234/400 (1000 APIs)...\n",
      "✅ Sorted batch 234 kept in memory.\n",
      "🔹 Sorting batch 235/400 (1000 APIs)...\n",
      "✅ Sorted batch 235 kept in memory.\n",
      "🔹 Sorting batch 236/400 (1000 APIs)...\n",
      "✅ Sorted batch 236 kept in memory.\n",
      "🔹 Sorting batch 237/400 (1000 APIs)...\n",
      "✅ Sorted batch 237 kept in memory.\n",
      "🔹 Sorting batch 238/400 (1000 APIs)...\n",
      "✅ Sorted batch 238 kept in memory.\n",
      "🔹 Sorting batch 239/400 (1000 APIs)...\n",
      "✅ Sorted batch 239 kept in memory.\n",
      "🔹 Sorting batch 240/400 (1000 APIs)...\n",
      "✅ Sorted batch 240 kept in memory.\n",
      "🔹 Sorting batch 241/400 (1000 APIs)...\n",
      "✅ Sorted batch 241 kept in memory.\n",
      "🔹 Sorting batch 242/400 (1000 APIs)...\n",
      "✅ Sorted batch 242 kept in memory.\n",
      "🔹 Sorting batch 243/400 (1000 APIs)...\n",
      "✅ Sorted batch 243 kept in memory.\n",
      "🔹 Sorting batch 244/400 (1000 APIs)...\n",
      "✅ Sorted batch 244 kept in memory.\n",
      "🔹 Sorting batch 245/400 (1000 APIs)...\n",
      "✅ Sorted batch 245 kept in memory.\n",
      "🔹 Sorting batch 246/400 (1000 APIs)...\n",
      "✅ Sorted batch 246 kept in memory.\n",
      "🔹 Sorting batch 247/400 (1000 APIs)...\n",
      "✅ Sorted batch 247 kept in memory.\n",
      "🔹 Sorting batch 248/400 (1000 APIs)...\n",
      "✅ Sorted batch 248 kept in memory.\n",
      "🔹 Sorting batch 249/400 (1000 APIs)...\n",
      "✅ Sorted batch 249 kept in memory.\n",
      "🔹 Sorting batch 250/400 (1000 APIs)...\n",
      "✅ Sorted batch 250 kept in memory.\n",
      "🔹 Sorting batch 251/400 (1000 APIs)...\n",
      "✅ Sorted batch 251 kept in memory.\n",
      "🔹 Sorting batch 252/400 (1000 APIs)...\n",
      "✅ Sorted batch 252 kept in memory.\n",
      "🔹 Sorting batch 253/400 (1000 APIs)...\n",
      "✅ Sorted batch 253 kept in memory.\n",
      "🔹 Sorting batch 254/400 (1000 APIs)...\n",
      "✅ Sorted batch 254 kept in memory.\n",
      "🔹 Sorting batch 255/400 (1000 APIs)...\n",
      "✅ Sorted batch 255 kept in memory.\n",
      "🔹 Sorting batch 256/400 (1000 APIs)...\n",
      "✅ Sorted batch 256 kept in memory.\n",
      "🔹 Sorting batch 257/400 (1000 APIs)...\n",
      "✅ Sorted batch 257 kept in memory.\n",
      "🔹 Sorting batch 258/400 (1000 APIs)...\n",
      "✅ Sorted batch 258 kept in memory.\n",
      "🔹 Sorting batch 259/400 (1000 APIs)...\n",
      "✅ Sorted batch 259 kept in memory.\n",
      "🔹 Sorting batch 260/400 (1000 APIs)...\n",
      "✅ Sorted batch 260 kept in memory.\n",
      "🔹 Sorting batch 261/400 (1000 APIs)...\n",
      "✅ Sorted batch 261 kept in memory.\n",
      "🔹 Sorting batch 262/400 (1000 APIs)...\n",
      "✅ Sorted batch 262 kept in memory.\n",
      "🔹 Sorting batch 263/400 (1000 APIs)...\n",
      "✅ Sorted batch 263 kept in memory.\n",
      "🔹 Sorting batch 264/400 (1000 APIs)...\n",
      "✅ Sorted batch 264 kept in memory.\n",
      "🔹 Sorting batch 265/400 (1000 APIs)...\n",
      "✅ Sorted batch 265 kept in memory.\n",
      "🔹 Sorting batch 266/400 (1000 APIs)...\n",
      "✅ Sorted batch 266 kept in memory.\n",
      "🔹 Sorting batch 267/400 (1000 APIs)...\n",
      "✅ Sorted batch 267 kept in memory.\n",
      "🔹 Sorting batch 268/400 (1000 APIs)...\n",
      "✅ Sorted batch 268 kept in memory.\n",
      "🔹 Sorting batch 269/400 (1000 APIs)...\n",
      "✅ Sorted batch 269 kept in memory.\n",
      "🔹 Sorting batch 270/400 (1000 APIs)...\n",
      "✅ Sorted batch 270 kept in memory.\n",
      "🔹 Sorting batch 271/400 (1000 APIs)...\n",
      "✅ Sorted batch 271 kept in memory.\n",
      "🔹 Sorting batch 272/400 (1000 APIs)...\n",
      "✅ Sorted batch 272 kept in memory.\n",
      "🔹 Sorting batch 273/400 (1000 APIs)...\n",
      "✅ Sorted batch 273 kept in memory.\n",
      "🔹 Sorting batch 274/400 (1000 APIs)...\n",
      "✅ Sorted batch 274 kept in memory.\n",
      "🔹 Sorting batch 275/400 (1000 APIs)...\n",
      "✅ Sorted batch 275 kept in memory.\n",
      "🔹 Sorting batch 276/400 (1000 APIs)...\n",
      "✅ Sorted batch 276 kept in memory.\n",
      "🔹 Sorting batch 277/400 (1000 APIs)...\n",
      "✅ Sorted batch 277 kept in memory.\n",
      "🔹 Sorting batch 278/400 (1000 APIs)...\n",
      "✅ Sorted batch 278 kept in memory.\n",
      "🔹 Sorting batch 279/400 (1000 APIs)...\n",
      "✅ Sorted batch 279 kept in memory.\n",
      "🔹 Sorting batch 280/400 (1000 APIs)...\n",
      "✅ Sorted batch 280 kept in memory.\n",
      "🔹 Sorting batch 281/400 (1000 APIs)...\n",
      "✅ Sorted batch 281 kept in memory.\n",
      "🔹 Sorting batch 282/400 (1000 APIs)...\n",
      "✅ Sorted batch 282 kept in memory.\n",
      "🔹 Sorting batch 283/400 (1000 APIs)...\n",
      "✅ Sorted batch 283 kept in memory.\n",
      "🔹 Sorting batch 284/400 (1000 APIs)...\n",
      "✅ Sorted batch 284 kept in memory.\n",
      "🔹 Sorting batch 285/400 (1000 APIs)...\n",
      "✅ Sorted batch 285 kept in memory.\n",
      "🔹 Sorting batch 286/400 (1000 APIs)...\n",
      "✅ Sorted batch 286 kept in memory.\n",
      "🔹 Sorting batch 287/400 (1000 APIs)...\n",
      "✅ Sorted batch 287 kept in memory.\n",
      "🔹 Sorting batch 288/400 (1000 APIs)...\n",
      "✅ Sorted batch 288 kept in memory.\n",
      "🔹 Sorting batch 289/400 (1000 APIs)...\n",
      "✅ Sorted batch 289 kept in memory.\n",
      "🔹 Sorting batch 290/400 (1000 APIs)...\n",
      "✅ Sorted batch 290 kept in memory.\n",
      "🔹 Sorting batch 291/400 (1000 APIs)...\n",
      "✅ Sorted batch 291 kept in memory.\n",
      "🔹 Sorting batch 292/400 (1000 APIs)...\n",
      "✅ Sorted batch 292 kept in memory.\n",
      "🔹 Sorting batch 293/400 (1000 APIs)...\n",
      "✅ Sorted batch 293 kept in memory.\n",
      "🔹 Sorting batch 294/400 (1000 APIs)...\n",
      "✅ Sorted batch 294 kept in memory.\n",
      "🔹 Sorting batch 295/400 (1000 APIs)...\n",
      "✅ Sorted batch 295 kept in memory.\n",
      "🔹 Sorting batch 296/400 (1000 APIs)...\n",
      "✅ Sorted batch 296 kept in memory.\n",
      "🔹 Sorting batch 297/400 (1000 APIs)...\n",
      "✅ Sorted batch 297 kept in memory.\n",
      "🔹 Sorting batch 298/400 (1000 APIs)...\n",
      "✅ Sorted batch 298 kept in memory.\n",
      "🔹 Sorting batch 299/400 (1000 APIs)...\n",
      "✅ Sorted batch 299 kept in memory.\n",
      "🔹 Sorting batch 300/400 (1000 APIs)...\n",
      "✅ Sorted batch 300 kept in memory.\n",
      "🔹 Sorting batch 301/400 (1000 APIs)...\n",
      "✅ Sorted batch 301 kept in memory.\n",
      "🔹 Sorting batch 302/400 (1000 APIs)...\n",
      "✅ Sorted batch 302 kept in memory.\n",
      "🔹 Sorting batch 303/400 (1000 APIs)...\n",
      "✅ Sorted batch 303 kept in memory.\n",
      "🔹 Sorting batch 304/400 (1000 APIs)...\n",
      "✅ Sorted batch 304 kept in memory.\n",
      "🔹 Sorting batch 305/400 (1000 APIs)...\n",
      "✅ Sorted batch 305 kept in memory.\n",
      "🔹 Sorting batch 306/400 (1000 APIs)...\n",
      "✅ Sorted batch 306 kept in memory.\n",
      "🔹 Sorting batch 307/400 (1000 APIs)...\n",
      "✅ Sorted batch 307 kept in memory.\n",
      "🔹 Sorting batch 308/400 (1000 APIs)...\n",
      "✅ Sorted batch 308 kept in memory.\n",
      "🔹 Sorting batch 309/400 (1000 APIs)...\n",
      "✅ Sorted batch 309 kept in memory.\n",
      "🔹 Sorting batch 310/400 (1000 APIs)...\n",
      "✅ Sorted batch 310 kept in memory.\n",
      "🔹 Sorting batch 311/400 (1000 APIs)...\n",
      "✅ Sorted batch 311 kept in memory.\n",
      "🔹 Sorting batch 312/400 (1000 APIs)...\n",
      "✅ Sorted batch 312 kept in memory.\n",
      "🔹 Sorting batch 313/400 (1000 APIs)...\n",
      "✅ Sorted batch 313 kept in memory.\n",
      "🔹 Sorting batch 314/400 (1000 APIs)...\n",
      "✅ Sorted batch 314 kept in memory.\n",
      "🔹 Sorting batch 315/400 (1000 APIs)...\n",
      "✅ Sorted batch 315 kept in memory.\n",
      "🔹 Sorting batch 316/400 (1000 APIs)...\n",
      "✅ Sorted batch 316 kept in memory.\n",
      "🔹 Sorting batch 317/400 (1000 APIs)...\n",
      "✅ Sorted batch 317 kept in memory.\n",
      "🔹 Sorting batch 318/400 (1000 APIs)...\n",
      "✅ Sorted batch 318 kept in memory.\n",
      "🔹 Sorting batch 319/400 (1000 APIs)...\n",
      "✅ Sorted batch 319 kept in memory.\n",
      "🔹 Sorting batch 320/400 (1000 APIs)...\n",
      "✅ Sorted batch 320 kept in memory.\n",
      "🔹 Sorting batch 321/400 (1000 APIs)...\n",
      "✅ Sorted batch 321 kept in memory.\n",
      "🔹 Sorting batch 322/400 (1000 APIs)...\n",
      "✅ Sorted batch 322 kept in memory.\n",
      "🔹 Sorting batch 323/400 (1000 APIs)...\n",
      "✅ Sorted batch 323 kept in memory.\n",
      "🔹 Sorting batch 324/400 (1000 APIs)...\n",
      "✅ Sorted batch 324 kept in memory.\n",
      "🔹 Sorting batch 325/400 (1000 APIs)...\n",
      "✅ Sorted batch 325 kept in memory.\n",
      "🔹 Sorting batch 326/400 (1000 APIs)...\n",
      "✅ Sorted batch 326 kept in memory.\n",
      "🔹 Sorting batch 327/400 (1000 APIs)...\n",
      "✅ Sorted batch 327 kept in memory.\n",
      "🔹 Sorting batch 328/400 (1000 APIs)...\n",
      "✅ Sorted batch 328 kept in memory.\n",
      "🔹 Sorting batch 329/400 (1000 APIs)...\n",
      "✅ Sorted batch 329 kept in memory.\n",
      "🔹 Sorting batch 330/400 (1000 APIs)...\n",
      "✅ Sorted batch 330 kept in memory.\n",
      "🔹 Sorting batch 331/400 (1000 APIs)...\n",
      "✅ Sorted batch 331 kept in memory.\n",
      "🔹 Sorting batch 332/400 (1000 APIs)...\n",
      "✅ Sorted batch 332 kept in memory.\n",
      "🔹 Sorting batch 333/400 (1000 APIs)...\n",
      "✅ Sorted batch 333 kept in memory.\n",
      "🔹 Sorting batch 334/400 (1000 APIs)...\n",
      "✅ Sorted batch 334 kept in memory.\n",
      "🔹 Sorting batch 335/400 (1000 APIs)...\n",
      "✅ Sorted batch 335 kept in memory.\n",
      "🔹 Sorting batch 336/400 (1000 APIs)...\n",
      "✅ Sorted batch 336 kept in memory.\n",
      "🔹 Sorting batch 337/400 (1000 APIs)...\n",
      "✅ Sorted batch 337 kept in memory.\n",
      "🔹 Sorting batch 338/400 (1000 APIs)...\n",
      "✅ Sorted batch 338 kept in memory.\n",
      "🔹 Sorting batch 339/400 (1000 APIs)...\n",
      "✅ Sorted batch 339 kept in memory.\n",
      "🔹 Sorting batch 340/400 (1000 APIs)...\n",
      "✅ Sorted batch 340 kept in memory.\n",
      "🔹 Sorting batch 341/400 (1000 APIs)...\n",
      "✅ Sorted batch 341 kept in memory.\n",
      "🔹 Sorting batch 342/400 (1000 APIs)...\n",
      "✅ Sorted batch 342 kept in memory.\n",
      "🔹 Sorting batch 343/400 (1000 APIs)...\n",
      "✅ Sorted batch 343 kept in memory.\n",
      "🔹 Sorting batch 344/400 (1000 APIs)...\n",
      "✅ Sorted batch 344 kept in memory.\n",
      "🔹 Sorting batch 345/400 (1000 APIs)...\n",
      "✅ Sorted batch 345 kept in memory.\n",
      "🔹 Sorting batch 346/400 (1000 APIs)...\n",
      "✅ Sorted batch 346 kept in memory.\n",
      "🔹 Sorting batch 347/400 (1000 APIs)...\n",
      "✅ Sorted batch 347 kept in memory.\n",
      "🔹 Sorting batch 348/400 (1000 APIs)...\n",
      "✅ Sorted batch 348 kept in memory.\n",
      "🔹 Sorting batch 349/400 (1000 APIs)...\n",
      "✅ Sorted batch 349 kept in memory.\n",
      "🔹 Sorting batch 350/400 (1000 APIs)...\n",
      "✅ Sorted batch 350 kept in memory.\n",
      "🔹 Sorting batch 351/400 (1000 APIs)...\n",
      "✅ Sorted batch 351 kept in memory.\n",
      "🔹 Sorting batch 352/400 (1000 APIs)...\n",
      "✅ Sorted batch 352 kept in memory.\n",
      "🔹 Sorting batch 353/400 (1000 APIs)...\n",
      "✅ Sorted batch 353 kept in memory.\n",
      "🔹 Sorting batch 354/400 (1000 APIs)...\n",
      "✅ Sorted batch 354 kept in memory.\n",
      "🔹 Sorting batch 355/400 (1000 APIs)...\n",
      "✅ Sorted batch 355 kept in memory.\n",
      "🔹 Sorting batch 356/400 (1000 APIs)...\n",
      "✅ Sorted batch 356 kept in memory.\n",
      "🔹 Sorting batch 357/400 (1000 APIs)...\n",
      "✅ Sorted batch 357 kept in memory.\n",
      "🔹 Sorting batch 358/400 (1000 APIs)...\n",
      "✅ Sorted batch 358 kept in memory.\n",
      "🔹 Sorting batch 359/400 (1000 APIs)...\n",
      "✅ Sorted batch 359 kept in memory.\n",
      "🔹 Sorting batch 360/400 (1000 APIs)...\n",
      "✅ Sorted batch 360 kept in memory.\n",
      "🔹 Sorting batch 361/400 (1000 APIs)...\n",
      "✅ Sorted batch 361 kept in memory.\n",
      "🔹 Sorting batch 362/400 (1000 APIs)...\n",
      "✅ Sorted batch 362 kept in memory.\n",
      "🔹 Sorting batch 363/400 (1000 APIs)...\n",
      "✅ Sorted batch 363 kept in memory.\n",
      "🔹 Sorting batch 364/400 (1000 APIs)...\n",
      "✅ Sorted batch 364 kept in memory.\n",
      "🔹 Sorting batch 365/400 (1000 APIs)...\n",
      "✅ Sorted batch 365 kept in memory.\n",
      "🔹 Sorting batch 366/400 (1000 APIs)...\n",
      "✅ Sorted batch 366 kept in memory.\n",
      "🔹 Sorting batch 367/400 (1000 APIs)...\n",
      "✅ Sorted batch 367 kept in memory.\n",
      "🔹 Sorting batch 368/400 (1000 APIs)...\n",
      "✅ Sorted batch 368 kept in memory.\n",
      "🔹 Sorting batch 369/400 (1000 APIs)...\n",
      "✅ Sorted batch 369 kept in memory.\n",
      "🔹 Sorting batch 370/400 (1000 APIs)...\n",
      "✅ Sorted batch 370 kept in memory.\n",
      "🔹 Sorting batch 371/400 (1000 APIs)...\n",
      "✅ Sorted batch 371 kept in memory.\n",
      "🔹 Sorting batch 372/400 (1000 APIs)...\n",
      "✅ Sorted batch 372 kept in memory.\n",
      "🔹 Sorting batch 373/400 (1000 APIs)...\n",
      "✅ Sorted batch 373 kept in memory.\n",
      "🔹 Sorting batch 374/400 (1000 APIs)...\n",
      "✅ Sorted batch 374 kept in memory.\n",
      "🔹 Sorting batch 375/400 (1000 APIs)...\n",
      "✅ Sorted batch 375 kept in memory.\n",
      "🔹 Sorting batch 376/400 (1000 APIs)...\n",
      "✅ Sorted batch 376 kept in memory.\n",
      "🔹 Sorting batch 377/400 (1000 APIs)...\n",
      "✅ Sorted batch 377 kept in memory.\n",
      "🔹 Sorting batch 378/400 (1000 APIs)...\n",
      "✅ Sorted batch 378 kept in memory.\n",
      "🔹 Sorting batch 379/400 (1000 APIs)...\n",
      "✅ Sorted batch 379 kept in memory.\n",
      "🔹 Sorting batch 380/400 (1000 APIs)...\n",
      "✅ Sorted batch 380 kept in memory.\n",
      "🔹 Sorting batch 381/400 (1000 APIs)...\n",
      "✅ Sorted batch 381 kept in memory.\n",
      "🔹 Sorting batch 382/400 (1000 APIs)...\n",
      "✅ Sorted batch 382 kept in memory.\n",
      "🔹 Sorting batch 383/400 (1000 APIs)...\n",
      "✅ Sorted batch 383 kept in memory.\n",
      "🔹 Sorting batch 384/400 (1000 APIs)...\n",
      "✅ Sorted batch 384 kept in memory.\n",
      "🔹 Sorting batch 385/400 (1000 APIs)...\n",
      "✅ Sorted batch 385 kept in memory.\n",
      "🔹 Sorting batch 386/400 (1000 APIs)...\n",
      "✅ Sorted batch 386 kept in memory.\n",
      "🔹 Sorting batch 387/400 (1000 APIs)...\n",
      "✅ Sorted batch 387 kept in memory.\n",
      "🔹 Sorting batch 388/400 (1000 APIs)...\n",
      "✅ Sorted batch 388 kept in memory.\n",
      "🔹 Sorting batch 389/400 (1000 APIs)...\n",
      "✅ Sorted batch 389 kept in memory.\n",
      "🔹 Sorting batch 390/400 (1000 APIs)...\n",
      "✅ Sorted batch 390 kept in memory.\n",
      "🔹 Sorting batch 391/400 (1000 APIs)...\n",
      "✅ Sorted batch 391 kept in memory.\n",
      "🔹 Sorting batch 392/400 (1000 APIs)...\n",
      "✅ Sorted batch 392 kept in memory.\n",
      "🔹 Sorting batch 393/400 (1000 APIs)...\n",
      "✅ Sorted batch 393 kept in memory.\n",
      "🔹 Sorting batch 394/400 (1000 APIs)...\n",
      "✅ Sorted batch 394 kept in memory.\n",
      "🔹 Sorting batch 395/400 (1000 APIs)...\n",
      "✅ Sorted batch 395 kept in memory.\n",
      "🔹 Sorting batch 396/400 (1000 APIs)...\n",
      "✅ Sorted batch 396 kept in memory.\n",
      "🔹 Sorting batch 397/400 (1000 APIs)...\n",
      "✅ Sorted batch 397 kept in memory.\n",
      "🔹 Sorting batch 398/400 (1000 APIs)...\n",
      "✅ Sorted batch 398 kept in memory.\n",
      "🔹 Sorting batch 399/400 (1000 APIs)...\n",
      "✅ Sorted batch 399 kept in memory.\n",
      "🔹 Sorting batch 400/400 (39 APIs)...\n",
      "✅ Sorted batch 400 kept in memory.\n",
      "✅ All 400 batches sorted.\n",
      "🔄 Concatenating 400 batches into final sorted DataFrame...\n"
     ]
    }
   ],
   "source": [
    "# I need to use the same respective parameters as I did to create backfill_df\n",
    "forecast_df = batch_sort_forecast_df(forecast_df, batch_size=1000, write_batches_to_disk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbd27679-0fe0-481e-958b-e2983b736da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_parquet('../data/forecast_3_sorted.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e510372-1132-4d1f-ad45-38f14e5c8163",
   "metadata": {},
   "source": [
    "That took about an hour and 20 minutes and I made an error the first time so I had to re-do the entire thing, but now that the data is loaded we should be good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "577f0385-7e15-4b80-ae94-518a32b67415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19951950 entries, 0 to 19951949\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   api_no_10                 string        \n",
      " 1   date_prod                 datetime64[ns]\n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             float64       \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Well_Production_Type      float64       \n",
      " 9   reservoir type            float64       \n",
      " 10  arps model                float64       \n",
      " 11  Production_Status         float64       \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     float64       \n",
      " 17  formation_group           float64       \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          float64       \n",
      " 22  well_generation           float64       \n",
      " 23  well_density_1km          float64       \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 int32         \n",
      " 26  prod_month                int32         \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      "dtypes: datetime64[ns](2), float64(23), int32(3), string(1)\n",
      "memory usage: 4.2 GB\n"
     ]
    }
   ],
   "source": [
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896469cc-5917-4e64-863e-c9c40a01514d",
   "metadata": {},
   "source": [
    "It looks good so far, the right number of rows with all the right columns, and takes up as much memory as I already imagined it would. Now it's time to add the backfill columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ce47a5f-ac72-49f6-ac99-f4ac874d7c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded joined_data as Dask DataFrame\n",
      "  Shape: (<dask_expr.expr.Scalar: expr=ReadParquetFSSpec(81259e1).size() // 11, dtype=int32>, 11)\n",
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 11 entries, api_no_10 to oil_avg_6\n",
      "dtypes: datetime64[ns](1), float64(9), string(1)"
     ]
    }
   ],
   "source": [
    "backfill_df = load_parquet_datasets({'joined_data': '../data/forecast_4_backfill.parquet'}, use_dask=True)['joined_data']\n",
    "backfill_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cf6e5fa-b8b6-4ea5-90d4-edb56aa198a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19951950 entries, 0 to 19951949\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   api_no_10          string        \n",
      " 1   date_prod          datetime64[ns]\n",
      " 2   last_year          float64       \n",
      " 3   last_month         float64       \n",
      " 4   last_gas           float64       \n",
      " 5   last_oil           float64       \n",
      " 6   months_since_last  float64       \n",
      " 7   gas_avg_3          float64       \n",
      " 8   oil_avg_3          float64       \n",
      " 9   gas_avg_6          float64       \n",
      " 10  oil_avg_6          float64       \n",
      "dtypes: datetime64[ns](1), float64(9), string(1)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "backfill_df = backfill_df.compute()\n",
    "backfill_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62361b81-5292-4618-ab91-428f6d8fa22e",
   "metadata": {},
   "source": [
    "Let's check that the heads and tails of the dataframes are the same, for evidence that the columns line up properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9844059-0e93-469c-9b17-b7ff9f3dde66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_no_10</th>\n",
       "      <th>date_prod</th>\n",
       "      <th>gas_monthly</th>\n",
       "      <th>oil_monthly</th>\n",
       "      <th>start_date</th>\n",
       "      <th>wellbore_type</th>\n",
       "      <th>Quality_Quant</th>\n",
       "      <th>Production_Age</th>\n",
       "      <th>Well_Production_Type</th>\n",
       "      <th>reservoir type</th>\n",
       "      <th>arps model</th>\n",
       "      <th>Production_Status</th>\n",
       "      <th>lat_surface</th>\n",
       "      <th>lon_surface</th>\n",
       "      <th>lat_bottomhole</th>\n",
       "      <th>lon_bottomhole</th>\n",
       "      <th>basin</th>\n",
       "      <th>formation_group</th>\n",
       "      <th>horizontal_length</th>\n",
       "      <th>measured_depth</th>\n",
       "      <th>depth_tvd</th>\n",
       "      <th>operator_cluster</th>\n",
       "      <th>well_generation</th>\n",
       "      <th>well_density_1km</th>\n",
       "      <th>nearest_well_distance_km</th>\n",
       "      <th>prod_year</th>\n",
       "      <th>prod_month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>337</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>338</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>339</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>340</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>342</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>343</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>344</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>345</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>346</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>347</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>348</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>349</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>350</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>352</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>354</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>355</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>356</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>31.628696</td>\n",
       "      <td>-95.472879</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2468.526123</td>\n",
       "      <td>570.0</td>\n",
       "      <td>564.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     api_no_10  date_prod  gas_monthly  oil_monthly start_date  wellbore_type  \\\n",
       "0   4200131030 2021-01-01          0.0          2.0 1993-01-01            2.0   \n",
       "1   4200131030 2021-02-01          0.0          1.0 1993-01-01            2.0   \n",
       "2   4200131030 2021-03-01          0.0          2.0 1993-01-01            2.0   \n",
       "3   4200131030 2021-04-01          0.0          2.0 1993-01-01            2.0   \n",
       "4   4200131030 2021-05-01          0.0          1.0 1993-01-01            2.0   \n",
       "5   4200131030 2021-06-01          0.0          2.0 1993-01-01            2.0   \n",
       "6   4200131030 2021-07-01          0.0          1.0 1993-01-01            2.0   \n",
       "7   4200131030 2021-08-01          0.0          1.0 1993-01-01            2.0   \n",
       "8   4200131030 2021-09-01          0.0          1.0 1993-01-01            2.0   \n",
       "9   4200131030 2021-10-01          0.0          2.0 1993-01-01            2.0   \n",
       "10  4200131030 2021-11-01          0.0          1.0 1993-01-01            2.0   \n",
       "11  4200131030 2021-12-01          0.0          2.0 1993-01-01            2.0   \n",
       "12  4200131030 2022-01-01          0.0          1.0 1993-01-01            2.0   \n",
       "13  4200131030 2022-02-01          0.0          1.0 1993-01-01            2.0   \n",
       "14  4200131030 2022-03-01          0.0          2.0 1993-01-01            2.0   \n",
       "15  4200131030 2022-04-01          0.0          2.0 1993-01-01            2.0   \n",
       "16  4200131030 2022-05-01          0.0          2.0 1993-01-01            2.0   \n",
       "17  4200131030 2022-06-01          0.0          1.0 1993-01-01            2.0   \n",
       "18  4200131030 2022-07-01          0.0          2.0 1993-01-01            2.0   \n",
       "19  4200131030 2022-08-01          0.0          2.0 1993-01-01            2.0   \n",
       "\n",
       "    Quality_Quant  Production_Age  Well_Production_Type  reservoir type  \\\n",
       "0             6.0             337                   3.0             1.0   \n",
       "1             6.0             338                   3.0             1.0   \n",
       "2             6.0             339                   3.0             1.0   \n",
       "3             6.0             340                   3.0             1.0   \n",
       "4             6.0             341                   3.0             1.0   \n",
       "5             6.0             342                   3.0             1.0   \n",
       "6             6.0             343                   3.0             1.0   \n",
       "7             6.0             344                   3.0             1.0   \n",
       "8             6.0             345                   3.0             1.0   \n",
       "9             6.0             346                   3.0             1.0   \n",
       "10            6.0             347                   3.0             1.0   \n",
       "11            6.0             348                   3.0             1.0   \n",
       "12            6.0             349                   3.0             1.0   \n",
       "13            6.0             350                   3.0             1.0   \n",
       "14            6.0             351                   3.0             1.0   \n",
       "15            6.0             352                   3.0             1.0   \n",
       "16            6.0             353                   3.0             1.0   \n",
       "17            6.0             354                   3.0             1.0   \n",
       "18            6.0             355                   3.0             1.0   \n",
       "19            6.0             356                   3.0             1.0   \n",
       "\n",
       "    arps model  Production_Status  lat_surface  lon_surface  lat_bottomhole  \\\n",
       "0          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "1          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "2          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "3          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "4          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "5          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "6          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "7          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "8          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "9          2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "10         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "11         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "12         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "13         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "14         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "15         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "16         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "17         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "18         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "19         2.0                1.0    31.628696   -95.472879       31.628696   \n",
       "\n",
       "    lon_bottomhole  basin  formation_group  horizontal_length  measured_depth  \\\n",
       "0       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "1       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "2       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "3       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "4       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "5       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "6       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "7       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "8       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "9       -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "10      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "11      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "12      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "13      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "14      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "15      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "16      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "17      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "18      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "19      -95.472879    2.0             16.0        2468.526123           570.0   \n",
       "\n",
       "    depth_tvd  operator_cluster  well_generation  well_density_1km  \\\n",
       "0       564.3               0.0              1.0             310.0   \n",
       "1       564.3               0.0              1.0             310.0   \n",
       "2       564.3               0.0              1.0             310.0   \n",
       "3       564.3               0.0              1.0             310.0   \n",
       "4       564.3               0.0              1.0             310.0   \n",
       "5       564.3               0.0              1.0             310.0   \n",
       "6       564.3               0.0              1.0             310.0   \n",
       "7       564.3               0.0              1.0             310.0   \n",
       "8       564.3               0.0              1.0             310.0   \n",
       "9       564.3               0.0              1.0             310.0   \n",
       "10      564.3               0.0              1.0             310.0   \n",
       "11      564.3               0.0              1.0             310.0   \n",
       "12      564.3               0.0              1.0             310.0   \n",
       "13      564.3               0.0              1.0             310.0   \n",
       "14      564.3               0.0              1.0             310.0   \n",
       "15      564.3               0.0              1.0             310.0   \n",
       "16      564.3               0.0              1.0             310.0   \n",
       "17      564.3               0.0              1.0             310.0   \n",
       "18      564.3               0.0              1.0             310.0   \n",
       "19      564.3               0.0              1.0             310.0   \n",
       "\n",
       "    nearest_well_distance_km  prod_year  prod_month     month_sin  \\\n",
       "0                   0.069054       2021           1  5.000000e-01   \n",
       "1                   0.069054       2021           2  8.660254e-01   \n",
       "2                   0.069054       2021           3  1.000000e+00   \n",
       "3                   0.069054       2021           4  8.660254e-01   \n",
       "4                   0.069054       2021           5  5.000000e-01   \n",
       "5                   0.069054       2021           6  1.224647e-16   \n",
       "6                   0.069054       2021           7 -5.000000e-01   \n",
       "7                   0.069054       2021           8 -8.660254e-01   \n",
       "8                   0.069054       2021           9 -1.000000e+00   \n",
       "9                   0.069054       2021          10 -8.660254e-01   \n",
       "10                  0.069054       2021          11 -5.000000e-01   \n",
       "11                  0.069054       2021          12 -2.449294e-16   \n",
       "12                  0.069054       2022           1  5.000000e-01   \n",
       "13                  0.069054       2022           2  8.660254e-01   \n",
       "14                  0.069054       2022           3  1.000000e+00   \n",
       "15                  0.069054       2022           4  8.660254e-01   \n",
       "16                  0.069054       2022           5  5.000000e-01   \n",
       "17                  0.069054       2022           6  1.224647e-16   \n",
       "18                  0.069054       2022           7 -5.000000e-01   \n",
       "19                  0.069054       2022           8 -8.660254e-01   \n",
       "\n",
       "       month_cos  \n",
       "0   8.660254e-01  \n",
       "1   5.000000e-01  \n",
       "2   6.123234e-17  \n",
       "3  -5.000000e-01  \n",
       "4  -8.660254e-01  \n",
       "5  -1.000000e+00  \n",
       "6  -8.660254e-01  \n",
       "7  -5.000000e-01  \n",
       "8  -1.836970e-16  \n",
       "9   5.000000e-01  \n",
       "10  8.660254e-01  \n",
       "11  1.000000e+00  \n",
       "12  8.660254e-01  \n",
       "13  5.000000e-01  \n",
       "14  6.123234e-17  \n",
       "15 -5.000000e-01  \n",
       "16 -8.660254e-01  \n",
       "17 -1.000000e+00  \n",
       "18 -8.660254e-01  \n",
       "19 -5.000000e-01  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ef25793-9799-4b8c-8274-52c2768fb933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_no_10</th>\n",
       "      <th>date_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4200131030</td>\n",
       "      <td>2022-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     api_no_10  date_prod\n",
       "0   4200131030 2021-01-01\n",
       "1   4200131030 2021-02-01\n",
       "2   4200131030 2021-03-01\n",
       "3   4200131030 2021-04-01\n",
       "4   4200131030 2021-05-01\n",
       "5   4200131030 2021-06-01\n",
       "6   4200131030 2021-07-01\n",
       "7   4200131030 2021-08-01\n",
       "8   4200131030 2021-09-01\n",
       "9   4200131030 2021-10-01\n",
       "10  4200131030 2021-11-01\n",
       "11  4200131030 2021-12-01\n",
       "12  4200131030 2022-01-01\n",
       "13  4200131030 2022-02-01\n",
       "14  4200131030 2022-03-01\n",
       "15  4200131030 2022-04-01\n",
       "16  4200131030 2022-05-01\n",
       "17  4200131030 2022-06-01\n",
       "18  4200131030 2022-07-01\n",
       "19  4200131030 2022-08-01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backfill_df[['api_no_10', 'date_prod']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb966a2-b5a7-4d8c-afbe-51a4b9d5a09f",
   "metadata": {},
   "source": [
    "The beginning is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7f55d49-a264-4c87-a224-8f78a0418e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_no_10</th>\n",
       "      <th>date_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19951930</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951931</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951932</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951933</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951934</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951935</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951936</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951937</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951938</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951939</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951940</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951941</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951942</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951943</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951944</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951945</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951946</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951947</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951948</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951949</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2025-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           api_no_10  date_prod\n",
       "19951930  4250130488 2023-07-01\n",
       "19951931  4250130488 2023-08-01\n",
       "19951932  4250130488 2023-09-01\n",
       "19951933  4250130488 2023-10-01\n",
       "19951934  4250130488 2023-11-01\n",
       "19951935  4250130488 2023-12-01\n",
       "19951936  4250130488 2024-01-01\n",
       "19951937  4250130488 2024-02-01\n",
       "19951938  4250130488 2024-03-01\n",
       "19951939  4250130488 2024-04-01\n",
       "19951940  4250130488 2024-05-01\n",
       "19951941  4250130488 2024-06-01\n",
       "19951942  4250130488 2024-07-01\n",
       "19951943  4250130488 2024-08-01\n",
       "19951944  4250130488 2024-09-01\n",
       "19951945  4250130488 2024-10-01\n",
       "19951946  4250130488 2024-11-01\n",
       "19951947  4250130488 2024-12-01\n",
       "19951948  4250130488 2025-01-01\n",
       "19951949  4250130488 2025-02-01"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backfill_df[['api_no_10', 'date_prod']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18501e7b-d19f-4155-bbe1-a92f7ac47030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api_no_10</th>\n",
       "      <th>date_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19951930</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951931</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951932</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951933</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951934</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951935</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951936</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951937</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951938</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951939</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951940</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951941</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951942</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951943</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951944</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951945</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951946</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951947</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2024-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951948</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951949</th>\n",
       "      <td>4250130488</td>\n",
       "      <td>2025-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           api_no_10  date_prod\n",
       "19951930  4250130488 2023-07-01\n",
       "19951931  4250130488 2023-08-01\n",
       "19951932  4250130488 2023-09-01\n",
       "19951933  4250130488 2023-10-01\n",
       "19951934  4250130488 2023-11-01\n",
       "19951935  4250130488 2023-12-01\n",
       "19951936  4250130488 2024-01-01\n",
       "19951937  4250130488 2024-02-01\n",
       "19951938  4250130488 2024-03-01\n",
       "19951939  4250130488 2024-04-01\n",
       "19951940  4250130488 2024-05-01\n",
       "19951941  4250130488 2024-06-01\n",
       "19951942  4250130488 2024-07-01\n",
       "19951943  4250130488 2024-08-01\n",
       "19951944  4250130488 2024-09-01\n",
       "19951945  4250130488 2024-10-01\n",
       "19951946  4250130488 2024-11-01\n",
       "19951947  4250130488 2024-12-01\n",
       "19951948  4250130488 2025-01-01\n",
       "19951949  4250130488 2025-02-01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df[['api_no_10', 'date_prod']].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c2714-d34a-4004-a45d-a1a43748b6dc",
   "metadata": {},
   "source": [
    "All the same dates and all the same indices, it looks solid. I'll just go ahead and check the whole columns since it should be too expensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c438ee00-e145-4b25-8f96-cd5ea48b0c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19951950"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(forecast_df['api_no_10'] == backfill_df['api_no_10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4603c-ce57-4c87-9690-72712928f0ae",
   "metadata": {},
   "source": [
    "Exactly the same as the number of entries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f334b86-3d84-431c-bd33-00cd4ad3f433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19951950"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(forecast_df['date_prod'] == backfill_df['date_prod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcf4ed2b-cb7b-4acf-9f8e-f556bcdc816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19951950 entries, 0 to 19951949\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   api_no_10                 string        \n",
      " 1   date_prod                 datetime64[ns]\n",
      " 2   gas_monthly               float64       \n",
      " 3   oil_monthly               float64       \n",
      " 4   start_date                datetime64[ns]\n",
      " 5   wellbore_type             float64       \n",
      " 6   Quality_Quant             float64       \n",
      " 7   Production_Age            int32         \n",
      " 8   Well_Production_Type      float64       \n",
      " 9   reservoir type            float64       \n",
      " 10  arps model                float64       \n",
      " 11  Production_Status         float64       \n",
      " 12  lat_surface               float64       \n",
      " 13  lon_surface               float64       \n",
      " 14  lat_bottomhole            float64       \n",
      " 15  lon_bottomhole            float64       \n",
      " 16  basin                     float64       \n",
      " 17  formation_group           float64       \n",
      " 18  horizontal_length         float64       \n",
      " 19  measured_depth            float64       \n",
      " 20  depth_tvd                 float64       \n",
      " 21  operator_cluster          float64       \n",
      " 22  well_generation           float64       \n",
      " 23  well_density_1km          float64       \n",
      " 24  nearest_well_distance_km  float64       \n",
      " 25  prod_year                 int32         \n",
      " 26  prod_month                int32         \n",
      " 27  month_sin                 float64       \n",
      " 28  month_cos                 float64       \n",
      " 29  last_year                 float64       \n",
      " 30  last_month                float64       \n",
      " 31  last_gas                  float64       \n",
      " 32  last_oil                  float64       \n",
      " 33  months_since_last         float64       \n",
      " 34  gas_avg_3                 float64       \n",
      " 35  oil_avg_3                 float64       \n",
      " 36  gas_avg_6                 float64       \n",
      " 37  oil_avg_6                 float64       \n",
      "dtypes: datetime64[ns](2), float64(32), int32(3), string(1)\n",
      "memory usage: 5.5 GB\n"
     ]
    }
   ],
   "source": [
    "for col in backfill_df.columns[2:]:\n",
    "    forecast_df[col] = backfill_df[col]\n",
    "\n",
    "forecast_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3fae3-43bf-4216-8ced-04ce8c162116",
   "metadata": {},
   "source": [
    "That is a monster of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4649ef00-a0bb-42ff-b428-1a2943ba983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: FORECAST_DF\n",
      "============================================================\n",
      "Shape: ((19951950, 38))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 string          19951950   399039     0.0       %\n",
      "date_prod                 datetime64[ns]  19951950   50         0.0       %\n",
      "gas_monthly               float64         16564703   129580     17.0      %\n",
      "oil_monthly               float64         16564703   38707      17.0      %\n",
      "start_date                datetime64[ns]  19951950   385        0.0       %\n",
      "wellbore_type             float64         19951950   3          0.0       %\n",
      "Quality_Quant             float64         19951950   9          0.0       %\n",
      "Production_Age            int32           19951950   386        0.0       %\n",
      "Well_Production_Type      float64         19951950   4          0.0       %\n",
      "reservoir type            float64         19951950   3          0.0       %\n",
      "arps model                float64         19951950   4          0.0       %\n",
      "Production_Status         float64         19951950   3          0.0       %\n",
      "lat_surface               float64         19951950   378656     0.0       %\n",
      "lon_surface               float64         19951950   385128     0.0       %\n",
      "lat_bottomhole            float64         19951950   382387     0.0       %\n",
      "lon_bottomhole            float64         19951950   386886     0.0       %\n",
      "basin                     float64         19951950   13         0.0       %\n",
      "formation_group           float64         19951950   17         0.0       %\n",
      "horizontal_length         float64         19951950   99702      0.0       %\n",
      "measured_depth            float64         19951950   25850      0.0       %\n",
      "depth_tvd                 float64         19951950   105422     0.0       %\n",
      "operator_cluster          float64         19951950   4          0.0       %\n",
      "well_generation           float64         19951950   17         0.0       %\n",
      "well_density_1km          float64         19951950   730        0.0       %\n",
      "nearest_well_distance_km  float64         19951950   273057     0.0       %\n",
      "prod_year                 int32           19951950   5          0.0       %\n",
      "prod_month                int32           19951950   12         0.0       %\n",
      "month_sin                 float64         19951950   11         0.0       %\n",
      "month_cos                 float64         19951950   11         0.0       %\n",
      "last_year                 float64         19951950   5          0.0       %\n",
      "last_month                float64         19951950   13         0.0       %\n",
      "last_gas                  float64         19951950   128036     0.0       %\n",
      "last_oil                  float64         19951950   38278      0.0       %\n",
      "months_since_last         float64         19951950   43         0.0       %\n",
      "gas_avg_3                 float64         19951950   262000     0.0       %\n",
      "oil_avg_3                 float64         19951950   95299      0.0       %\n",
      "gas_avg_6                 float64         19951950   430300     0.0       %\n",
      "oil_avg_6                 float64         19951950   172912     0.0       %\n"
     ]
    }
   ],
   "source": [
    "comprehensive_data_overview_dask({'forecast_df': forecast_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c9cd1e3-e8c4-4bd3-bb0d-c3da15f36581",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_parquet('../data/forecast_4.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f23f4c-a283-44e9-a375-defc4461431d",
   "metadata": {},
   "source": [
    "## Forecasting and Final Calculations <a id=\"Conclusions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc0c822c-f69c-4d84-adf6-1d40bb4f665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows needing predictions: 3,387,247\n"
     ]
    }
   ],
   "source": [
    "missing_mask = forecast_df['gas_monthly'].isna()\n",
    "print(f\"Rows needing predictions: {missing_mask.sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5caa097e-508d-4fd2-8994-85ad6c2c1119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387247"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(forecast_df['oil_monthly'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba1244b2-aa60-41e6-a9fd-24ba3135ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: X_FORECAST\n",
      "============================================================\n",
      "Shape: ((3387247, 33))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "wellbore_type             float64         3387247    3          0.0       %\n",
      "Quality_Quant             float64         3387247    9          0.0       %\n",
      "Production_Age            int32           3387247    386        0.0       %\n",
      "Well_Production_Type      float64         3387247    4          0.0       %\n",
      "reservoir type            float64         3387247    3          0.0       %\n",
      "arps model                float64         3387247    4          0.0       %\n",
      "Production_Status         float64         3387247    3          0.0       %\n",
      "lat_surface               float64         3387247    378656     0.0       %\n",
      "lon_surface               float64         3387247    385128     0.0       %\n",
      "lat_bottomhole            float64         3387247    382387     0.0       %\n",
      "lon_bottomhole            float64         3387247    386886     0.0       %\n",
      "basin                     float64         3387247    13         0.0       %\n",
      "formation_group           float64         3387247    17         0.0       %\n",
      "horizontal_length         float64         3387247    99702      0.0       %\n",
      "measured_depth            float64         3387247    25850      0.0       %\n",
      "depth_tvd                 float64         3387247    105422     0.0       %\n",
      "operator_cluster          float64         3387247    4          0.0       %\n",
      "well_generation           float64         3387247    17         0.0       %\n",
      "well_density_1km          float64         3387247    730        0.0       %\n",
      "nearest_well_distance_km  float64         3387247    273057     0.0       %\n",
      "prod_year                 int32           3387247    5          0.0       %\n",
      "prod_month                int32           3387247    12         0.0       %\n",
      "month_sin                 float64         3387247    11         0.0       %\n",
      "month_cos                 float64         3387247    11         0.0       %\n",
      "last_year                 float64         3387247    5          0.0       %\n",
      "last_month                float64         3387247    13         0.0       %\n",
      "last_gas                  float64         3387247    26685      0.0       %\n",
      "last_oil                  float64         3387247    11593      0.0       %\n",
      "months_since_last         float64         3387247    43         0.0       %\n",
      "gas_avg_3                 float64         3387247    54805      0.0       %\n",
      "oil_avg_3                 float64         3387247    29659      0.0       %\n",
      "gas_avg_6                 float64         3387247    71245      0.0       %\n",
      "oil_avg_6                 float64         3387247    38323      0.0       %\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns (exclude API, dates, and targets)\n",
    "exclude_cols = ['api_no_10', 'date_prod', 'start_date', 'gas_monthly', 'oil_monthly']\n",
    "feature_cols = [col for col in forecast_df.columns if col not in exclude_cols]\n",
    "\n",
    "# Create feature matrix and target vectors\n",
    "X_forecast = forecast_df[missing_mask][feature_cols].copy()\n",
    "comprehensive_data_overview_dask({'X_forecast': X_forecast})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4b5fc-9ebf-4a3e-849d-32b6524a082f",
   "metadata": {},
   "source": [
    "I accidentally wrote \"and target vectors\" in the comment above the creation of the forecast features, but that is just because I copied my code from before, it doesn't mean anything, there are no target vectors in this case since these are missing values, we can estimate the performance from what we did on the test set earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fb95252-bb56-4981-bbd5-38d5c83c678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_model = joblib.load('../models/final_gas_model.pkl')\n",
    "oil_model = joblib.load('../models/final_oil_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2cf1837-eb8b-4af8-a21f-b247e3ad7dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;mae&#x27;, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;mae&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.03</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device='cuda', early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='mae', feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fd115f1-deeb-461d-98f4-214b634f1d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;mae&#x27;, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;mae&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.03</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device='cuda', early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='mae', feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "             max_leaves=None, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "             n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "073fb73a-fc12-4b67-8c82-d0df7d7da0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_predictions = gas_model.predict(X_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37d73d1f-63d2-4dab-8ef5-3b35fcdc8014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.387247e+06\n",
       "mean     8.513797e+03\n",
       "std      4.205036e+04\n",
       "min     -2.296225e+04\n",
       "25%      1.872266e+01\n",
       "50%      1.015935e+02\n",
       "75%      2.572326e+03\n",
       "max      7.384224e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(gas_predictions).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "282da9a1-016a-4f7c-bd62-8f208424d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162587"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.Series(gas_predictions) <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e285f50-6a3c-4801-ad69-e5a93aa34895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.799974728739889"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*sum(pd.Series(gas_predictions) <= 0) / len(pd.Series(gas_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0052f0a5-2cc1-4788-8462-0c1e5f7ab754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.609890261352902"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*sum(forecast_df['gas_monthly'] == 0) / len(forecast_df['gas_monthly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a6770-bc5a-40f7-a64e-ee103b660dc4",
   "metadata": {},
   "source": [
    "There are some negative values there which we'll have to fix, **they'll just be interpreted as zeroes**, it's less than 5% of the data so hopefully not a problem considering how many zeroes there are, there are actually a lot more zero values in forecast_df for the gas_monthly values that we know, but that could also be happenstance since there isn't necessarily a random selection of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f62da713-8907-448a-8b19-d5b1755c438a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.387247e+06\n",
       "mean     8.531177e+03\n",
       "std      4.204627e+04\n",
       "min      0.000000e+00\n",
       "25%      1.872266e+01\n",
       "50%      1.015935e+02\n",
       "75%      2.572326e+03\n",
       "max      7.384224e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_predictions = np.maximum(gas_predictions, 0)\n",
    "pd.Series(gas_predictions).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a95065b-6ef0-45f8-9044-2c346fb7119d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.656470e+07\n",
       "mean     2.646018e+03\n",
       "std      1.856230e+04\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      5.600000e+01\n",
       "75%      8.210000e+02\n",
       "max      1.614492e+07\n",
       "Name: gas_monthly, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df['gas_monthly'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcebae6-cc39-4bb8-9b99-6f1c8eb41574",
   "metadata": {},
   "source": [
    "So the values towards the low end of our predictions tend to be higher than average whereas the values towards the highest end tend to be lower, this suggests to me that our model might over-correcting towards the mean, so that is one possible area where we could improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b71efc5-7c82-4ffb-bcd6-64da115bbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_predictions = oil_model.predict(X_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21beccf8-7a72-4153-8f43-cbc97cad6e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.387247e+06\n",
       "mean     2.847601e+03\n",
       "std      9.207719e+03\n",
       "min     -3.608422e+03\n",
       "25%      4.662048e+00\n",
       "50%      4.286880e+01\n",
       "75%      3.625202e+02\n",
       "max      1.419534e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(oil_predictions).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7092fda-ad9a-4e6c-a616-aa7cc27b5df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131359"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.Series(oil_predictions) <= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d05fd-d168-4a1c-bccf-d03c96b22e38",
   "metadata": {},
   "source": [
    "Similar amount of negative oil values, perhaps even fewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01050f95-06fd-4725-93ce-2d0c75eb9010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.387247e+06\n",
       "mean     2.850251e+03\n",
       "std      9.206856e+03\n",
       "min      0.000000e+00\n",
       "25%      4.662048e+00\n",
       "50%      4.286880e+01\n",
       "75%      3.625202e+02\n",
       "max      1.419534e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_predictions = np.maximum(oil_predictions, 0)\n",
    "pd.Series(oil_predictions).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3190981-bd3e-4287-9c1a-68e289867e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.656470e+07\n",
       "mean     4.283009e+02\n",
       "std      2.322347e+03\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      2.300000e+01\n",
       "75%      1.060000e+02\n",
       "max      1.391600e+06\n",
       "Name: oil_monthly, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df['oil_monthly'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c908b-3a58-423e-a6f8-e1289c66075b",
   "metadata": {},
   "source": [
    "The oil model interestingly is a bit different, it doesn't over-correct towards the mean it just has a bit larger than average values, but quite close in many case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72f6fbbe-eebf-4cc5-9018-c98f1992aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.loc[missing_mask, 'gas_monthly'] = gas_predictions\n",
    "forecast_df.loc[missing_mask, 'oil_monthly'] = oil_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c375df0-bdfd-441d-9385-67cb2403fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_parquet('../well_forecasts_complete.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b464ad7-cf16-4fd5-9a28-a1825b825b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: FORECAST_DF\n",
      "============================================================\n",
      "Shape: ((19951950, 38))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 string          19951950   399039     0.0       %\n",
      "date_prod                 datetime64[ns]  19951950   50         0.0       %\n",
      "gas_monthly               float64         19951950   471423     0.0       %\n",
      "oil_monthly               float64         19951950   597728     0.0       %\n",
      "start_date                datetime64[ns]  19951950   385        0.0       %\n",
      "wellbore_type             float64         19951950   3          0.0       %\n",
      "Quality_Quant             float64         19951950   9          0.0       %\n",
      "Production_Age            int32           19951950   386        0.0       %\n",
      "Well_Production_Type      float64         19951950   4          0.0       %\n",
      "reservoir type            float64         19951950   3          0.0       %\n",
      "arps model                float64         19951950   4          0.0       %\n",
      "Production_Status         float64         19951950   3          0.0       %\n",
      "lat_surface               float64         19951950   378656     0.0       %\n",
      "lon_surface               float64         19951950   385128     0.0       %\n",
      "lat_bottomhole            float64         19951950   382387     0.0       %\n",
      "lon_bottomhole            float64         19951950   386886     0.0       %\n",
      "basin                     float64         19951950   13         0.0       %\n",
      "formation_group           float64         19951950   17         0.0       %\n",
      "horizontal_length         float64         19951950   99702      0.0       %\n",
      "measured_depth            float64         19951950   25850      0.0       %\n",
      "depth_tvd                 float64         19951950   105422     0.0       %\n",
      "operator_cluster          float64         19951950   4          0.0       %\n",
      "well_generation           float64         19951950   17         0.0       %\n",
      "well_density_1km          float64         19951950   730        0.0       %\n",
      "nearest_well_distance_km  float64         19951950   273057     0.0       %\n",
      "prod_year                 int32           19951950   5          0.0       %\n",
      "prod_month                int32           19951950   12         0.0       %\n",
      "month_sin                 float64         19951950   11         0.0       %\n",
      "month_cos                 float64         19951950   11         0.0       %\n",
      "last_year                 float64         19951950   5          0.0       %\n",
      "last_month                float64         19951950   13         0.0       %\n",
      "last_gas                  float64         19951950   128036     0.0       %\n",
      "last_oil                  float64         19951950   38278      0.0       %\n",
      "months_since_last         float64         19951950   43         0.0       %\n",
      "gas_avg_3                 float64         19951950   262000     0.0       %\n",
      "oil_avg_3                 float64         19951950   95299      0.0       %\n",
      "gas_avg_6                 float64         19951950   430300     0.0       %\n",
      "oil_avg_6                 float64         19951950   172912     0.0       %\n"
     ]
    }
   ],
   "source": [
    "comprehensive_data_overview_dask({'forecast_df': forecast_df})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b9fde1-ebf8-48c0-a953-09d047139fd5",
   "metadata": {},
   "source": [
    "### State-Level Totals and Uncertainty <a id=\"State\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1caa66e-f93a-4e63-9f59-62139b747274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET: TARGET_PERIOD\n",
      "============================================================\n",
      "Shape: ((1197117, 38))\n",
      "\n",
      "Column Overview:\n",
      "Column                    Type            Non-Null   Unique     Missing % \n",
      "--------------------------------------------------------------------------------\n",
      "api_no_10                 string          1197117    399039     0.0       %\n",
      "date_prod                 datetime64[ns]  1197117    3          0.0       %\n",
      "gas_monthly               float64         1197117    81560      0.0       %\n",
      "oil_monthly               float64         1197117    89233      0.0       %\n",
      "start_date                datetime64[ns]  1197117    385        0.0       %\n",
      "wellbore_type             float64         1197117    3          0.0       %\n",
      "Quality_Quant             float64         1197117    9          0.0       %\n",
      "Production_Age            int32           1197117    383        0.0       %\n",
      "Well_Production_Type      float64         1197117    4          0.0       %\n",
      "reservoir type            float64         1197117    3          0.0       %\n",
      "arps model                float64         1197117    4          0.0       %\n",
      "Production_Status         float64         1197117    3          0.0       %\n",
      "lat_surface               float64         1197117    378656     0.0       %\n",
      "lon_surface               float64         1197117    385128     0.0       %\n",
      "lat_bottomhole            float64         1197117    382387     0.0       %\n",
      "lon_bottomhole            float64         1197117    386886     0.0       %\n",
      "basin                     float64         1197117    13         0.0       %\n",
      "formation_group           float64         1197117    17         0.0       %\n",
      "horizontal_length         float64         1197117    99702      0.0       %\n",
      "measured_depth            float64         1197117    25850      0.0       %\n",
      "depth_tvd                 float64         1197117    105422     0.0       %\n",
      "operator_cluster          float64         1197117    4          0.0       %\n",
      "well_generation           float64         1197117    17         0.0       %\n",
      "well_density_1km          float64         1197117    730        0.0       %\n",
      "nearest_well_distance_km  float64         1197117    273057     0.0       %\n",
      "prod_year                 int32           1197117    1          0.0       %\n",
      "prod_month                int32           1197117    3          0.0       %\n",
      "month_sin                 float64         1197117    3          0.0       %\n",
      "month_cos                 float64         1197117    3          0.0       %\n",
      "last_year                 float64         1197117    5          0.0       %\n",
      "last_month                float64         1197117    13         0.0       %\n",
      "last_gas                  float64         1197117    30191      0.0       %\n",
      "last_oil                  float64         1197117    12445      0.0       %\n",
      "months_since_last         float64         1197117    40         0.0       %\n",
      "gas_avg_3                 float64         1197117    51984      0.0       %\n",
      "oil_avg_3                 float64         1197117    23404      0.0       %\n",
      "gas_avg_6                 float64         1197117    70298      0.0       %\n",
      "oil_avg_6                 float64         1197117    32784      0.0       %\n"
     ]
    }
   ],
   "source": [
    "target_period = forecast_df[\n",
    "    (forecast_df['date_prod'] >= '2024-09-01') & \n",
    "    (forecast_df['date_prod'] <= '2024-11-30')\n",
    "].copy()\n",
    "\n",
    "comprehensive_data_overview_dask({'target_period': target_period})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "601582ee-952d-4c0f-8128-bc89091d528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly totals for Sep-Nov 2024:\n",
      "   date_prod   gas_monthly   oil_monthly\n",
      "0 2024-09-01  1.157746e+09  2.146556e+08\n",
      "1 2024-10-01  1.164559e+09  2.121537e+08\n",
      "2 2024-11-01  1.153913e+09  2.077197e+08\n"
     ]
    }
   ],
   "source": [
    "monthly_totals = target_period.groupby('date_prod').agg({\n",
    "    'gas_monthly': 'sum',\n",
    "    'oil_monthly': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Monthly totals for Sep-Nov 2024:\")\n",
    "print(monthly_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25daf723-24e8-492a-8bd1-164b90161467",
   "metadata": {},
   "source": [
    "Let's consider the uncertainty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69e4da8d-8ef4-41b6-b849-42b34c67655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty with bootstrap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap sampling:   0%|                                                                      | 0/100 [02:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m bootstrap_sample = []\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m api \u001b[38;5;129;01min\u001b[39;00m sampled_apis:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     api_data = target_period[\u001b[43mtarget_period\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapi_no_10\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m]\n\u001b[32m     16\u001b[39m     bootstrap_sample.append(api_data)\n\u001b[32m     18\u001b[39m bootstrap_df = pd.concat(bootstrap_sample, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[39m, in \u001b[36mOpsMixin.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\series.py:5803\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   5800\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   5801\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m5803\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5805\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:332\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    324\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mLengths must match to compare\u001b[39m\u001b[33m\"\u001b[39m, lvalues.shape, rvalues.shape\n\u001b[32m    325\u001b[39m         )\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    328\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[32m    329\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m lvalues.dtype != \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    330\u001b[39m ):\n\u001b[32m    331\u001b[39m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     res_values = op(lvalues, rvalues)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[32m    335\u001b[39m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator.ne:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[39m, in \u001b[36mOpsMixin.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py:652\u001b[39m, in \u001b[36mArrowExtensionArray._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(other):\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m         result = \u001b[43mpc_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pa_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_box_pa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (pa.lib.ArrowNotImplementedError, pa.lib.ArrowInvalid):\n\u001b[32m    654\u001b[39m         mask = isna(\u001b[38;5;28mself\u001b[39m) | isna(other)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\hyperion-forecasting\\Lib\\site-packages\\pyarrow\\compute.py:252\u001b[39m, in \u001b[36m_make_generic_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(memory_pool, *args)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], Expression):\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Expression._call(func_name, \u001b[38;5;28mlist\u001b[39m(args))\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_pool\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_bootstrap = 100\n",
    "bootstrap_results = []\n",
    "unique_apis = target_period['api_no_10'].unique()\n",
    "\n",
    "print(\"Calculating uncertainty with bootstrap...\")\n",
    "for i in tqdm(range(n_bootstrap), desc=\"Bootstrap sampling\"):\n",
    "    # Sample wells with replacement\n",
    "    sampled_apis = np.random.choice(unique_apis, \n",
    "                                   size=len(unique_apis), \n",
    "                                   replace=True)\n",
    "    \n",
    "    # Create bootstrap sample\n",
    "    bootstrap_sample = []\n",
    "    for api in sampled_apis:\n",
    "        api_data = target_period[target_period['api_no_10'] == api]\n",
    "        bootstrap_sample.append(api_data)\n",
    "    \n",
    "    bootstrap_df = pd.concat(bootstrap_sample, ignore_index=True)\n",
    "    \n",
    "    # Calculate totals for this bootstrap sample\n",
    "    bootstrap_totals = bootstrap_df.groupby('date_prod').agg({\n",
    "        'gas_monthly': 'sum',\n",
    "        'oil_monthly': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    bootstrap_results.append(bootstrap_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253ce58-30a0-486b-8b28-f72e7e4247b9",
   "metadata": {},
   "source": [
    "Taking way too long as usual, let's take another approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fcfdec7c-3310-4faf-89ee-4e6075fb23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_aggregate_fast(target_period, n_bootstrap=1000):\n",
    "    unique_apis = target_period['api_no_10'].unique()\n",
    "    n_apis = len(unique_apis)\n",
    "    bootstrap_results = []\n",
    "\n",
    "    for _ in tqdm(range(n_bootstrap), desc=\"Bootstrap sampling\"):\n",
    "        # Step 1: Sample API counts\n",
    "        sampled_apis = np.random.choice(unique_apis, size=n_apis, replace=True)\n",
    "        sampled_counts = pd.Series(sampled_apis).value_counts()\n",
    "\n",
    "        # Step 2: Merge counts with data\n",
    "        sampled_data = target_period[target_period['api_no_10'].isin(sampled_counts.index)].copy()\n",
    "        sampled_data = sampled_data.merge(sampled_counts.rename('count'), left_on='api_no_10', right_index=True)\n",
    "\n",
    "        # Step 3: Weight and aggregate\n",
    "        sampled_data['gas_monthly_weighted'] = sampled_data['gas_monthly'] * sampled_data['count']\n",
    "        sampled_data['oil_monthly_weighted'] = sampled_data['oil_monthly'] * sampled_data['count']\n",
    "\n",
    "        bootstrap_totals = sampled_data.groupby('date_prod').agg({\n",
    "            'gas_monthly_weighted': 'sum',\n",
    "            'oil_monthly_weighted': 'sum'\n",
    "        }).reset_index().rename(\n",
    "            columns={'gas_monthly_weighted': 'gas_monthly', 'oil_monthly_weighted': 'oil_monthly'}\n",
    "        )\n",
    "\n",
    "        bootstrap_results.append(bootstrap_totals)\n",
    "\n",
    "    return bootstrap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdcc18f3-2340-43cd-9f89-fbf43b415418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap sampling: 100%|████████████████████████████████████████████████████████████| 100/100 [05:09<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "bootstrap_results = bootstrap_aggregate_fast(target_period, n_bootstrap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54718dfa-ddd2-4125-bef7-1127544d88b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State totals with 95% confidence intervals:\n",
      "             gas_monthly                               oil_monthly  \\\n",
      "                    mean    <lambda_0>    <lambda_1>          mean   \n",
      "date_prod                                                            \n",
      "2024-09-01  1.157466e+09  1.139847e+09  1.179911e+09  2.146671e+08   \n",
      "2024-10-01  1.164302e+09  1.146643e+09  1.184698e+09  2.120810e+08   \n",
      "2024-11-01  1.153625e+09  1.136426e+09  1.173554e+09  2.075977e+08   \n",
      "\n",
      "                                        \n",
      "              <lambda_0>    <lambda_1>  \n",
      "date_prod                               \n",
      "2024-09-01  2.115205e+08  2.175992e+08  \n",
      "2024-10-01  2.086922e+08  2.147655e+08  \n",
      "2024-11-01  2.045415e+08  2.097808e+08  \n"
     ]
    }
   ],
   "source": [
    "# Calculate confidence intervals\n",
    "all_bootstrap = pd.concat(bootstrap_results)\n",
    "confidence_intervals = all_bootstrap.groupby('date_prod').agg({\n",
    "    'gas_monthly': ['mean', lambda x: np.percentile(x, 2.5), lambda x: np.percentile(x, 97.5)],\n",
    "    'oil_monthly': ['mean', lambda x: np.percentile(x, 2.5), lambda x: np.percentile(x, 97.5)]\n",
    "})\n",
    "\n",
    "print(\"\\nState totals with 95% confidence intervals:\")\n",
    "print(confidence_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe64fd2a-5372-4de6-adf5-8e6b6fb5bb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('gas_monthly',       'mean'),\n",
       "            ('gas_monthly', '<lambda_0>'),\n",
       "            ('gas_monthly', '<lambda_1>'),\n",
       "            ('oil_monthly',       'mean'),\n",
       "            ('oil_monthly', '<lambda_0>'),\n",
       "            ('oil_monthly', '<lambda_1>')],\n",
       "           )"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_intervals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "38d3959c-82e4-490f-8c44-e5ed4174d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State totals with 95% confidence intervals:\n",
      "            (gas_monthly, mean)  (gas_monthly, 2.5%)  (gas_monthly, 97.5%)  \\\n",
      "date_prod                                                                    \n",
      "2024-09-01         1.157466e+09         1.139847e+09          1.179911e+09   \n",
      "2024-10-01         1.164302e+09         1.146643e+09          1.184698e+09   \n",
      "2024-11-01         1.153625e+09         1.136426e+09          1.173554e+09   \n",
      "\n",
      "            (oil_monthly, mean)  (oil_monthly, 2.5%)  (oil_monthly, 97.5%)  \n",
      "date_prod                                                                   \n",
      "2024-09-01         2.146671e+08         2.115205e+08          2.175992e+08  \n",
      "2024-10-01         2.120810e+08         2.086922e+08          2.147655e+08  \n",
      "2024-11-01         2.075977e+08         2.045415e+08          2.097808e+08  \n"
     ]
    }
   ],
   "source": [
    "confidence_intervals.columns = [('gas_monthly',       'mean'),\n",
    "            ('gas_monthly', '2.5%'),\n",
    "            ('gas_monthly', '97.5%'),\n",
    "            ('oil_monthly',       'mean'),\n",
    "            ('oil_monthly', '2.5%'),\n",
    "            ('oil_monthly', '97.5%')]\n",
    "print(\"\\nState totals with 95% confidence intervals:\")\n",
    "print(confidence_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac89fdc7-d732-4a72-b1ee-5fed75cc6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_totals.to_csv('../state_totals_sep_nov_2024.csv', index=False)\n",
    "confidence_intervals.to_csv('../state_totals_with_uncertainty.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2d7fe-99eb-4e9d-bafa-015ee7629a07",
   "metadata": {},
   "source": [
    "## Results <a id=\"Results\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c8dd9a9-b96f-43d2-85d7-90044d7cb491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly totals for Sep-Nov 2024:\n",
      "   date_prod   gas_monthly   oil_monthly\n",
      "0 2024-09-01  1.157746e+09  2.146556e+08\n",
      "1 2024-10-01  1.164559e+09  2.121537e+08\n",
      "2 2024-11-01  1.153913e+09  2.077197e+08\n"
     ]
    }
   ],
   "source": [
    "print(\"Monthly totals for Sep-Nov 2024:\")\n",
    "print(monthly_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db71a2-b035-4005-83e0-174a5c2ef0f3",
   "metadata": {},
   "source": [
    "This chart lets us know how we're doing: https://www.rrc.texas.gov/oil-and-gas/research-and-statistics/production-data/texas-monthly-oil-gas-production/\n",
    "\n",
    "Actual Texas Gas values by MCF:\n",
    "- Gas Sep: 1,065,447,457\n",
    "- Gas Oct: 1,110,512,790\n",
    "- Gas Nov: 1,068,563,172\n",
    "\n",
    "On gas our predictions are pretty good, just a bit high, but right within the range of one billion MCF, and our predictions even replicate the slight spike in October\n",
    "\n",
    "Actual Texas Oil values by Barrel:\n",
    "- Oil Sep: 193,438,651\n",
    "- Oil Oct: 201,262,381\n",
    "- Oil Nov: 191,097,147\n",
    "\n",
    "Also not bad predictions for oil, right around the ballpark of 200 million, the spike in the oil case is less accurate though\n",
    "\n",
    "So overall I'd say my predictions easily pass the sanity check, they are within the correct range of values. With more advanced approaches they could probably be even more precise. I can calculate the percentage difference from the actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18184c07-f4f1-470f-b7b4-c6044b058269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0758040626671086"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*abs(monthly_totals['gas_monthly'].iloc[0] - 1065447457) / 2 / (monthly_totals['gas_monthly'].iloc[0] + 1065447457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "520b3f82-311b-40ae-8514-597b5845eb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.187789277325298"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*abs(monthly_totals['gas_monthly'].iloc[1] - 1110512790) / 2 / (monthly_totals['gas_monthly'].iloc[1] + 1110512790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4dc2486a-0a8d-47bf-a4a0-26aba7189fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.920142839634344"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*abs(monthly_totals['gas_monthly'].iloc[2] - 1068563172) / 2 / (monthly_totals['gas_monthly'].iloc[2] + 1068563172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c60b12f-cff4-4a8d-8945-a6baa8977f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5995183873374628"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*abs(monthly_totals['oil_monthly'].iloc[0] - 193438651) / 2 / (monthly_totals['oil_monthly'].iloc[0] + 193438651)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d227e3f1-1b08-4ca9-baaa-c6dc861a0dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3172346618675461"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*abs(monthly_totals['oil_monthly'].iloc[1] - 201262381) / 2 / (monthly_totals['oil_monthly'].iloc[1] + 201262381)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44e22144-7938-4751-bec6-a1468d4468b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.083986223404608"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*abs(monthly_totals['oil_monthly'].iloc[2] - 191097147) / 2 / (monthly_totals['oil_monthly'].iloc[2] + 191097147)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db5889-00f0-4e74-9935-fda6b1005241",
   "metadata": {},
   "source": [
    "All within 3 percent of the actual value, often considerably closer than that (even near 1 percent away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1c5fc-a327-45b8-8b26-b78e33e16eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
